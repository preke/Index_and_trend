,Issue_id_1,Issue_id_2,Resolution,Title_1,Title_2,same_comp,same_prio,same_tw
0,SPARK-533,SPARK-736,Fixed,Killing tasks in spark - request for comment,Killing tasks in spark,1,0,1
1,SPARK-545,SPARK-983,Duplicate,support external sort,Support external sorting for RDD#sortByKey(),0,0,1
2,SPARK-586,SPARK-589,Duplicate,Update docs to say that you need to set MESOS_NATIVE_LIBRARY when running standalone apps on Mesos,MESOS_NATIVE_LIBRARY env var needs to be set when running on Mesos,0,1,1
3,SPARK-594,SPARK-612,Fixed,Update examples to pass JARs when building a SparkContext in 0.6 and master,Update examples to pass JAR file to SparkContext in master and 0.6 branches,1,1,1
4,SPARK-620,SPARK-671,Duplicate,Default SPARK_MEM on AMI too high,Spark runs out of memory on fork/exec (affects both pipes and python),0,0,1
5,SPARK-636,SPARK-650,Unresolved,Add mechanism to run system management/configuration tasks on all workers,"Add a ""setup hook"" API for running initialization code on each executor",1,0,1
6,SPARK-636,SPARK-3513,Unresolved,Add mechanism to run system management/configuration tasks on all workers,Provide a utility for running a function once on each executor,1,0,1
7,SPARK-652,SPARK-673,Duplicate,Propagate exceptions from PySpark workers to the driver,PySpark should capture and re-throw Python exceptions,1,1,1
8,SPARK-655,SPARK-5785,Duplicate,Implement co-partitioning aware joins in PySpark,Pyspark does not support narrow dependencies,1,1,1
9,SPARK-672,SPARK-1989,Duplicate,"Executor gets stuck in a ""zombie"" state after running out of memory",Exit executors faster if they get into a cycle of heavy GC,1,0,1
10,SPARK-679,SPARK-1251,Duplicate,Have a DSL or other language support for OLAP expressions,Support for optimizing and executing structured queries,0,0,1
11,SPARK-682,SPARK-695,Duplicate,Memoize results of getPreferredLocations,Exponential recursion in getPreferredLocations,1,0,1
12,SPARK-693,SPARK-4616,Duplicate,Let deploy scripts set alternate conf; work directories,SPARK_CONF_DIR is not effective in spark-submit,1,0,1
13,SPARK-697,SPARK-1296,Duplicate,RDD should be covariant in T,Make RDDs Covariant,1,1,1
14,SPARK-750,SPARK-4442,Duplicate,LocalSparkContext should be included in Spark JAR,Move common unit test utilities into their own package / module,0,1,1
15,SPARK-754,SPARK-2243,Duplicate,Multiple Spark Contexts active in a single Spark Context,Support multiple SparkContexts in the same JVM,0,0,1
16,SPARK-761,SPARK-6828,Unresolved,Print a nicer error message when incompatible Spark binaries try to talk,Spark returns misleading message when client is incompatible with server,1,1,1
17,SPARK-786,SPARK-1860,Duplicate,Clean up old work directories in standalone worker,Standalone Worker cleanup should not clean up running executors,1,0,1
18,SPARK-791,SPARK-1091,Fixed,add DenseVector and SparseVector to mllib; and replace all Array[Double] with Vectors,Cloudpickle does not work correctly for some methods that use a splat,1,0,1
19,SPARK-836,SPARK-837,Duplicate,ResultTask's serialization forget to handle generation,"ResultTask's serialization forget about handling ""generation"" field; while ShuffleMapTask does",1,0,1
20,SPARK-868,SPARK-892,Duplicate,Document fair scheduler,Add docs page for fair scheduler,1,1,1
21,SPARK-888,SPARK-5495,Duplicate,Killing jobs on standalone cluster,Offer user the ability to kill application in master web UI for standalone mode,1,1,1
22,SPARK-907,SPARK-3644,Duplicate,Add JSON endpoints to SparkUI,REST API for Spark application info (jobs / stages / tasks / storage info),0,0,1
23,SPARK-926,SPARK-5403,Duplicate,spark_ec2 script when ssh/scp-ing should pipe UserknowHostFile to /dev/null,Ignore UserKnownHostsFile in SSH calls,1,0,1
24,SPARK-926,SPARK-5403,Duplicate,spark_ec2 script when ssh/scp-ing should pipe UserknowHostFile to /dev/null,Ignore UserKnownHostsFile in SSH calls,1,0,1
25,SPARK-936,SPARK-994,Duplicate,Please publish jars for Scala 2.10,Upgrade Spark to Scala 2.10,0,1,1
26,SPARK-937,SPARK-1118,Fixed,Executors that exit cleanly should not have KILLED status,Executor state shows as KILLED even the application is finished normally,0,0,1
27,SPARK-951,SPARK-3588,Duplicate,Gaussian Mixture Model,Gaussian Mixture Model clustering,0,0,1
28,SPARK-952,SPARK-3588,Duplicate,Python version of Gaussian Mixture Model,Gaussian Mixture Model clustering,0,0,1
29,SPARK-953,SPARK-1405,Duplicate,Latent Dirichlet Association (LDA model),parallel Latent Dirichlet Allocation (LDA) atop of spark in MLlib,0,1,1
30,SPARK-958,SPARK-1006,Duplicate,When iteration in ALS increases to 10 running in local mode; spark throws out error of StackOverflowError,MLlib ALS gets stack overflow with too many iterations,0,1,1
31,SPARK-969,SPARK-1132,Duplicate,Persistent web ui,Persisting Web UI through refactoring the SparkListener interface,0,0,1
32,SPARK-981,SPARK-4592,Duplicate,"Seemingly spurious ""Duplicate worker ID"" error messages",Worker registration failed: Duplicate worker ID error during Master failover,0,0,1
33,SPARK-983,SPARK-1541,Fixed,Support external sorting for RDD#sortByKey(),sortByKey requires all data to fit in memory,1,0,1
34,SPARK-993,SPARK-1018,Won't Fix,Don't reuse Writable objects in HadoopRDDs by default,take and collect don't work on HadoopRDD,0,1,1
35,SPARK-1006,SPARK-3370,Duplicate,MLlib ALS gets stack overflow with too many iterations,The simple test error,0,1,1
36,SPARK-1010,SPARK-4893,Fixed,Update all unit tests to use SparkConf instead of system properties,Clean up uses of System.setProperty in unit tests,0,0,1
37,SPARK-1013,SPARK-1066,Fixed,Have DEVELOPERS.txt file with documentation for developers,Improve Developer Documentation,1,1,1
38,SPARK-1014,SPARK-2309,Duplicate,MultilogisticRegressionWithSGD,Generalize the binary logistic regression into multinomial logistic regression,1,0,1
39,SPARK-1018,SPARK-3693,Not A Problem,take and collect don't work on HadoopRDD,Cached Hadoop RDD always return rows with the same value,1,1,1
40,SPARK-1020,SPARK-1132,Duplicate,SparkListener interfaces should not expose internal types/objects,Persisting Web UI through refactoring the SparkListener interface,0,0,1
41,SPARK-1045,SPARK-1113,Duplicate,ExternalAppendOnlyMap Iterator throw no such element on joining two large rdd,External Spilling Bug - hash collision causes NoSuchElementException,0,0,1
42,SPARK-1047,SPARK-3490,Fixed,Ability to disable the spark ui server (unit tests),Alleviate port collisions during tests,0,0,1
43,SPARK-1047,SPARK-2100,Fixed,Ability to disable the spark ui server (unit tests),Allow users to disable Jetty Spark UI in local mode,0,0,1
44,SPARK-1067,SPARK-1190,Duplicate,Default log4j initialization causes errors for those not using log4j,Do not initialize log4j if slf4j log4j backend is not being used,0,0,1
45,SPARK-1071,SPARK-1120,Fixed,Tidy logging strategy and use of log4j,Send all dependency logging through slf4j,0,0,1
46,SPARK-1086,SPARK-6443,Duplicate,Some corner case during HA master switching?,Support HA in standalone cluster mode,0,1,1
47,SPARK-1095,SPARK-6428,Duplicate,Ensure all public methods return explicit types,"Add to style checker ""public method must have explicit type defined""",0,1,1
48,SPARK-1097,SPARK-1388,Fixed,ConcurrentModificationException,ConcurrentModificationException in hadoop_common exposed by Spark,1,1,1
49,SPARK-1127,SPARK-2447,Won't Fix,Add saveAsHBase to PairRDDFunctions,Add common solution for sending upsert actions to HBase (put; deletes; and increment),0,1,1
50,SPARK-1141,SPARK-19486,Won't Fix,Parallelize Task Serialization,Investigate using multiple threads for task serialization,0,1,1
51,SPARK-1148,SPARK-4863,Duplicate,Suggestions for exception handling (avoid potential bugs),Suspicious exception handlers,1,0,1
52,SPARK-1152,SPARK-1210,Duplicate,ArrayStoreException on mapping RDD on cluster,Prevent ContextClassLoader of Actor from becoming ClassLoader of Executor,1,1,1
53,SPARK-1153,SPARK-3799,Won't Fix,Generalize VertexId in GraphX so that UUIDs can be used as vertex IDs.,Enable String ID's for GraphX,1,1,1
54,SPARK-1154,SPARK-1860,Fixed,Spark fills up disk with app-* folders,Standalone Worker cleanup should not clean up running executors,1,0,1
55,SPARK-1159,SPARK-10465,Duplicate,Add Shortest-path computations to graphx.lib,Shortest Path between two vertices; using distance and results carries shortest path and distance,1,1,1
56,SPARK-1170,SPARK-2871,Duplicate,Add histogram() to PySpark,Missing API in PySpark,0,0,1
57,SPARK-1170,SPARK-1207,Duplicate,Add histogram() to PySpark,Make python support for histograms,0,1,1
58,SPARK-1180,SPARK-1830,Duplicate,Allow to provide a custom persistence engine,Deploy failover; Make Persistence engine and LeaderAgent Pluggable.,0,0,1
59,SPARK-1188,SPARK-1883,Fixed,GraphX triplets not working properly,spark graph.triplets does not return correct values,0,1,1
60,SPARK-1199,SPARK-1836,Fixed,Type mismatch in Spark shell when using case class defined in shell,REPL $outer type mismatch causes lookup() and equals() problems,0,0,1
61,SPARK-1199,SPARK-2330,Fixed,Type mismatch in Spark shell when using case class defined in shell,Spark shell has weird scala semantics,1,0,1
62,SPARK-1201,SPARK-1777,Duplicate,Do not materialize partitions whenever possible in BlockManager,"Pass ""cached"" blocks directly to disk if memory is not large enough",0,0,1
63,SPARK-1215,SPARK-2355,Fixed,Clustering: Index out of bounds error,Check for the number of clusters to avoid ArrayIndexOutOfBoundsException,1,1,1
64,SPARK-1216,SPARK-5888,Duplicate,Add a OneHotEncoder for handling categorical features,Add OneHotEncoder as a Transformer,0,0,1
65,SPARK-1231,SPARK-3736,Duplicate,DEAD worker should recover automaticly,Workers should reconnect to Master if disconnected,0,0,1
66,SPARK-1236,SPARK-1377,Fixed,Update Jetty to 9,Upgrade Jetty to 8.1.14v20131031,0,0,1
67,SPARK-1256,SPARK-1265,Fixed,Master web UI and Worker web UI returns a 404 error,Fix 404 not found error in UI introduced in Jetty 9.0 upgrade,0,1,1
68,SPARK-1263,SPARK-1266,Duplicate,Implicit ALS unnecessarily recomputes factor matrices,Persist factors in implicit ALS,1,1,1
69,SPARK-1271,SPARK-1320,Fixed,[STREAMING] Annotate developer and experimental API's,cogroup and groupby should pass an iterator,0,0,1
70,SPARK-1279,SPARK-1280,Duplicate,"Stage.name return  ""apply at Option.scala:120""","Stage.name return ""apply at Option.scala:120""",1,0,1
71,SPARK-1282,SPARK-1283,Duplicate,Create spark-contrib repo for 1.0,Create spark-contrib repo for 1.0,1,1,1
72,SPARK-1287,SPARK-2140,Duplicate,yarn alpha and stable Client calculateAMMemory routines are different,yarn stable client doesn't properly handle MEMORY_OVERHEAD for AM,1,1,1
73,SPARK-1297,SPARK-2720,Fixed,Upgrade HBase dependency to 0.98.0,spark-examples should depend on HBase modules for HBase 0.96+,1,1,1
74,SPARK-1300,SPARK-1357,Fixed,Clean-up and clarify private vs public fields in MLLib,[streaming] Add deployment subsection to streaming,1,0,1
75,SPARK-1301,SPARK-6447,Fixed,"Add UI elements to collapse ""Aggregated Metrics by Executor"" pane on stage page",Add quick-links to StagePage to jump to Accumulator/Task tables,1,1,1
76,SPARK-1302,SPARK-2649,Fixed,httpd doesn't start in spark-ec2 (cc2.8xlarge),EC2: Ganglia-httpd broken on hvm based machines like r3.4xlarge,1,1,1
77,SPARK-1304,SPARK-6014,Won't Fix,Job fails with spot instances (due to IllegalStateException: Shutdown in progress),java.io.IOException: Filesystem is thrown when ctrl+c or ctrl+d spark-sql on YARN ,0,1,1
78,SPARK-1309,SPARK-1429,Fixed,sbt assemble-deps no longer works,"Spark shell fails to start after ""sbt clean assemble-deps package""",1,0,1
79,SPARK-1315,SPARK-1325,Fixed,spark on yarn-alpha with mvn on master branch won't build,The maven build error for Spark Tools,1,0,1
80,SPARK-1337,SPARK-1411,Fixed,Application web UI garbage collects newest stages instead old ones,When using spark.ui.retainedStages=n only the first n stages are kept; not the most recent.,1,1,1
81,SPARK-1353,SPARK-1476,Duplicate,IllegalArgumentException when writing to disk,2GB limit in spark for blocks,0,0,1
82,SPARK-1362,SPARK-4145,Fixed,Web UI should provide page of showing statistics and stage list for a given job,Create jobs overview and job details pages on the web UI,0,1,1
83,SPARK-1363,SPARK-8360,Duplicate,Add streaming support for Spark SQL module,Structured Streaming (aka Streaming DataFrames),0,1,1
84,SPARK-1391,SPARK-6235,Duplicate,BlockManager cannot transfer blocks larger than 2G in size,Address various 2G limits,0,1,1
85,SPARK-1392,SPARK-1777,Duplicate,Local spark-shell Runs Out of Memory With Default Settings,"Pass ""cached"" blocks directly to disk if memory is not large enough",1,0,1
86,SPARK-1400,SPARK-1592,Duplicate,Spark Streaming's received data is not cleaned up from BlockManagers when not needed any more,Old streaming input blocks not removed automatically from the BlockManagers,0,0,1
87,SPARK-1407,SPARK-2906,Not A Problem,EventLogging to HDFS doesn't work properly on yarn,FileLogger throws a invocation target exception.,1,0,1
88,SPARK-1422,SPARK-4400,Won't Fix,Add scripts for launching Spark on Google Compute Engine,Add scripts for launching Spark on Google Compute Engine (GCE),0,1,1
89,SPARK-1433,SPARK-1806,Duplicate,Upgrade Mesos dependency to 0.17.0,Upgrade to Mesos 0.18.1 with Shaded Protobuf,0,0,1
90,SPARK-1435,SPARK-1480,Duplicate,Don't assume context class loader is set when creating classes via reflection,Choose classloader consistently inside of Spark codebase,1,1,1
91,SPARK-1442,SPARK-3587,Fixed,Add Window function support,Spark SQL can't support lead() over() window function,1,0,1
92,SPARK-1444,SPARK-1787,Won't Fix,Update branch-0.9's SBT to 0.13.1 so that it works with Java 8,Build failure on JDK8 :: SBT fails to load build configuration file,1,0,1
93,SPARK-1451,SPARK-2309,Duplicate,Multinomial Logistic Regression Support,Generalize the binary logistic regression into multinomial logistic regression,1,0,1
94,SPARK-1453,SPARK-1946,Duplicate,Improve the way Spark on Yarn waits for executors before starting,Submit stage after executors have been registered,0,1,1
95,SPARK-1455,SPARK-3534,Fixed,Determine which test suites to run based on code changes,Avoid running MLlib and Streaming tests when testing SQL PRs,0,0,1
96,SPARK-1462,SPARK-1464,Fixed,Examples of ML algorithms are using deprecated APIs,Update MLLib Examples to Use Breeze,0,0,1
97,SPARK-1499,SPARK-6183,Duplicate,Workers continuously produce failing executors,Skip bad workers when re-launching executors,0,1,1
98,SPARK-1513,SPARK-2190,Duplicate,Specialized ColumnType for Timestamp,Specialized ColumnType for Timestamp,1,0,1
99,SPARK-1517,SPARK-4542,Unresolved,Publish nightly snapshots of documentation; maven artifacts; and binary builds,Post nightly releases,0,0,1
100,SPARK-1520,SPARK-1718,Unresolved,Assembly Jar with more than 65536 files won't work when compiled on  JDK7 and run on JDK6,pyspark doesn't work with assembly jar containing over 65536 files/dirs built on redhat ,0,0,1
101,SPARK-1520,SPARK-3008,Unresolved,Assembly Jar with more than 65536 files won't work when compiled on  JDK7 and run on JDK6,PySpark fails due to  zipimport not able to load the assembly jar (/usr/bin/python: No module named pyspark),0,0,1
102,SPARK-1532,SPARK-2528,Fixed,provide option for more restrictive firewall rule in ec2/spark_ec2.py,Default spark-ec2 security group permissions are too open,1,1,1
103,SPARK-1534,SPARK-1641,Fixed,spark-submit for yarn prints warnings even though calling as expected ,Spark submit warning tells the user to use spark-submit,0,0,1
104,SPARK-1542,SPARK-1543,Duplicate,Add ADMM for solving Lasso (and elastic net) problem,Add ADMM for solving Lasso (and elastic net) problem,1,1,1
105,SPARK-1543,SPARK-1794,Later,Add ADMM for solving Lasso (and elastic net) problem,Generic ADMM implementation for SVM; lasso; and L1-regularized logistic regression,0,1,1
106,SPARK-1546,SPARK-2401,Unresolved,Add AdaBoost algorithm to Spark MLlib,AdaBoost.MH; a multi-class multi-label classifier,1,0,1
107,SPARK-1547,SPARK-3525,Fixed,Add gradient boosting algorithm to MLlib,Gradient boosting in MLLib,1,0,1
108,SPARK-1559,SPARK-2058,Duplicate,Add conf dir to CLASSPATH in compute-classpath.sh dependent on whether SPARK_CONF_DIR is set,SPARK_CONF_DIR should override all present configs,1,0,1
109,SPARK-1564,SPARK-1635,Fixed,Add JavaScript into Javadoc to turn ::Experimental:: and such into badges,Java API docs do not show annotation.,1,1,1
110,SPARK-1598,SPARK-1636,Duplicate,Mark main methods experimental,Move main methods to examples,1,1,1
111,SPARK-1609,SPARK-1638,Fixed,Executor fails to start when Command.extraJavaOptions contains multiple Java options,"Executors fail to come up if ""spark.executor.extraJavaOptions"" is set ",1,0,1
112,SPARK-1627,SPARK-1692,Won't Fix,Support external aggregation in Spark SQL,Enable external sorting in Spark SQL aggregates,1,0,1
113,SPARK-1647,SPARK-3129,Duplicate,Prevent data loss when Streaming driver goes down,Prevent data loss in Spark Streaming on driver failure using Write Ahead Logs,1,0,1
114,SPARK-1652,SPARK-1905,Fixed,Fixes and improvements for spark-submit/configs,Issues with `spark-submit`,0,0,1
115,SPARK-1664,SPARK-1755,Duplicate,spark-submit --name doesn't work in yarn-client mode,Spark-submit --name does not resolve to application name on YARN,0,1,1
116,SPARK-1665,SPARK-1680,Duplicate,add a config to replace SPARK_YARN_USER_ENV,Clean up use of setExecutorEnvs in SparkConf ,0,0,1
117,SPARK-1673,SPARK-1892,Duplicate,GLMNET implementation in Spark,Add an OWL-QN optimizer for L1 regularized optimizations.,1,1,1
118,SPARK-1697,SPARK-2243,Duplicate,Driver error org.apache.spark.scheduler.TaskSetManager - Loss was due to java.io.FileNotFoundException,Support multiple SparkContexts in the same JVM,0,1,1
119,SPARK-1714,SPARK-2687,Fixed,Take advantage of AMRMClient APIs to simplify logic in YarnAllocationHandler,after receving allocated containers;amClient should remove ContainerRequest.,1,1,1
120,SPARK-1756,SPARK-1796,Won't Fix,Add missing description to spark-env.sh.template,spark-submit does not set driver memory correctly,1,0,1
121,SPARK-1761,SPARK-3957,Duplicate,Add broadcast information on SparkUI storage tab,Broadcast variable memory usage not reflected in UI,0,1,1
122,SPARK-1795,SPARK-3586,Duplicate,Add recursive directory file search to fileInputStream,Support nested directories in Spark Streaming,1,0,1
123,SPARK-1800,SPARK-2214,Fixed,Add broadcast hash join operator,Broadcast Join (aka map join),1,1,1
124,SPARK-1800,SPARK-2218,Fixed,Add broadcast hash join operator,rename Equals to EqualTo in Spark SQL expressions,1,1,1
125,SPARK-1802,SPARK-1828,Fixed,Audit dependency graph when Spark is built with -Phive,Created forked version of hive-exec that doesn't bundle other dependencies,0,1,1
126,SPARK-1805,SPARK-5086,Fixed,Error launching cluster when master and slave machines are of different virtualization types,Specifying the master instance type,1,0,1
127,SPARK-1811,SPARK-2543,Duplicate,Support resizable output buffer for kryo serializer,Allow user to set maximum Kryo buffer size,1,1,1
128,SPARK-1812,SPARK-2040,Fixed,Support cross-building with Scala 2.11,[MLLIB] Univariate kernel density estimation,1,1,1
129,SPARK-1813,SPARK-4164,Fixed,Add a utility to SparkConf that makes using Kryo really easy,spark.kryo.registrator shall use comma separated value to support multiple registrator,1,1,1
130,SPARK-1825,SPARK-5164,Fixed,Windows Spark fails to work with Linux YARN,YARN | Spark job submits from windows machine to a linux YARN cluster fail,1,1,1
131,SPARK-1832,SPARK-2132,Fixed,Executor UI improvement suggestions,Color GC time red when over a percentage of task time,1,0,1
132,SPARK-1834,SPARK-3266,Duplicate,NoSuchMethodError when invoking JavaPairRDD.reduce() in Java,JavaDoubleRDD doesn't contain max(),0,1,1
133,SPARK-1849,SPARK-6316,Won't Fix,sc.textFile does not support non UTF-8 encodings,"add a parameter for  SparkContext(conf).textFile() method ; support for multi-language  hdfs file ;   e.g. ""gbk""",1,1,1
134,SPARK-1855,SPARK-7292,Fixed,Provide memory-and-local-disk RDD checkpointing,Provide operator to truncate lineage without persisting RDD's,0,1,1
135,SPARK-1863,SPARK-5358,Unresolved,Allowing user jars to take precedence over Spark jars does not work as expected,spark.files.userClassPathFirst doesn't work correctly,1,0,1
136,SPARK-1888,SPARK-3000,Duplicate,enhance MEMORY_AND_DISK mode by dropping blocks in parallel,Drop old blocks to disk in parallel when memory is not large enough for caching new blocks,0,1,1
137,SPARK-1920,SPARK-6869,Duplicate,Spark JAR compiled with Java 7 leads to PySpark not working in YARN,Add pyspark archives path to PYTHONPATH,0,1,1
138,SPARK-1927,SPARK-5150,Duplicate,Implicits declared in companion objects not found in Spark shell,Strange implicit resolution behavior in Spark REPL,1,1,1
139,SPARK-1950,SPARK-1951,Duplicate,spark on yarn can't start ,spark on yarn can't start ,1,1,1
140,SPARK-1953,SPARK-5861,Fixed,yarn client mode Application Master memory size is same as driver memory size,generalize the type of categoricalFeaturesInfo to PartialFunction[Int; Int],1,1,1
141,SPARK-1954,SPARK-2026,Duplicate,Make it easier to get Spark on YARN code to compile in IntelliJ,"Maven ""hadoop*"" Profiles Should Set the expected Hadoop Version.",1,1,1
142,SPARK-2002,SPARK-4454,Duplicate,Race condition in accessing cache locations in DAGScheduler,Race condition in DAGScheduler,0,0,1
143,SPARK-2015,SPARK-8667,Done,Spark UI issues at scale,Improve Spark UI behavior at scale,1,1,1
144,SPARK-2017,SPARK-7716,Fixed,web ui stage page becomes unresponsive when the number of tasks is large,SparkUI stage page hangs with many tasks,1,0,1
145,SPARK-2020,SPARK-2022,Duplicate,Spark 1.0.0 fails to run in coarse-grained mesos mode,Spark 1.0.0 is failing if mesos.coarse set to true,1,0,1
146,SPARK-2021,SPARK-2538,Duplicate,External hashing in PySpark,External aggregation in Python,1,0,1
147,SPARK-2027,SPARK-2913,Duplicate,spark-ec2 puts Hadoop's log4j ahead of Spark's in classpath,Spark's log4j.properties should always appear ahead of Hadoop's on classpath,0,1,1
148,SPARK-2051,SPARK-2139,Fixed,spark.yarn.dist.* configs are not supported in yarn-cluster mode,spark.yarn.dist.* configs are not documented,1,1,1
149,SPARK-2063,SPARK-3414,Fixed,Creating a SchemaRDD via sql() does not correctly resolve nested types,Case insensitivity breaks when unresolved relation contains attributes with uppercase letters in their names,1,0,1
150,SPARK-2064,SPARK-8172,Duplicate,web ui should not remove executors if they are dead,Driver UI should enable viewing of dead executors' logs,1,1,1
151,SPARK-2082,SPARK-2512,Fixed,Stratified sampling implementation in PairRDDFunctions,Stratified sampling,1,1,1
152,SPARK-2087,SPARK-3552,Fixed,Clean Multi-user semantics for thrift JDBC/ODBC server.,Thrift server doesn't reset current database for each connection,1,0,1
153,SPARK-2087,SPARK-6757,Fixed,Clean Multi-user semantics for thrift JDBC/ODBC server.,spark.sql.shuffle.partitions is global; not per connection,1,0,1
154,SPARK-2087,SPARK-4815,Fixed,Clean Multi-user semantics for thrift JDBC/ODBC server.,ThriftServer use only one SessionState to run sql using hive ,1,0,1
155,SPARK-2114,SPARK-2926,Duplicate,groupByKey and joins on raw data,Add MR-style (merge-sort) SortShuffleReader for sort-based shuffle,0,1,1
156,SPARK-2114,SPARK-4550,Duplicate,groupByKey and joins on raw data,In sort-based shuffle; store map outputs in serialized form,1,0,1
157,SPARK-2122,SPARK-2124,Duplicate,Move aggregation into shuffle implementation,Move aggregation into ShuffleManager implementations,1,1,1
158,SPARK-2127,SPARK-3377,Duplicate,Use application specific folders to dump metrics via CsvSink,Metrics can be accidentally aggregated against our intention,1,0,1
159,SPARK-2152,SPARK-2160,Fixed,the error of comput rightNodeAgg about  Decision tree algorithm  in Spark MLlib ,error of  Decision tree algorithm  in Spark MLlib ,0,1,1
160,SPARK-2175,SPARK-4170,Duplicate,Null values when using App trait.,"Closure problems when running Scala app that ""extends App""",1,0,1
161,SPARK-2179,SPARK-2276,Fixed,Public API for DataTypes and Schema,user should be able to provide schema for table creation,1,0,1
162,SPARK-2215,SPARK-3862,Later,Multi-way join,MultiWayBroadcastInnerHashJoin,1,0,1
163,SPARK-2216,SPARK-16026,Later,Cost-based join reordering,Cost-based Optimizer Framework,1,1,1
164,SPARK-2220,SPARK-2227,Fixed,Fix remaining Hive Commands,"Support ""dfs"" command",1,0,1
165,SPARK-2221,SPARK-5754,Duplicate,Spark fails on windows YARN (HortonWorks 2.4),Spark AM not launching on Windows,0,1,1
166,SPARK-2223,SPARK-3431,Duplicate,Building and running tests with maven is extremely slow,Parallelize Scala/Java test execution,1,1,1
167,SPARK-2226,SPARK-2589,Fixed,HAVING should be able to contain aggregate expressions that don't appear in the aggregation list. ,Support HAVING clause generated by Tableau,1,1,1
168,SPARK-2228,SPARK-2316,Duplicate,onStageSubmitted does not properly called so NoSuchElement will be thrown in onStageCompleted,StorageStatusListener should avoid O(blocks) operations,0,0,1
169,SPARK-2242,SPARK-2244,Fixed,Running sc.parallelize(..).count() hangs pyspark,pyspark - RDD action hangs (after previously succeeding),1,0,1
170,SPARK-2242,SPARK-2244,Fixed,Running sc.parallelize(..).count() hangs pyspark,pyspark - RDD action hangs (after previously succeeding),1,0,1
171,SPARK-2243,SPARK-2556,Won't Fix,Support multiple SparkContexts in the same JVM,Multiple SparkContexts can coexist in one process,0,0,1
172,SPARK-2247,SPARK-5097,Duplicate,Data frame (or Pandas) like API for structured data,Adding data frame APIs to SchemaRDD,0,0,1
173,SPARK-2272,SPARK-2776,Fixed,Feature scaling which standardizes the range of independent variables or features of data.,Add normalizeByCol method to mllib.util.MLUtils,0,0,1
174,SPARK-2290,SPARK-2454,Duplicate,Do not send SPARK_HOME from driver to executors,Separate driver spark home from executor spark home,1,1,1
175,SPARK-2290,SPARK-2454,Duplicate,Do not send SPARK_HOME from driver to executors,Separate driver spark home from executor spark home,1,1,1
176,SPARK-2308,SPARK-14174,Won't Fix,Add KMeans MiniBatch clustering algorithm to MLlib,Implement the Mini-Batch KMeans,0,0,1
177,SPARK-2316,SPARK-3882,Fixed,StorageStatusListener should avoid O(blocks) operations,JobProgressListener gets permanently out of sync with long running job,0,0,1
178,SPARK-2321,SPARK-2633,Fixed,Design a proper progress reporting & event listener API,enhance spark listener API to gather more spark job information,0,1,1
179,SPARK-2325,SPARK-2974,Duplicate,Utils.getLocalDir had better check the directory and choose a good one instead of choosing the first one directly,Utils.getLocalDir() may return non-existent spark.local.dir directory,1,0,1
180,SPARK-2326,SPARK-2723,Duplicate,DiskBlockManager could add DiskChecker function for kicking off bad directories,Block Manager should catch exceptions in putValues,0,1,1
181,SPARK-2335,SPARK-2336,Duplicate,k-Nearest Neighbor classification and regression for MLLib,Approximate k-NN Models for MLLib,1,1,1
182,SPARK-2351,SPARK-2352,Duplicate,Add Artificial Neural Network (ANN) to Spark,"In ""local[N]""; free cores of the only executor should be touched by ""spark.task.cpus"" for every finish/start-up of tasks.",1,1,1
183,SPARK-2352,SPARK-5575,Duplicate,"In ""local[N]""; free cores of the only executor should be touched by ""spark.task.cpus"" for every finish/start-up of tasks.",Artificial neural networks for MLlib deep learning,1,1,1
184,SPARK-2352,SPARK-9273,Duplicate,"In ""local[N]""; free cores of the only executor should be touched by ""spark.task.cpus"" for every finish/start-up of tasks.",Add Convolutional Neural network to Spark MLlib,1,1,1
185,SPARK-2352,SPARK-9129,Duplicate,"In ""local[N]""; free cores of the only executor should be touched by ""spark.task.cpus"" for every finish/start-up of tasks.",Integrate convolutional deep belief networks for visual recognition tasks  ,1,1,1
186,SPARK-2353,SPARK-2931,Fixed,ArrayIndexOutOfBoundsException in scheduler,getAllowedLocalityLevel() throws ArrayIndexOutOfBoundsException,1,1,1
187,SPARK-2356,SPARK-6961,Duplicate,Exception: Could not locate executable null\bin\winutils.exe in the Hadoop ,Cannot save data to parquet files when executing from Windows from a Maven Project,0,1,1
188,SPARK-2356,SPARK-9638,Duplicate,Exception: Could not locate executable null\bin\winutils.exe in the Hadoop ,.save() Procedure fails,0,0,1
189,SPARK-2356,SPARK-14727,Duplicate,Exception: Could not locate executable null\bin\winutils.exe in the Hadoop ,NullPointerException while trying to launch local spark job,0,0,1
190,SPARK-2360,SPARK-2378,Won't Fix,CSV import to SchemaRDDs,Implement functionality to read csv files,0,0,1
191,SPARK-2383,SPARK-2492,Duplicate,With auto.offset.reset; KafkaReceiver potentially deletes Consumer nodes from Zookeeper,KafkaReceiver minor changes to align with Kafka 0.8 ,1,0,1
192,SPARK-2389,SPARK-4895,Won't Fix,"globally shared SparkContext / shared Spark ""application""",Support a shared RDD store among different Spark contexts,0,1,1
193,SPARK-2398,SPARK-3768,Duplicate,Trouble running Spark 1.0 on Yarn ,Modify default YARN memory_overhead-- from an additive constant to a multiplier,0,1,1
194,SPARK-2421,SPARK-2442,Won't Fix,Spark should treat writable as serializable for keys,Add a Hadoop Writable serializer,0,1,1
195,SPARK-2424,SPARK-16956,Duplicate,ApplicationState.MAX_NUM_RETRY should be configurable,Make ApplicationState.MAX_NUM_RETRY configurable,0,1,1
196,SPARK-2429,SPARK-6517,Duplicate,Hierarchical Implementation of KMeans,Bisecting k-means clustering,1,1,1
197,SPARK-2432,SPARK-4001,Duplicate,Apriori algorithm for frequent itemset mining,Add FP-growth algorithm to Spark MLlib,1,1,1
198,SPARK-2445,SPARK-3535,Duplicate,MesosExecutorBackend crashes in fine grained mode,Spark on Mesos not correctly setting heap overhead,1,1,1
199,SPARK-2445,SPARK-3817,Duplicate,MesosExecutorBackend crashes in fine grained mode,BlockManagerMasterActor: Got two different block manager registrations with Mesos,1,1,1
200,SPARK-2448,SPARK-2474,Duplicate,"Table name is not getting applied to their attributes after ""registerAsTable""","For a registered table in OverrideCatalog; the Analyzer failed to resolve references in the format of ""tableName.fieldName""",1,1,1
201,SPARK-2450,SPARK-5736,Fixed,Provide link to YARN executor logs on UI,Add executor log url to Executors page on Yarn,0,1,1
202,SPARK-2452,SPARK-2453,Fixed,Multi-statement input to spark repl does not work,Compound lines in spark-shell cause compilation errors,1,0,1
203,SPARK-2463,SPARK-6077,Duplicate,Creating then stopping StreamingContext multiple times from shell generates duplicate Streaming tabs in UI,Multiple spark streaming tabs on UI when reuse the same sparkcontext,1,0,1
204,SPARK-2465,SPARK-4303,Won't Fix,Use long as user / item ID for ALS,JavaRDDLike.groupBy[K](f: JFunction[T; K]) may fail with typechecking errors,1,0,1
205,SPARK-2484,SPARK-2644,Fixed,Build should not run hive compatibility tests by default.,Hive should not be enabled by default in the build.,1,1,1
206,SPARK-2488,SPARK-2495,Duplicate,Model SerDe in MLlib,Ability to re-create ML models,1,1,1
207,SPARK-2489,SPARK-21666,Unresolved,Unsupported parquet datatype optional fixed_len_byte_array,Cannot handle Parquet type FIXED_LEN_BYTE_ARRAY,1,1,1
208,SPARK-2541,SPARK-3438,Unresolved,Standalone mode can't access secure HDFS anymore,Support for accessing secured HDFS in Standalone Mode,0,1,1
209,SPARK-2562,SPARK-3407,Duplicate,Add Date datatype support to Spark SQL,Add Date type support,1,0,1
210,SPARK-2572,SPARK-7439,Duplicate,Can't delete local dir on executor automatically when running spark over Mesos.,Should delete temporary local directories,0,1,1
211,SPARK-2578,SPARK-2998,Fixed,OUTER JOINs cause ClassCastException,scala.collection.mutable.HashSet cannot be cast to scala.collection.mutable.BitSet,1,0,1
212,SPARK-2579,SPARK-5917,Cannot Reproduce,Reading from S3 returns an inconsistent number of items with Spark 0.9.1,Distinct is broken,0,0,1
213,SPARK-2585,SPARK-4083,Won't Fix,Remove special handling of Hadoop JobConf,Remove all unnecessary broadcasts,0,0,1
214,SPARK-2590,SPARK-2591,Fixed,Add config property to disable incremental collection used in Thrift server,Add config property to disable incremental collection used in Thrift server,1,0,1
215,SPARK-2608,SPARK-2921,Fixed,Mesos doesn't handle spark.executor.extraJavaOptions correctly (among other things),Mesos doesn't handle spark.executor.extraJavaOptions correctly (among other things),1,1,1
216,SPARK-2611,SPARK-3405,Duplicate,VPC Issue while creating an ec2 cluster,EC2 cluster creation on VPC,0,0,1
217,SPARK-2620,SPARK-5149,Unresolved,case class cannot be used as key for reduce,Type mismatch when defining classes in Spark REPL,1,1,1
218,SPARK-2620,SPARK-9621,Unresolved,case class cannot be used as key for reduce,Closure inside RDD doesn't properly close over environment,0,0,1
219,SPARK-2623,SPARK-10408,Duplicate,Stacked Auto Encoder (Deep Learning ),Autoencoder,0,1,1
220,SPARK-2630,SPARK-4092,Duplicate,Input data size of CoalescedRDD is incorrect,Input metrics don't work for coalesce()'d RDD's,0,0,1
221,SPARK-2677,SPARK-2681,Fixed,BasicBlockFetchIterator#next can wait forever,Spark can hang when fetching shuffle blocks,1,1,1
222,SPARK-2678,SPARK-2894,Fixed,`Spark-submit` overrides user application options,spark-shell doesn't accept flags,0,1,1
223,SPARK-2678,SPARK-2880,Fixed,`Spark-submit` overrides user application options,spark-submit processes app cmdline options,0,0,1
224,SPARK-2686,SPARK-3354,Fixed,Add Length support to Spark SQL and HQL and Strlen support to SQL,Add LENGTH and DATALENGTH functions to Spark SQL,1,0,1
225,SPARK-2690,SPARK-7019,Duplicate,Make unidoc part of our test process,Build docs on doc changes,0,0,1
226,SPARK-2699,SPARK-2927,Duplicate,Improve compatibility with parquet file/table,Add a conf to configure if we always read Binary columns stored in Parquet as String columns,1,1,1
227,SPARK-2702,SPARK-2732,Fixed,Upgrade Tachyon dependency to 0.5.0,Update build script to Tachyon 0.5.0,1,1,1
228,SPARK-2702,SPARK-2733,Fixed,Upgrade Tachyon dependency to 0.5.0,Update make-distribution.sh to download Tachyon 0.5.0,1,1,1
229,SPARK-2702,SPARK-2731,Fixed,Upgrade Tachyon dependency to 0.5.0,Update Tachyon dependency to 0.5.0,1,1,1
230,SPARK-2707,SPARK-2805,Fixed,Upgrade to Akka 2.3,Update akka to version 2.3.4,0,1,1
231,SPARK-2719,SPARK-2757,Duplicate,Add Mima binary checks to Flume-Sink,Add Mima test for Spark Sink after 1.1.0 is released,1,0,1
232,SPARK-2722,SPARK-2914,Won't Fix,Mechanism for escaping spark configs is not consistent,spark.*.extraJavaOptions are evaluated too many times,1,0,1
233,SPARK-2754,SPARK-4506,Duplicate,Document standalone-cluster mode now that it's working,Update documentation to clarify whether standalone-cluster mode is now officially supported,1,1,1
234,SPARK-2755,SPARK-6235,Duplicate,TorrentBroadcast cannot broadcast very large objects,Address various 2G limits,0,1,1
235,SPARK-2775,SPARK-6898,Duplicate,HiveContext does not support dots in column names. ,Special chars in column names is broken,1,1,1
236,SPARK-2788,SPARK-4382,Won't Fix,Add location filtering to Twitter streams,Add locations parameter to Twitter Stream,1,0,1
237,SPARK-2788,SPARK-13065,Won't Fix,Add location filtering to Twitter streams,streaming-twitter pass twitter4j.FilterQuery argument to TwitterUtils.createStream(),1,1,1
238,SPARK-2788,SPARK-7166,Won't Fix,Add location filtering to Twitter streams,Add filter by location boundingbox in TwitterInputDStream.scala,1,0,1
239,SPARK-2788,SPARK-3182,Won't Fix,Add location filtering to Twitter streams,Twitter Streaming Geoloaction Filter,1,0,1
240,SPARK-2817,SPARK-2847,Fixed,"add  ""show create table"" support","SPARK SQL Hive misses ""SHOW CREATE TABLE"" command",1,1,1
241,SPARK-2823,SPARK-5351,Fixed,GraphX jobs throw IllegalArgumentException,Can't zip RDDs with unequal numbers of partitions in ReplicatedVertexView.upgrade(),1,1,1
242,SPARK-2863,SPARK-8947,Duplicate,Emulate Hive type coercion in native reimplementations of Hive functions,Improve expression type coercion; casting & checking,1,1,1
243,SPARK-2872,SPARK-3557,Won't Fix,Fix conflict between code and doc in YarnClientSchedulerBackend,Yarn client config prioritization is backwards,1,1,1
244,SPARK-2873,SPARK-3056,Fixed,Support disk spilling in Spark SQL aggregation,Sort-based Aggregation,1,0,1
245,SPARK-2873,SPARK-6104,Fixed,Support disk spilling in Spark SQL aggregation,spark SQL shuffle OOM,0,0,1
246,SPARK-2878,SPARK-3070,Fixed,Inconsistent Kryo serialisation with custom Kryo Registrator,Kryo deserialization without using the custom registrator,1,0,1
247,SPARK-2883,SPARK-3720,Fixed,Spark Support for ORCFile format,support ORC in spark sql,0,0,1
248,SPARK-2891,SPARK-2898,Duplicate,Daemon failed to launch worker,Failed to connect to daemon,1,0,1
249,SPARK-2897,SPARK-2928,Fixed,"org.apache.spark.broadcast.TorrentBroadcast does use the serializer class specified in the spark option ""spark.serializer""",TorrentBroadcast should use the user specified serializer,1,1,1
250,SPARK-2913,SPARK-4997,Unresolved,Spark's log4j.properties should always appear ahead of Hadoop's on classpath,Check if Spark's conf needs to be put ahead of Hadoop's (for log4j purposes),0,0,1
251,SPARK-2933,SPARK-3107,Fixed,Refactor and cleanup Yarn AM code,Don't pass null jar to executor in yarn-client mode,1,0,1
252,SPARK-2946,SPARK-3183,Duplicate,Allow specifying * for --num-executors in YARN,Add option for requesting full YARN cluster,0,0,1
253,SPARK-2947,SPARK-3224,Duplicate,DAGScheduler resubmit the stage into an infinite loop,FetchFailed stages could show up multiple times in failed stages in web ui,0,1,1
254,SPARK-2947,SPARK-3224,Duplicate,DAGScheduler resubmit the stage into an infinite loop,FetchFailed stages could show up multiple times in failed stages in web ui,0,1,1
255,SPARK-2960,SPARK-3482,Fixed,Spark executables fail to start via symlinks,Allow symlinking to scripts (spark-shell; spark-submit; ...),0,0,1
256,SPARK-2973,SPARK-8094,Later,Use LocalRelation for all ExecutedCommands; avoid job for take/collect(),Calling take on ExecutedCommand and OneRowRelation should not trigger job execution,1,1,1
257,SPARK-2980,SPARK-3964,Duplicate,Python support for chi-squared test,Python API for Hypothesis testing ,1,1,1
258,SPARK-2996,SPARK-4739,Fixed,Standalone and Yarn have different settings for adding the user classpath first,Add inferSchema support for RDD[Map[String; Any]],0,1,1
259,SPARK-2996,SPARK-5358,Fixed,Standalone and Yarn have different settings for adding the user classpath first,spark.files.userClassPathFirst doesn't work correctly,0,1,1
260,SPARK-2996,SPARK-3053,Fixed,Standalone and Yarn have different settings for adding the user classpath first,Reconcile spark.files.userClassPathFirst with spark.yarn.user.classpath.first,0,1,1
261,SPARK-3024,SPARK-3454,Duplicate,CLI interface to Driver,Expose JSON representation of data shown in WebUI,0,1,1
262,SPARK-3032,SPARK-3656,Fixed,Potential bug when running sort-based shuffle with sorting using TimSort,IllegalArgumentException when I using sort-based shuffle,1,0,1
263,SPARK-3039,SPARK-3965,Fixed,Spark assembly for new hadoop API (hadoop 2) contains avro-mapred for hadoop 1 API,Spark assembly for hadoop2 contains avro-mapred for hadoop1,0,0,1
264,SPARK-3066,SPARK-4231,Fixed,Support recommendAll in matrix factorization model,Add RankingMetrics to examples.MovieLensALS,0,0,1
265,SPARK-3080,SPARK-19600,Cannot Reproduce,ArrayIndexOutOfBoundsException in ALS for Large datasets,ArrayIndexOutOfBoundsException in ALS,1,0,1
266,SPARK-3153,SPARK-5418,Unresolved,shuffle will run out of space when disks have different free space,Output directory for shuffle should consider left space of each directory set in conf,1,0,1
267,SPARK-3155,SPARK-9190,Unresolved,Support DecisionTree pruning,CLONE - Support DecisionTree pruning,1,0,1
268,SPARK-3188,SPARK-3189,Won't Fix,Add Robust Regression Algorithm with Tukey bisquare weight  function (Biweight Estimates) ,Add Robust Regression Algorithm with Turkey bisquare weight  function (Biweight Estimates) ,1,0,1
269,SPARK-3190,SPARK-10228,Fixed,Creation of large graph(> 2.15 B nodes) seems to be broken:possible overflow somewhere ,Integer overflow in VertexRDDImpl.count,1,0,1
270,SPARK-3200,SPARK-13634,Won't Fix,Class defined with reference to external variables crashes in REPL.,Assigning spark context to variable results in serialization error,1,0,1
271,SPARK-3200,SPARK-4165,Won't Fix,Class defined with reference to external variables crashes in REPL.,Using Companion Objects throws ambiguous reference error in REPL when an instance of Class is initialized,1,1,1
272,SPARK-3203,SPARK-6299,Duplicate,ClassNotFoundException in spark-shell with Cassandra,ClassNotFoundException in standalone mode when running groupByKey with class defined in REPL.,0,1,1
273,SPARK-3220,SPARK-6706,Unresolved,K-Means clusterer should perform K-Means initialization in parallel,kmeans|| hangs for a long time if both k and vector dimension are large,1,1,1
274,SPARK-3228,SPARK-5829,Won't Fix,When DStream save RDD to hdfs ; don't create directory and empty file if there are no data received from source in the batch duration .,JavaStreamingContext.fileStream run task loop repeated  empty when no more new files found,1,0,1
275,SPARK-3249,SPARK-12047,Fixed,Fix links in ScalaDoc that cause warning messages in `sbt/sbt unidoc`,Unhelpful error messages generated by JavaDoc while doing sbt unidoc,0,0,1
276,SPARK-3262,SPARK-4239,Duplicate,CREATE VIEW is not supported but the error message is not clear,support view in HiveQL,1,1,1
277,SPARK-3276,SPARK-6061,Fixed,Provide a API to specify MIN_REMEMBER_DURATION for files to consider as input in streaming,File source dstream can not include the old file which timestamp is before the system time,1,0,1
278,SPARK-3284,SPARK-6961,Duplicate,saveAsParquetFile not working on windows,Cannot save data to parquet files when executing from Windows from a Maven Project,0,0,1
279,SPARK-3293,SPARK-3627,Duplicate,"yarn's web show ""SUCCEEDED"" when the driver throw a exception in yarn-client",spark on yarn reports success even though job fails,1,0,1
280,SPARK-3323,SPARK-3742,Fixed,yarn website's Tracking UI links to the Standby RM,Link to Spark UI sometimes fails when using H/A RM's,1,1,1
281,SPARK-3336,SPARK-3855,Duplicate,[SQL] bug in CaseWhen resolve,Binding Exception when running PythonUDFs,1,1,1
282,SPARK-3337,SPARK-4275,Fixed,Paranoid quoting in shell to allow install dirs with spaces within.,./sbt/sbt assembly command fails if path has <space> in the name,0,0,1
283,SPARK-3348,SPARK-5190,Duplicate,Support user-defined SparkListeners properly,Allow spark listeners to be added before spark context gets initialized.,1,1,1
284,SPARK-3355,SPARK-5541,Fixed,Allow running maven tests in run-tests,Allow running Maven or SBT in run-tests,0,1,1
285,SPARK-3359,SPARK-12047,Fixed,`sbt/sbt unidoc` doesn't work with Java 8,Unhelpful error messages generated by JavaDoc while doing sbt unidoc,1,0,1
286,SPARK-3374,SPARK-12343,Duplicate,Spark on Yarn remove deprecated configs for 2.0,Remove YARN Client / ClientArguments,1,1,1
287,SPARK-3379,SPARK-6829,Duplicate,Implement 'POWER' for sql,Support math functions in DataFrames,1,0,1
288,SPARK-3416,SPARK-3435,Duplicate,Add matrix operations for large data set,Distributed matrix multiplication,1,1,1
289,SPARK-3435,SPARK-3975,Duplicate,Distributed matrix multiplication,Block Matrix addition and multiplication,1,1,1
290,SPARK-3438,SPARK-5158,Duplicate,Support for accessing secured HDFS in Standalone Mode,Allow for keytab-based HDFS security in Standalone mode,0,0,1
291,SPARK-3444,SPARK-7260,Fixed,Provide a way to easily change the log level in the Spark shell while running,Support changing Spark's log level programatically,0,1,1
292,SPARK-3457,SPARK-4952,Duplicate,ConcurrentModificationException starting up pyspark,Handle ConcurrentModificationExceptions in SparkEnv.environmentDetails ,0,1,1
293,SPARK-3482,SPARK-4162,Duplicate,Allow symlinking to scripts (spark-shell; spark-submit; ...),Make scripts symlinkable ,0,0,1
294,SPARK-3495,SPARK-3498,Fixed,Block replication fails continuously when the replication target node is dead,Block always replicated to the same node,0,0,1
295,SPARK-3512,SPARK-5004,Duplicate,yarn-client through socks proxy,PySpark does not handle SOCKS proxy,0,1,1
296,SPARK-3548,SPARK-4351,Won't Fix,Display cache hit ratio on WebUI,Record cacheable RDD reads and display RDD miss rates,0,0,1
297,SPARK-3558,SPARK-4180,Duplicate,Throw exception for concurrently-running SparkContexts / StreamingContexts in the same JVM,SparkContext constructor should throw exception if another SparkContext is already running,1,0,1
298,SPARK-3559,SPARK-3823,Fixed,appendReadColumnIDs and appendReadColumnNames introduce unnecessary columns in the lists of needed column ids and column names stored in hiveConf,Spark Hive SQL readColumn is not reset each time for a new query,1,0,1
299,SPARK-3561,SPARK-12892,Won't Fix,Allow for pluggable execution contexts in Spark,Support plugging in Spark scheduler ,1,1,1
300,SPARK-3563,SPARK-5836,Duplicate,Shuffle data not always be cleaned,Highlight in Spark documentation that by default Spark does not delete its temporary files,0,0,1
301,SPARK-3577,SPARK-7413,Fixed,Add task metric to report spill time,Time to write shuffle spill files is not captured in ShuffleWriteMetrics,0,0,1
302,SPARK-3588,SPARK-4156,Duplicate,Gaussian Mixture Model clustering,Add expectation maximization for Gaussian mixture models to MLLib clustering,0,1,1
303,SPARK-3607,SPARK-5375,Fixed,ConnectionManager threads.max configs on the thread pools don't work,Specify more clearly about the max thread meaning in the ConnectionManager,0,0,1
304,SPARK-3613,SPARK-4909,Fixed,Don't record the size of each shuffle block for large jobs,Error communicating with MapOutputTracker when run a big spark job,0,1,1
305,SPARK-3625,SPARK-4094,Won't Fix,In some cases; the RDD.checkpoint does not work,checkpoint should still be available after rdd actions,1,1,1
306,SPARK-3627,SPARK-4647,Fixed,spark on yarn reports success even though job fails,yarn-client mode reports success even though job fails,1,0,1
307,SPARK-3630,SPARK-6977,Done,Identify cause of Kryo+Snappy PARSING_ERROR,PARSING_ERROR(2)  in Spark Streaming,0,1,1
308,SPARK-3630,SPARK-3743,Done,Identify cause of Kryo+Snappy PARSING_ERROR,noisy logging when context is stopped,1,0,1
309,SPARK-3662,SPARK-4348,Duplicate,Importing pandas breaks included pi.py example,pyspark.mllib.random conflicts with random module,0,0,1
310,SPARK-3665,SPARK-11919,Workaround,Java API for GraphX,graphx should be supported with java,0,1,1
311,SPARK-3675,SPARK-6049,Fixed,Allow starting JDBC server on an existing context,HiveThriftServer2 may expose Inheritable methods,1,0,1
312,SPARK-3678,SPARK-5222,Duplicate,Yarn app name reported in RM is different between cluster and client mode,YARN client and cluster modes have different app name behaviors,1,0,1
313,SPARK-3692,SPARK-4638,Duplicate,RBF Kernel implementation to SVM,Spark's MLlib SVM classification to include Kernels like Gaussian / (RBF) to find non linear boundaries,1,0,1
314,SPARK-3694,SPARK-5307,Duplicate,Allow printing object graph of tasks/RDD's with a debug flag,Add utility to help with NotSerializableException debugging,1,1,1
315,SPARK-3719,SPARK-4168,Duplicate,"Spark UI: ""complete/failed stages"" is better to show the total number of stages ",Completed Stages Number are misleading webUI when stages are more than 1000,1,0,1
316,SPARK-3727,SPARK-4736,Unresolved,Trees and ensembles: More prediction functionality,functions returning the category with weights,1,1,1
317,SPARK-3733,SPARK-4924,Duplicate,Support for programmatically submitting Spark jobs,Factor out code to launch Spark applications into a separate library,0,1,1
318,SPARK-3754,SPARK-5297,Duplicate,Spark Streaming fileSystem API is not callable from Java,JavaStreamingContext.fileStream won't work because type info isn't propagated,1,0,1
319,SPARK-3755,SPARK-4334,Fixed,Do not bind port 1 - 1024 to server in spark,Utils.startServiceOnPort should check whether the tryPort is less than 1024,1,0,1
320,SPARK-3778,SPARK-7110,Fixed,newAPIHadoopRDD doesn't properly pass credentials for secure hdfs on yarn,"when use saveAsNewAPIHadoopFile; sometimes it throws ""Delegation Token can be issued only with kerberos or web authentication""",0,0,1
321,SPARK-3780,SPARK-3837,Fixed,YarnAllocator should look at the container completed diagnostic message,Warn when YARN is killing containers for exceeding memory limits,1,1,1
322,SPARK-3784,SPARK-3785,Duplicate,Support off-loading computations to a GPU,Support off-loading computations to a GPU,1,1,1
323,SPARK-3785,SPARK-5705,Later,Support off-loading computations to a GPU,Explore GPU-accelerated Linear Algebra Libraries,1,1,1
324,SPARK-3785,SPARK-12620,Later,Support off-loading computations to a GPU,Proposal of GPU exploitation for Spark,0,0,1
325,SPARK-3788,SPARK-4712,Fixed,Yarn dist cache code is not friendly to HDFS HA; Federation,uploading jar when set spark.yarn.jar ,1,1,1
326,SPARK-3808,SPARK-3879,Fixed,PySpark fails to start in Windows,"spark-shell.cmd fails giving error ""!=x was unexpected at this time""",0,0,1
327,SPARK-3821,SPARK-4958,Won't Fix,Develop an automated way of creating Spark images (AMI; Docker; and others),Bake common tools like ganglia into Spark AMI,0,0,1
328,SPARK-3839,SPARK-4483,Duplicate,Reimplement HashOuterJoin to construct hash table of only one relation,Optimization about reduce memory costs during the HashOuterJoin,1,0,1
329,SPARK-3846,SPARK-5707,Duplicate,[PYSPARK] PySpark's sample methods do not work with NumPy 1.9,Enabling spark.sql.codegen throws ClassNotFound exception,1,1,1
330,SPARK-3849,SPARK-8806,Done,Automate remaining Spark Code Style Guide rules,run-tests scala style must fail if it does not adhere to Spark Code Style Guide,0,1,1
331,SPARK-3859,SPARK-5931,Duplicate,Use consistent config names for duration (with units!),Use consistent naming for time properties,1,1,1
332,SPARK-3877,SPARK-11854,Fixed,The exit code of spark-submit is still 0 when an yarn application fails,The exit code of spark-submit is still 0 when an yarn application fails,1,1,1
333,SPARK-3884,SPARK-4299,Fixed,If deploy mode is cluster; --driver-memory shouldn't apply to client JVM,In spark-submit; the driver-memory value is used for the SPARK_SUBMIT_DRIVER_MEMORY value,0,1,1
334,SPARK-3884,SPARK-9088,Fixed,If deploy mode is cluster; --driver-memory shouldn't apply to client JVM,spark-class should ignore driver-memory when running in YARN cluster mode.,0,1,1
335,SPARK-3891,SPARK-4263,Fixed,Support Hive Percentile UDAF with array of percentile values,PERCENTILE is not working,1,0,1
336,SPARK-3939,SPARK-4037,Duplicate,NPE caused by SessionState.out not set in thriftserver2,NPE in JDBC server when calling SET,1,0,1
337,SPARK-3951,SPARK-3962,Duplicate,Make the external-* jars fat jars,"Mark spark dependency as ""provided"" in external libraries",0,0,1
338,SPARK-3956,SPARK-6100,Duplicate,Python API for Distributed Matrix,Distributed linear algebra in PySpark/MLlib,1,1,1
339,SPARK-3970,SPARK-4091,Fixed,Remove duplicate removal of local dirs,Occasionally spark.local.dir can be deleted twice and causes test failure,0,1,1
340,SPARK-3972,SPARK-6961,Cannot Reproduce,PySpark Error on Windows with sc.wholeTextFiles,Cannot save data to parquet files when executing from Windows from a Maven Project,0,0,1
341,SPARK-4001,SPARK-6381,Fixed,Add FP-growth algorithm to Spark MLlib,add Apriori algorithm to MLLib,1,1,1
342,SPARK-4025,SPARK-4141,Fixed,Don't show accumulator values in the task table on the stage detail page when there are no accumulators,Hide Accumulators column on stage page when no accumulators exist,1,1,1
343,SPARK-4037,SPARK-4103,Fixed,NPE in JDBC server when calling SET,Clean up SessionState in HiveContext,1,0,1
344,SPARK-4039,SPARK-12861,Won't Fix,KMeans support sparse cluster centers,Changes to support KMeans with large feature space,0,1,1
345,SPARK-4046,SPARK-7096,Fixed,Incorrect Java example on site,Java example for Streaming on site uses map instead of mapToPair,1,1,1
346,SPARK-4049,SPARK-16218,Unresolved,"Storage web UI ""fraction cached"" shows as > 100%","spark 1.4.1 ""Storage Fraction Cached""  was greater than 120%.And I recache the talbe in memory and find querying faster than before;May be its a bug.",0,1,1
347,SPARK-4078,SPARK-4132,Fixed,New FsPermission instance w/o FsPermission.createImmutable in eventlog,Spark uses incompatible HDFS API,1,0,1
348,SPARK-4092,SPARK-4157,Fixed,Input metrics don't work for coalesce()'d RDD's,Task input statistics incomplete when a task reads from multiple locations,1,0,1
349,SPARK-4105,SPARK-12418,Fixed,FAILED_TO_UNCOMPRESS(5) errors when fetching shuffle data with sort-based shuffle,spark shuffle FAILED_TO_UNCOMPRESS,0,0,1
350,SPARK-4123,SPARK-10359,Duplicate,Show dependency changes in pull requests,Enumerate Spark's dependencies in a file and diff against it for new pull requests ,0,0,1
351,SPARK-4131,SPARK-16255,Fixed,"Support ""Writing data into the filesystem from queries""","Spark2.0 doesn't support the following SQL statement:""insert into directory ""/u_qa_user/hive_testdata/test1/t1"" select * from d_test_tpc_2g_txt.auction"" while Hive supports",1,0,1
352,SPARK-4133,SPARK-4641,Fixed,PARSING_ERROR(2) when upgrading issues from 1.0.2 to 1.1.0,A FileNotFoundException happened in Hash Shuffle Manager,0,1,1
353,SPARK-4134,SPARK-11789,Fixed,Dynamic allocation: tone down scary executor lost messages when killing on purpose,Spark prints misleading error messages about losing executors,0,0,1
354,SPARK-4140,SPARK-4839,Fixed,Document the dynamic allocation feature,Adding documentations about dynamic resource allocation,0,1,1
355,SPARK-4151,SPARK-8159,Duplicate,Add string operation function trim; ltrim; rtrim; length to support SparkSql (HiveQL) ,Improve expression function coverage (Spark 1.5),1,0,1
356,SPARK-4160,SPARK-17978,Unresolved,Standalone cluster mode does not upload all needed jars to driver node,#NAME?,0,1,1
357,SPARK-4160,SPARK-16364,Unresolved,Standalone cluster mode does not upload all needed jars to driver node,Allow spark-submit to upload jars to nodes in cluster mode,0,0,1
358,SPARK-4169,SPARK-4271,Fixed,"[SQL] use beeline execute ""create table as""  thriftserver is not use ""hive""  user ;but the new hdfs dir's owner is ""hive""  ",jetty Server can't tryport+1,1,1,1
359,SPARK-4169,SPARK-4316,Fixed,"[SQL] use beeline execute ""create table as""  thriftserver is not use ""hive""  user ;but the new hdfs dir's owner is ""hive""  ",Utils.isBindCollision misjudges at Non-English environment,1,0,1
360,SPARK-4173,SPARK-4249,Fixed,EdgePartitionBuilder uses wrong value for first clustered index,A problem of EdgePartitionBuilder in Graphx,1,0,1
361,SPARK-4176,SPARK-4657,Fixed,Support decimals with precision > 18 in Parquet,Suport storing decimals in Parquet that don't fit in a LONG,1,1,1
362,SPARK-4181,SPARK-4694,Duplicate,Create separate options to control the client-mode AM resource allocation request,,0,0,1
363,SPARK-4184,SPARK-5960,Duplicate,Improve Spark Streaming documentation to address commonly-asked questions ,Allow AWS credentials to be passed to KinesisUtils.createStream(),1,1,1
364,SPARK-4188,SPARK-4238,Fixed,Shuffle fetches should be retried at a lower level,Perform network-level retry of shuffle file fetches,1,0,1
365,SPARK-4188,SPARK-4195,Fixed,Shuffle fetches should be retried at a lower level,retry to fetch blocks's result when fetchfailed's reason is connection timeout,1,1,1
366,SPARK-4193,SPARK-4543,Fixed,Disable doclint in Java 8 to prevent from build error.,Javadoc failure for network-common causes publish-local to fail,0,0,1
367,SPARK-4208,SPARK-5009,Duplicate,stack over flow error while using sqlContext.sql,allCaseVersions function in  SqlLexical  leads to StackOverflow Exception,0,1,1
368,SPARK-4217,SPARK-4252,Invalid,Result of SparkSQL is incorrect after a table join and group by operation,SparkSQL behaves differently from Hive when encountering illegal record,1,0,1
369,SPARK-4226,SPARK-13831,Fixed,SparkSQL - Add support for subqueries in predicates,TPC-DS Query 35 fails with the following compile error,1,1,1
370,SPARK-4226,SPARK-12543,Fixed,SparkSQL - Add support for subqueries in predicates,Support subquery in select/where/having,1,1,1
371,SPARK-4226,SPARK-12545,Fixed,SparkSQL - Add support for subqueries in predicates,Support exists condition,1,1,1
372,SPARK-4226,SPARK-10600,Fixed,SparkSQL - Add support for subqueries in predicates,SparkSQL - Support for Not Exists in a Correlated Subquery,1,1,1
373,SPARK-4273,SPARK-10690,Fixed,Providing ExternalSet to avoid OOM when count(distinct),SQL select count(distinct ) won't work for a normal load,0,0,1
374,SPARK-4280,SPARK-7955,Duplicate,In dynamic allocation; add option to never kill executors with cached blocks,Dynamic allocation: longer timeout for executors with cached blocks,1,1,1
375,SPARK-4286,SPARK-5197,Fixed,Support External Shuffle Service with Mesos integration,Support external shuffle service in fine-grained mode on mesos cluster,0,1,1
376,SPARK-4288,SPARK-10408,Duplicate,Add Sparse Autoencoder algorithm to MLlib ,Autoencoder,0,1,1
377,SPARK-4296,SPARK-4322,Fixed,"Throw ""Expression not in GROUP BY"" when using same expression in group by clause and  select clause",Struct fields can't be used as sub-expression of grouping fields,1,1,1
378,SPARK-4324,SPARK-4328,Fixed,Support numpy/scipy in all Python API of MLlib,Python serialization updates make Python ML API more brittle to types,1,0,1
379,SPARK-4333,SPARK-4401,Fixed,Correctly log number of iterations in RuleExecutor,RuleExecutor correctly logs trace iteration num,1,0,1
380,SPARK-4336,SPARK-5706,Won't Fix,auto detect type from json string,Support inference schema from a single json string,1,0,1
381,SPARK-4342,SPARK-4393,Duplicate,connection ack timeout improvement; replace Timer with ScheudledExecutor...,Memory leak in connection manager timeout thread,1,0,1
382,SPARK-4349,SPARK-4737,Duplicate,Spark driver hangs on sc.parallelize() if exception is thrown during serialization,Prevent serialization errors from ever crashing the DAG scheduler,1,0,1
383,SPARK-4366,SPARK-6424,Unresolved,Aggregation Improvement,Support user-defined aggregators in AggregateFunction,1,0,1
384,SPARK-4376,SPARK-4628,Duplicate,Put external modules behind build profiles,Put external projects and examples behind a build flag,0,0,1
385,SPARK-4388,SPARK-5768,Duplicate,Add tooltips to explain maxMemory / usedMemory columns in executor UI,Spark UI Shows incorrect memory under Yarn,0,0,1
386,SPARK-4392,SPARK-5467,Won't Fix,Event proration based on event timestamps,DStreams should provide windowing based on timestamps from the data (as opposed to wall clock time),1,1,1
387,SPARK-4416,SPARK-6284,Duplicate,Support Mesos framework authentication,Support framework authentication and role in Mesos framework,1,1,1
388,SPARK-4452,SPARK-14560,Fixed,Shuffle data structures can starve others on the same thread for memory ,Cooperative Memory Management for Spillables,1,1,1
389,SPARK-4467,SPARK-4515,Fixed,Number of elements read is never reset in ExternalSorter,OOM/GC errors with sort-based shuffle,0,1,1
390,SPARK-4476,SPARK-5936,Unresolved,Use MapType for dict in json which has unique keys in each row.,Automatically convert a StructType to a MapType when the number of fields exceed a threshold.,1,0,1
391,SPARK-4502,SPARK-5446,Unresolved,Spark SQL reads unneccesary nested fields from Parquet,Parquet column pruning should work for Map and Struct,1,0,1
392,SPARK-4541,SPARK-5732,Duplicate,Add --version to spark-submit,Add an option to print the spark version in spark script,1,1,1
393,SPARK-4544,SPARK-5847,Duplicate,Spark JVM Metrics doesn't have context.,Allow for configuring MetricsSystem's use of app ID to namespace all metrics,1,0,1
394,SPARK-4552,SPARK-4702,Fixed,query for empty parquet table in spark sql hive get IllegalArgumentException,Querying  non-existent partition produces exception in v1.2.0-rc1,1,0,1
395,SPARK-4558,SPARK-5522,Duplicate,History Server waits ~10s before starting up,Accelerate the History Server start,0,0,1
396,SPARK-4563,SPARK-6680,Fixed,Allow spark driver to bind to different ip then advertise ip,Be able to specifie IP for spark-shell(spark driver) blocker for Docker integration,1,1,1
397,SPARK-4563,SPARK-21668,Fixed,Allow spark driver to bind to different ip then advertise ip,Ability to run driver programs within a container,0,1,1
398,SPARK-4579,SPARK-6543,Fixed,Scheduling Delay appears negative,Scheduler Delay column in tasks table on Stage detail page showing negative numbers,1,0,1
399,SPARK-4579,SPARK-5877,Fixed,Scheduling Delay appears negative,Scheduler delay is incorrect for running tasks,1,0,1
400,SPARK-4587,SPARK-5359,Fixed,Model export/import,ML model import/export,0,0,1
401,SPARK-4598,SPARK-5899,Fixed,Paginate stage page to avoid OOM with > 100;000 tasks,Viewing specific stage information which contains thousands of tasks will freak out the driver and CPU cores from where it runs,1,0,1
402,SPARK-4598,SPARK-9037,Fixed,Paginate stage page to avoid OOM with > 100;000 tasks,Task table pagination for the Stage page,1,1,1
403,SPARK-4607,SPARK-13952,Duplicate,Add random seed to GBTClassifier; GBTRegressor,spark.ml GBT algs need to use random seed,1,1,1
404,SPARK-4609,SPARK-6183,Duplicate,Job can not finish if there is one bad slave in clusters,Skip bad workers when re-launching executors,0,1,1
405,SPARK-4616,SPARK-5382,Duplicate,SPARK_CONF_DIR is not effective in spark-submit,Scripts do not use SPARK_CONF_DIR where they should,0,0,1
406,SPARK-4622,SPARK-4623,Duplicate,Add the some error infomation if using spark-sql in yarn-cluster mode,Add the some error infomation if using spark-sql in yarn-cluster mode,1,1,1
407,SPARK-4630,SPARK-9850,Duplicate,Dynamically determine optimal number of partitions,Adaptive execution in Spark,0,1,1
408,SPARK-4632,SPARK-4637,Fixed,Upgrade MQTT dependency to use mqtt-client 1.0.1,spark-1.1.0 does not compile any more,0,1,1
409,SPARK-4648,SPARK-5244,Duplicate,Support COALESCE function in Spark SQL and HiveQL,add parser for COALESCE(),1,1,1
410,SPARK-4654,SPARK-5374,Unresolved,Clean up DAGScheduler's getMissingParentStages() and stageDependsOn() methods,abstract RDD's DAG graph iteration in DAGScheduler,1,1,1
411,SPARK-4660,SPARK-4830,Fixed,JavaSerializer uses wrong classloader,Spark Streaming Java Application : java.lang.ClassNotFoundException,0,0,1
412,SPARK-4681,SPARK-8425,Duplicate,Turn on executor level blacklisting by default,Add blacklist mechanism for task scheduling,0,0,1
413,SPARK-4681,SPARK-17675,Duplicate,Turn on executor level blacklisting by default,Add Blacklisting of Executors & Nodes within one TaskSet,1,1,1
414,SPARK-4705,SPARK-6751,Fixed,Driver retries in cluster mode always fail if event logging is enabled,Spark History Server support multiple application attempts,1,1,1
415,SPARK-4709,SPARK-4987,Duplicate,Spark SQL support error reading Parquet with timestamp type field,Parquet support for timestamp type,0,0,1
416,SPARK-4709,SPARK-4768,Duplicate,Spark SQL support error reading Parquet with timestamp type field,Add Support For Impala Encoded Timestamp (INT96),1,0,1
417,SPARK-4718,SPARK-4731,Duplicate,spark-ec2 script creates empty spark folder,Spark 1.1.1 launches broken EC2 clusters,1,1,1
418,SPARK-4751,SPARK-5349,Fixed,Support dynamic allocation for standalone mode,Spark standalone should support dynamic resource scaling,1,0,1
419,SPARK-4766,SPARK-4875,Won't Fix,ML Estimator Params should be distinct from Transformer Params,Separate Transformer; Estimator params,1,0,1
420,SPARK-4768,SPARK-4987,Duplicate,Add Support For Impala Encoded Timestamp (INT96),Parquet support for timestamp type,0,0,1
421,SPARK-4783,SPARK-15685,Fixed,System.exit() calls in SparkContext disrupt applications embedding Spark,StackOverflowError (VirtualMachineError) or NoClassDefFoundError (LinkageError) should not System.exit() in local mode,1,0,1
422,SPARK-4783,SPARK-6804,Fixed,System.exit() calls in SparkContext disrupt applications embedding Spark,System.exit(1) on error,0,0,1
423,SPARK-4783,SPARK-9687,Fixed,System.exit() calls in SparkContext disrupt applications embedding Spark,System.exit() still disrupt applications embedding Spark,0,1,1
424,SPARK-4796,SPARK-5836,Duplicate,Spark does not remove temp files,Highlight in Spark documentation that by default Spark does not delete its temporary files,0,0,1
425,SPARK-4799,SPARK-5078,Duplicate,Spark should not rely on local host being resolvable on every node,Allow setting Akka host name from env vars,1,0,1
426,SPARK-4801,SPARK-6199,Duplicate,Add CTE capability to HiveContext,Support CTE,1,1,1
427,SPARK-4804,SPARK-5040,Duplicate,StringContext method to allow using Strings for column names in catalyst DSL,"Support expressing unresolved attributes using $""attribute name"" notation in SQL DSL",1,0,1
428,SPARK-4811,SPARK-6708,Duplicate,Custom UDTFs not working in Spark SQL,Using Hive UDTF may throw ClassNotFoundException,1,0,1
429,SPARK-4818,SPARK-4824,Fixed,Join operation should use iterator/lazy evaluation,Join should use `Iterator` rather than `Iterable`,1,1,1
430,SPARK-4819,SPARK-12548,Fixed,"Remove Guava's ""Optional"" from public API",Add more exceptions to Guava relocation,0,1,1
431,SPARK-4820,SPARK-8825,Fixed,"Spark build encounters ""File name too long"" on some encrypted filesystems",Spark build fails,0,0,1
432,SPARK-4820,SPARK-21531,Fixed,"Spark build encounters ""File name too long"" on some encrypted filesystems","CLONE - Spark build encounters ""File name too long"" on some encrypted filesystems",1,0,1
433,SPARK-4835,SPARK-5545,Fixed,Streaming saveAs*HadoopFiles() methods may throw FileAlreadyExistsException during checkpoint recovery,[Spark SQL] show poor performance when multiple table do join operation,0,1,1
434,SPARK-4836,SPARK-5023,Unresolved,Web UI should display separate information for all stage attempts,In Web UI job history; the total job duration is incorrect (much smaller than the sum of its stages),1,1,1
435,SPARK-4846,SPARK-5261,Fixed,"When the vocabulary size is large; Word2Vec may yield ""OutOfMemoryError: Requested array size exceeds VM limit""",In some cases ;The value of word's vector representation is too big,1,0,1
436,SPARK-4849,SPARK-5354,Fixed,Pass partitioning information (distribute by) to In-memory caching,Set InMemoryColumnarTableScan's outputPartitioning and outputOrdering,1,0,1
437,SPARK-4854,SPARK-6708,Duplicate,Custom UDTF with Lateral View throws ClassNotFound exception in Spark SQL CLI,Using Hive UDTF may throw ClassNotFoundException,1,1,1
438,SPARK-4870,SPARK-4954,Fixed,Add version information to driver log,Add spark version information in log for standalone mode,1,1,1
439,SPARK-4877,SPARK-5358,Fixed,userClassPathFirst doesn't handle user classes inheriting from parent,spark.files.userClassPathFirst doesn't work correctly,1,1,1
440,SPARK-4882,SPARK-5779,Fixed,PySpark broadcast breaks when using KryoSerializer,Python broadcast does not work with Kryo serializer,1,0,1
441,SPARK-4913,SPARK-4933,Fixed,Fix incorrect event log path,eventLog file not found after merging into a single file,0,1,1
442,SPARK-4922,SPARK-6287,Duplicate,Support dynamic allocation for coarse-grained Mesos,Add support for dynamic allocation in the Mesos coarse-grained scheduler,1,0,1
443,SPARK-4937,SPARK-4938,Fixed,Adding optimization to simplify the filter condition,Adding optimization to simplify the filter condition,1,1,1
444,SPARK-4939,SPARK-6232,Fixed,Python updateStateByKey example hang in local mode,Spark Streaming: simple application stalls processing,0,0,1
445,SPARK-4944,SPARK-5720,Auto Closed,"Table Not Found exception in ""Create Table Like registered RDD table""",`Create Table Like` in HiveContext need support `like registered temporary table`,1,1,1
446,SPARK-4956,SPARK-6150,Won't Fix,Vector Initialization error when initialize a Sparse Vector by calling Vectors.sparse(size; indices; values),Validate indices before constructing a SparseVector,1,1,1
447,SPARK-4983,SPARK-7900,Fixed,Add sleep() before tagging EC2 instances to allow instance metadata to propagate,Reduce number of tagging calls in spark-ec2,1,1,1
448,SPARK-5004,SPARK-5820,Unresolved,PySpark does not handle SOCKS proxy,Example does not work when using SOCKS proxy,0,0,1
449,SPARK-5014,SPARK-7206,Not A Problem,GaussianMixture (GMM) improvements,Gaussian Mixture Model (GMM) improvements,0,1,1
450,SPARK-5030,SPARK-9741,Duplicate,Approximated cardinality with HyperLogLog UDAF,approx count distinct function,1,0,1
451,SPARK-5033,SPARK-5754,Duplicate,Spark 1.1.0/1.1.1/1.2.0 can't run well in HDP on Windows,Spark AM not launching on Windows,1,1,1
452,SPARK-5048,SPARK-8378,Duplicate,Add Flume to the Python Streaming API,Add Spark Flume Python API,0,1,1
453,SPARK-5058,SPARK-5394,Fixed,Typos and broken URL,kafka link in streaming docs goes to nowhere,0,0,1
454,SPARK-5058,SPARK-5409,Fixed,Typos and broken URL,Broken link in documentation,0,1,1
455,SPARK-5063,SPARK-15787,Fixed,Display more helpful error messages for several invalid operations,Display more helpful error messages for several invalid operations,0,1,1
456,SPARK-5069,SPARK-5070,Fixed,Race condition in TaskSchedulerImpl.dagScheduler,Race condition in TaskSchedulerImpl.dagScheduler,1,1,1
457,SPARK-5069,SPARK-5072,Fixed,Race condition in TaskSchedulerImpl.dagScheduler,Race condition in TaskSchedulerImpl.dagScheduler,1,1,1
458,SPARK-5081,SPARK-6905,Cannot Reproduce,Shuffle write increases,Upgrade Snappy Java to 1.1.1.7 to fix bug that resulted in worse compression,0,0,1
459,SPARK-5081,SPARK-5715,Cannot Reproduce,Shuffle write increases,Shuffle size increase; performance loss from Spark 1.1.0 to Spark 1.2.0 (and 1.2.1),0,0,1
460,SPARK-5105,SPARK-5107,Duplicate,A better log info for the start of receiver,A trick log info for the start of Receiver,0,0,1
461,SPARK-5113,SPARK-6420,Won't Fix,Audit and document use of hostnames and IP addresses in Spark,"Driver's Block Manager does not use ""spark.driver.host"" in Yarn-Client mode",0,0,1
462,SPARK-5113,SPARK-5368,Won't Fix,Audit and document use of hostnames and IP addresses in Spark,Spark should  support NAT (via akka improvements),1,0,1
463,SPARK-5131,SPARK-5485,Fixed,A typo in configuration doc,typo in spark streaming configuration parameter,0,0,1
464,SPARK-5140,SPARK-6003,Won't Fix,Two RDDs which are scheduled concurrently should be able to wait on parent in all cases,"Spark should offer a ""sync"" method that guarantees that RDDs are eagerly evaluated and persisted",1,0,1
465,SPARK-5144,SPARK-5289,Duplicate,spark-yarn module should be published,Backport publishing of repl; yarn into branch-1.2,0,0,1
466,SPARK-5151,SPARK-17636,Duplicate,Parquet Predicate Pushdown Does Not Work with Nested Structures.,Parquet filter push down doesn't handle struct fields,0,0,1
467,SPARK-5162,SPARK-5173,Fixed,Python yarn-cluster mode,support python application running on yarn cluster mode,0,1,1
468,SPARK-5165,SPARK-6356,Duplicate,Add support for rollup and cube in sqlcontext,Support the ROLLUP/CUBE/GROUPING SETS/grouping() in SQLContext,1,1,1
469,SPARK-5178,SPARK-7021,Duplicate,Integrate Python unit tests into Jenkins,JUnit output for Python tests,1,1,1
470,SPARK-5182,SPARK-6561,Fixed,Partitioning support for tables created by the data source API,Add partition support in saveAsParquet,1,0,1
471,SPARK-5185,SPARK-6047,Fixed,pyspark --jars does not add classes to driver class path,pyspark - class loading on driver failing with --jars and --packages,0,1,1
472,SPARK-5185,SPARK-5975,Fixed,pyspark --jars does not add classes to driver class path,SparkSubmit --jars not present on driver in python,0,0,1
473,SPARK-5185,SPARK-6027,Fixed,pyspark --jars does not add classes to driver class path,Make KafkaUtils work in Python with kafka-assembly provided as --jar or maven package provided as --packages,0,0,1
474,SPARK-5185,SPARK-6301,Fixed,pyspark --jars does not add classes to driver class path,Unable to load external jars while submitting Spark Job,0,1,1
475,SPARK-5192,SPARK-6607,Duplicate,Parquet fails to parse schema contains '\r',Aggregation attribute name including special chars '(' and ')' should be replaced before generating Parquet schema,1,0,1
476,SPARK-5199,SPARK-5347,Fixed,Input metrics should show up for InputFormats that return CombineFileSplits,InputMetrics bug when inputSplit is not instanceOf FileSplit,1,1,1
477,SPARK-5206,SPARK-12407,Unresolved,Accumulators are not re-registered during recovering from checkpoint,ClassCast Exception when restarting spark streaming from checkpoint,1,1,1
478,SPARK-5212,SPARK-5364,Fixed,Add support of schema-less; custom field delimiter and SerDe for HiveQL transform,HiveQL transform doesn't support the non output clause,0,0,1
479,SPARK-5213,SPARK-6200,Fixed,Pluggable SQL Parser Support,Support dialect in SQL,1,1,1
480,SPARK-5215,SPARK-8240,Duplicate,concat support in sqlcontext,string function: concat,1,1,1
481,SPARK-5229,SPARK-5251,Duplicate,Use tableIdentifier as the reference of a table ,Using `tableIdentifier` in hive metastore ,1,1,1
482,SPARK-5237,SPARK-5383,Duplicate,UDTF don't work with multi-alias of multi-columns as output on SparK SQL,support alias for udfs with multi output columns,1,1,1
483,SPARK-5239,SPARK-5481,Fixed,"JdbcRDD throws ""java.lang.AbstractMethodError: oracle.jdbc.driver.xxxxxx.isClosed()Z""",JdbcRDD requires JDBC 4 APIs; limiting compatible JDBC Drivers,0,0,1
484,SPARK-5242,SPARK-6588,Fixed,ec2/spark_ec2.py lauch does not work with VPC if no public DNS or IP is available,Private VPC's and subnets currently don't work with the Spark ec2 script,1,0,1
485,SPARK-5245,SPARK-5248,Fixed,Move Decimal from types.decimal to types package,moving Decimal from types.decimal to types package,0,0,1
486,SPARK-5265,SPARK-5497,Duplicate,Submitting applications on Standalone cluster controlled by Zookeeper forces to know active master,start-all script not working properly on Standalone HA cluster (with Zookeeper),1,1,1
487,SPARK-5265,SPARK-6443,Duplicate,Submitting applications on Standalone cluster controlled by Zookeeper forces to know active master,Support HA in standalone cluster mode,0,1,1
488,SPARK-5275,SPARK-5276,Fixed,pyspark.streaming is not included in assembly jar,pyspark.streaming is not included in assembly jar,1,1,1
489,SPARK-5278,SPARK-6273,Fixed,check ambiguous reference to fields in Spark SQL is incompleted,Got error when one table's alias name is the same with other table's column name,1,1,1
490,SPARK-5281,SPARK-5290,Fixed,Registering table on RDD is giving MissingRequirementError,Executing functions in sparkSQL registered in sqlcontext gives scala.reflect.internal.MissingRequirementError: class org.apache.spark.sql.catalyst.ScalaReflection,1,0,1
491,SPARK-5292,SPARK-12394,Duplicate,optimize join for table that are already sharded/support for hive bucket,Support writing out pre-hash-partitioned data and exploit that in join optimizations to avoid shuffle (i.e. bucketing in Hive),1,1,1
492,SPARK-5311,SPARK-18988,Won't Fix,EventLoggingListener throws exception if log directory does not exist,"Spark ""spark.eventLog.dir"" dir should create the directory if it is different from ""spark.history.fs.logDirectory""",0,0,1
493,SPARK-5311,SPARK-22174,Won't Fix,EventLoggingListener throws exception if log directory does not exist,Support to automatically create the directory where the event logs go (`spark.eventLog.dir`) ,1,0,1
494,SPARK-5311,SPARK-6078,Won't Fix,EventLoggingListener throws exception if log directory does not exist,create event log directory automatically if not exists,1,0,1
495,SPARK-5311,SPARK-17478,Won't Fix,EventLoggingListener throws exception if log directory does not exist,Create spark.eventLog.dir if it does not exist,0,0,1
496,SPARK-5311,SPARK-16547,Won't Fix,EventLoggingListener throws exception if log directory does not exist,EventLoggingListener to auto create log base dir if it does not exist,0,0,1
497,SPARK-5348,SPARK-7481,Not A Problem,s3a:// protocol and hadoop-aws dependency,Add spark-hadoop-cloud module to pull in object store support,0,0,1
498,SPARK-5369,SPARK-5370,Duplicate,remove allocatedHostToContainersMap.synchronized in YarnAllocator,Remove some unnecessary synchronization in YarnAllocator,0,0,1
499,SPARK-5374,SPARK-15927,Duplicate,abstract RDD's DAG graph iteration in DAGScheduler,Eliminate redundant code in DAGScheduler's getParentStages and getAncestorShuffleDependencies methods.,1,0,1
500,SPARK-5389,SPARK-6084,Cannot Reproduce,spark-shell.cmd does not run from DOS Windows 7,spark-shell broken on Windows,0,1,1
501,SPARK-5389,SPARK-7195,Cannot Reproduce,spark-shell.cmd does not run from DOS Windows 7,Can't start spark shell or pyspark in Windows 7,0,1,1
502,SPARK-5399,SPARK-6113,Duplicate,tree Losses strings should match loss names,Stabilize DecisionTree and ensembles APIs,0,0,1
503,SPARK-5427,SPARK-6829,Duplicate,Add support for floor function in Spark SQL,Support math functions in DataFrames,1,0,1
504,SPARK-5469,SPARK-5589,Fixed,Break sql.py into multiple files,Split pyspark/sql.py into multiple files,0,1,1
505,SPARK-5479,SPARK-7725,Fixed,PySpark on yarn mode need to support non-local python files,--py-files doesn't seem to work in YARN cluster mode,0,1,1
506,SPARK-5479,SPARK-8017,Fixed,PySpark on yarn mode need to support non-local python files,YARN cluster python --py-files does not work,1,1,1
507,SPARK-5483,SPARK-5489,Not A Problem,java.lang.NoSuchMethodError: scala.Predef$.ArrowAssoc(Ljava/lang/Object;)Ljava/lang/Object;,KMeans clustering java.lang.NoSuchMethodError: scala.runtime.IntRef.create  (I)Lscala/runtime/IntRef;,1,1,1
508,SPARK-5508,SPARK-6774,Duplicate,Arrays and Maps stored with Hive Parquet Serde may not be able to read by the Parquet support in the Data Souce API,Implement Parquet complex types backwards-compatiblity rules,1,1,1
509,SPARK-5544,SPARK-7155,Duplicate,wholeTextFiles should recognize multiple input paths delimited by ;,SparkContext's newAPIHadoopFile does not support comma-separated list of files; but the other API hadoopFile does.,1,1,1
510,SPARK-5547,SPARK-5557,Duplicate,With assembly jar to run example throws an exception,Servlet API classes now missing after jetty shading,1,0,1
511,SPARK-5615,SPARK-5681,Duplicate,Fix testPackage in StreamingContextSuite,Calling graceful stop() immediately after start() on StreamingContext should not get stuck indefinitely,1,0,1
512,SPARK-5623,SPARK-12995,Duplicate,Replace an obsolete mapReduceTriplets with a new aggregateMessages in GraphSuite,Remove deprecate APIs from GraphX,1,1,1
513,SPARK-5629,SPARK-5879,Won't Fix,Add spark-ec2 action to return info about an existing cluster,spary_ec2.py should expose/return master and slave lists (e.g. write to file),1,0,1
514,SPARK-5632,SPARK-6898,Fixed,not able to resolve dot('.') in field name,Special chars in column names is broken,1,0,1
515,SPARK-5681,SPARK-7346,Fixed,Calling graceful stop() immediately after start() on StreamingContext should not get stuck indefinitely,Fix a bug that ssc.stop(true; stopGracefully = true) may block forever,1,1,1
516,SPARK-5682,SPARK-6460,Fixed,Add encrypted shuffle in spark,Implement OpensslAesCtrCryptoCodec to enable encrypted shuffle algorithms which openssl provides,1,1,1
517,SPARK-5682,SPARK-10771,Fixed,Add encrypted shuffle in spark,Implement the shuffle encryption with AES-CTR crypto using JCE key provider.,1,0,1
518,SPARK-5682,SPARK-12333,Fixed,Add encrypted shuffle in spark,Support shuffle spill encryption in Spark,1,1,1
519,SPARK-5721,SPARK-5759,Duplicate,Propagate missing external shuffle service errors to client,ExecutorRunnable should catch YarnException while NMClient start container,0,1,1
520,SPARK-5739,SPARK-5928,Duplicate,Size exceeds Integer.MAX_VALUE in File Map,Remote Shuffle Blocks cannot be more than 2 GB,0,0,1
521,SPARK-5749,SPARK-5765,Fixed,Fix Bash word splitting bugs in compute-classpath.sh,word split problem in run-example and compute-classpath,0,1,1
522,SPARK-5753,SPARK-10186,Duplicate,add basic support to JDBCRDD for postgresql types: uuid; hstore; and array,Add support for more postgres column types,1,1,1
523,SPARK-5754,SPARK-7700,Fixed,Spark AM not launching on Windows,Spark 1.3.0 on YARN: Application failed 2 times due to AM Container,0,1,1
524,SPARK-5775,SPARK-6276,Fixed,GenericRow cannot be cast to SpecificMutableRow when nested data and partitioned table,beeline client class cast exception on partitioned table Spark SQL,1,0,1
525,SPARK-5801,SPARK-5830,Fixed,Shuffle creates too many nested directories,Don't create unnecessary directory for local root dir,0,1,1
526,SPARK-5805,SPARK-5819,Fixed,Fix the type error in the final example given in MLlib - Clustering documentation,Backport of SPARK-5805 to branch-1.2,0,1,1
527,SPARK-5836,SPARK-6011,Not A Problem,Highlight in Spark documentation that by default Spark does not delete its temporary files,Out of disk space due to Spark not deleting shuffle files of lost executors,0,0,1
528,SPARK-5837,SPARK-9779,Not A Problem,HTTP 500 if try to access Spark UI in yarn-cluster or yarn-client mode,HTTP500 revisit when open web-UI in yarn-cluster yarn-client mode (1.2-1.3) ,1,1,1
529,SPARK-5841,SPARK-5869,Fixed,Memory leak in DiskBlockManager,Exception when deleting Spark local dirs when shutting down DiskBlockManager,0,1,1
530,SPARK-5841,SPARK-8024,Fixed,Memory leak in DiskBlockManager,Luigi triggering resolved Blockmanager bug,1,1,1
531,SPARK-5847,SPARK-10610,Fixed,Allow for configuring MetricsSystem's use of app ID to namespace all metrics,Using AppName instead of AppId in the name of all metrics,1,1,1
532,SPARK-5863,SPARK-6620,Fixed,Improve performance of convertToScala codepath.,Speed up toDF() and rdd() functions by constructing converters in ScalaReflection,1,0,1
533,SPARK-5870,SPARK-5972,Duplicate,GradientBoostedTrees should cache residuals from partial model,Cache residuals for GradientBoostedTrees during training,1,0,1
534,SPARK-5884,SPARK-6525,Fixed,Implement feature transformers to ML pipelines for Spark 1.4,Add new feature transformers in ML package,1,0,1
535,SPARK-5903,SPARK-6195,Duplicate,Add support for Decimal type in SQL Table caching,Specialized in-memory column type for fixed-precision decimal,1,1,1
536,SPARK-5918,SPARK-11660,Unresolved,Spark Thrift server reports metadata for VARCHAR column as STRING in result set schema,Spark Thrift GetResultSetMetadata describes a VARCHAR as a STRING,1,1,1
537,SPARK-5928,SPARK-20308,Unresolved,Remote Shuffle Blocks cannot be more than 2 GB,org.apache.spark.shuffle.FetchFailedException: Too large frame,0,1,1
538,SPARK-5959,SPARK-9215,Duplicate,Create a ReliableKinesisReceiver similar to the ReliableKafkaReceiver,Implement WAL-free Kinesis receiver that give at-least once guarantee,1,1,1
539,SPARK-5962,SPARK-5963,Fixed,[MLLIB] Python support for Power Iteration Clustering,Spark-submit deploy-mode incorrectly affecting submission when master = local[4] ,1,1,1
540,SPARK-5962,SPARK-6260,Fixed,[MLLIB] Python support for Power Iteration Clustering,Python API for PowerIterationClustering,0,1,1
541,SPARK-5964,SPARK-11653,Won't Fix,Allow spark-daemon.sh to support foreground operation,Would be very useful if spark-daemon.sh supported foreground operations,0,1,1
542,SPARK-5964,SPARK-16352,Won't Fix,Allow spark-daemon.sh to support foreground operation,change sbin scripts to allow running spark foregroud,1,1,1
543,SPARK-5970,SPARK-7917,Fixed,Temporary directories are not removed (but their content is),Spark doesn't clean up Application Directories (local dirs) ,1,1,1
544,SPARK-5973,SPARK-6008,Fixed,zip two rdd with AutoBatchedSerializer will fail,zip two rdds derived from pickleFile fails,1,0,1
545,SPARK-6000,SPARK-14174,Duplicate,"Batch K-Means clusters should support ""mini-batch"" updates",Implement the Mini-Batch KMeans,0,0,1
546,SPARK-6006,SPARK-12077,Fixed,Optimize count distinct in case of high cardinality columns,Use more robust plan for single distinct aggregation,1,0,1
547,SPARK-6009,SPARK-9083,Duplicate,IllegalArgumentException thrown by TimSort when SQL ORDER BY RAND (),If order by clause has non-deterministic expressions; we should add a project to materialize results of these expressions ,1,1,1
548,SPARK-6009,SPARK-8428,Duplicate,IllegalArgumentException thrown by TimSort when SQL ORDER BY RAND (),TimSort Comparison method violates its general contract with CLUSTER BY,1,1,1
549,SPARK-6014,SPARK-7865,Fixed,java.io.IOException: Filesystem is thrown when ctrl+c or ctrl+d spark-sql on YARN ,Hadoop Filesystem for eventlog closed before sparkContext stopped,0,0,1
550,SPARK-6014,SPARK-6445,Fixed,java.io.IOException: Filesystem is thrown when ctrl+c or ctrl+d spark-sql on YARN ,IOException: Filesystem closed  is thrown while existing spark-sql console,0,1,1
551,SPARK-6014,SPARK-10358,Fixed,java.io.IOException: Filesystem is thrown when ctrl+c or ctrl+d spark-sql on YARN ,Spark-sql throws IOException on exit when using HDFS to store event log.,0,1,1
552,SPARK-6018,SPARK-6449,Fixed,NoSuchMethodError in Spark app is swallowed by YARN AM,Driver OOM results in reported application result SUCCESS,1,0,1
553,SPARK-6038,SPARK-6039,Invalid,"java.util.NoSuchElementException: key not found: xyz  ;this error is came most  number of times in cluster mode  while working with 1.2.1 latest version .please solve this.""","java.util.NoSuchElementException: key not found: xyz ;this error is came most number of times in cluster mode while working with 1.2.1 latest version .please solve this."" ",1,1,1
554,SPARK-6063,SPARK-6532,Fixed,MLlib doesn't pass mvn scalastyle check due to UTF chars in LDAModel.scala,LDAModel.scala fails scalastyle on Windows,1,1,1
555,SPARK-6067,SPARK-8379,Duplicate,Spark sql hive dynamic partitions job will fail if task fails,LeaseExpiredException when using dynamic partition with speculative execution,1,0,1
556,SPARK-6072,SPARK-11111,Duplicate,Enable hash joins for null-safe equality predicates,Fast null-safe join,1,1,1
557,SPARK-6084,SPARK-7374,Duplicate,spark-shell broken on Windows,"Error message when launching: ""find: 'version' : No such file or directory""",0,1,1
558,SPARK-6107,SPARK-8143,Fixed,event log file ends with .inprogress should be able to display on webUI for standalone mode,Spark application history cannot be found even for finished jobs,0,1,1
559,SPARK-6143,SPARK-8871,Unresolved,Improve FP-Growth for mining closed-forms of frequent patterns,Add maximal frequent itemsets filter in Spark MLib FPGrowth,1,0,1
560,SPARK-6156,SPARK-6157,Won't Fix,Not cache in memory again if put memory_and_disk level block after put it in disk after unroll unsuccess in memory.,Unrolling with MEMORY_AND_DISK should always release memory,1,0,1
561,SPARK-6171,SPARK-6172,Cannot Reproduce,No class def found for HiveConf in Spark shell,NoClassDefFoundError when launching spark shell w/o hive,0,0,1
562,SPARK-6174,SPARK-12632,Duplicate,Improve doc: Python ALS; MatrixFactorizationModel,Make Parameter Descriptions Consistent for PySpark MLlib FPM and Recommendation,0,0,1
563,SPARK-6183,SPARK-6353,Unresolved,Skip bad workers when re-launching executors,Handling fatal errors of executors and decommission datanodes,0,1,1
564,SPARK-6185,SPARK-6271,Duplicate," Deltele repeated TOKEN. ""TOK_CREATEFUNCTION"" has existed at Line 84;",Sort these tokens in alphabetic order to avoid further duplicate in HiveQl,1,0,1
565,SPARK-6187,SPARK-8625,Duplicate,Report full executor exceptions to the driver,Propagate user exceptions in tasks back to driver,1,0,1
566,SPARK-6197,SPARK-6314,Fixed,handle json parse exception for eventlog file not finished writing ,Failed to load application log data from FileStatus,0,0,1
567,SPARK-6216,SPARK-6298,Fixed,Check Python version in worker before run PySpark job,Warn users about mixed python versions when running PySpark,1,1,1
568,SPARK-6223,SPARK-6225,Duplicate,Avoid Build warning- enable implicit value scala.language.existentials visible,Resolve most build warnings; 1.3.0 edition,0,0,1
569,SPARK-6235,SPARK-22622,Unresolved,Address various 2G limits,OutOfMemory thrown by Closure Serializer without proper failure propagation,0,0,1
570,SPARK-6239,SPARK-10920,Invalid,Spark MLlib fpm#FPGrowth minSupport should use long instead,another constructor for FPGrowth algorithm to support the absolute value for support,0,1,1
571,SPARK-6242,SPARK-6471,Duplicate,Support replace (drop) column for parquet table,Metastore schema should only be a subset of parquet schema to support dropping of columns using replace columns,1,0,1
572,SPARK-6249,SPARK-9434,Won't Fix,Get Kafka offsets from consumer group in ZK when using direct stream,Need how-to for resuming direct Kafka streaming consumers where they had left off before getting terminated; OR actual support for that mode in the Streaming API,0,1,1
573,SPARK-6249,SPARK-8833,Won't Fix,Get Kafka offsets from consumer group in ZK when using direct stream,Kafka Direct API support offset in zookeeper,1,0,1
574,SPARK-6270,SPARK-7600,Unresolved,Standalone Master hangs when streaming job completes and event logging is enabled,Stopping Streaming Context (sometimes) crashes master,0,0,1
575,SPARK-6279,SPARK-6569,Fixed,"Miss expressions flag ""s"" at logging string ",Kafka directInputStream logs what appear to be incorrect warnings,1,1,1
576,SPARK-6294,SPARK-6344,Fixed,PySpark task may hang while call take() on in Java/Scala,Pyspark local stalls when take() before count() on cached rdd,1,0,1
577,SPARK-6299,SPARK-7061,Fixed,ClassNotFoundException in standalone mode when running groupByKey with class defined in REPL.,Case Classes Cannot be Repartitioned/Shuffled in Spark REPL,1,0,1
578,SPARK-6307,SPARK-6922,Not A Problem,Executers fetches the same rdd-block 100's or 1000's of times,RDD.cartesian is much slower than join,0,1,1
579,SPARK-6310,SPARK-6312,Duplicate,ChiSqTest should check for too few counts,ChiSqTest should check for too few counts,1,0,1
580,SPARK-6311,SPARK-6312,Duplicate,ChiSqTest should check for too few counts,ChiSqTest should check for too few counts,1,0,1
581,SPARK-6330,SPARK-6351,Fixed,newParquetRelation gets incorrect FileSystem,ParquetRelation2 does not support paths for different file systems,1,0,1
582,SPARK-6330,SPARK-6446,Fixed,newParquetRelation gets incorrect FileSystem,Spark Sql hive query is not working on spark1.3 version,0,0,1
583,SPARK-6334,SPARK-6717,Duplicate,spark-local dir not getting cleared during ALS,Clear shuffle files after checkpointing in ALS,1,1,1
584,SPARK-6348,SPARK-6683,Duplicate,Enable useFeatureScaling in SVMWithSGD,Handling feature scaling properly for GLMs,1,0,1
585,SPARK-6364,SPARK-9750,Duplicate,hashCode and equals for Matrices,SparseMatrix should override equals,1,0,1
586,SPARK-6381,SPARK-6386,Duplicate,add Apriori algorithm to MLLib,add association rule mining algorithm to MLLib,1,1,1
587,SPARK-6383,SPARK-7607,Fixed,Few examples on Dataframe operation give compiler errors ,Spark SQL prog guide code error,0,0,1
588,SPARK-6385,SPARK-9794,Duplicate,ISO 8601 timestamp parsing does not support arbitrary precision second fractions,ISO DateTime parser is too strict,1,0,1
589,SPARK-6386,SPARK-8559,Duplicate,add association rule mining algorithm to MLLib,Support association rule generation in FPGrowth,1,1,1
590,SPARK-6400,SPARK-6433,Duplicate,It would be great if you could share your test jars in Maven central repository for the Spark SQL module,hive tests to import spark-sql test JAR for QueryTest access,0,0,1
591,SPARK-6407,SPARK-6711,Unresolved,Streaming ALS for Collaborative Filtering,Support parallelized online matrix factorization for Collaborative Filtering ,0,0,1
592,SPARK-6418,SPARK-7296,Fixed,Add simple per-stage visualization to the UI,Timeline view for Stage page,1,1,1
593,SPARK-6431,SPARK-6434,Fixed,Couldn't find leader offsets exception when creating KafkaDirectStream,When I build Spark 1.3 sbt gives me to following error   : unresolved dependency: org.apache.kafka#kafka_2.11;0.8.1.1: not found  org.scalamacros#quasiquotes_2.11;2.0.1: not found [error] Total time: 27 s; completed 27-Mar-2015 14:24:39,1,0,1
594,SPARK-6438,SPARK-7296,Fixed,Indicate which tasks ran on which executors in per-stage visualization in UI,Timeline view for Stage page,1,1,1
595,SPARK-6439,SPARK-7296,Fixed,Show per-task metrics when you hover over a task in the web UI visualization,Timeline view for Stage page,1,1,1
596,SPARK-6442,SPARK-10989,Unresolved,MLlib Local Linear Algebra Package,Add the dot and hadamard products to the Vectors object,1,0,1
597,SPARK-6443,SPARK-8941,Fixed,Support HA in standalone cluster mode,Standalone cluster worker does not accept multiple masters on launch,0,0,1
598,SPARK-6443,SPARK-6801,Fixed,Support HA in standalone cluster mode,spark-submit is not able to identify Alive Master in case of multiple master,0,1,1
599,SPARK-6461,SPARK-7193,Duplicate,spark.executorEnv.PATH in spark-defaults.conf is not pass to mesos,Spark on Mesos may need more tests for spark 1.3.1 release,0,1,1
600,SPARK-6476,SPARK-12482,Unresolved,Spark fileserver not started on same IP as using spark.driver.host,Spark fileserver not started on same IP as configured in spark.driver.host,1,1,1
601,SPARK-6482,SPARK-6507,Not A Problem,Remove synchronization of Hive Native commands,Create separate Hive Driver instance for each SQL query in HiveThriftServer2,1,0,1
602,SPARK-6508,SPARK-7736,Duplicate,error handling issue running python in yarn cluster mode ,Exception not failing Python applications (in yarn cluster mode),1,1,1
603,SPARK-6511,SPARK-8061,Fixed,"Publish ""hadoop provided"" build with instructions for different distros","Document how to use ""hadoop provided"" builds",0,1,1
604,SPARK-6551,SPARK-9021,Duplicate,Incorrect aggregate results if seqOp(...) mutates its first argument, Change RDD.aggregate() to do reduce(mapPartitions()) instead of mapPartitions.fold(),1,1,1
605,SPARK-6566,SPARK-7117,Fixed,Update Spark to use the latest version of Parquet libraries,SparkSQL and Spark sometimes throw exceptions when reading Parquet files.,0,1,1
606,SPARK-6566,SPARK-7340,Fixed,Update Spark to use the latest version of Parquet libraries,Use latest parquet release 1.6.0 in spark,1,1,1
607,SPARK-6583,SPARK-7963,Fixed,Support aggregated function in order by,order by should support aggregate functions,1,1,1
608,SPARK-6589,SPARK-20252,Not A Problem,SQLUserDefinedType failed in spark-shell,java.lang.ClassNotFoundException: $line22.$read$$iwC$$iwC$movie_row,0,1,1
609,SPARK-6609,SPARK-6610,Invalid,explicit checkpoint does not work,mlllib explicit ALS checkpoint does not work,1,0,1
610,SPARK-6649,SPARK-8004,Fixed,DataFrame created through SQLContext.jdbc() failed if columns table must be quoted,Spark does not enclose column names when fetchting from jdbc sources,1,0,1
611,SPARK-6654,SPARK-7679,Duplicate,Update Kinesis Streaming impls (both KCL-based and Direct) to use latest aws-java-sdk and kinesis-client-library,Update AWS SDK and KCL versions to 1.2.1,1,0,1
612,SPARK-6668,SPARK-6890,Duplicate,repeated asking to remove non-existent executor,Local cluster mode is broken with SPARK_PREPEND_CLASSES,1,0,1
613,SPARK-6674,SPARK-7186,Duplicate,Use different types to represent rows used inside and outside Catalyst,Decouple internal Row from external Row,1,0,1
614,SPARK-6680,SPARK-21668,Duplicate,Be able to specifie IP for spark-shell(spark driver) blocker for Docker integration,Ability to run driver programs within a container,0,1,1
615,SPARK-6684,SPARK-10433,Fixed,Add checkpointing to GradientBoostedTrees,Gradient boosted trees: increasing input size in 1.4,1,1,1
616,SPARK-6690,SPARK-6933,Fixed,spark-sql script ends up throwing Exception when event logging is enabled.,Thrift Server couldn't strip .inprogress suffix after being stopped,1,0,1
617,SPARK-6700,SPARK-6701,Duplicate,flaky test: run Python application in yarn-cluster mode ,Flaky test: o.a.s.deploy.yarn.YarnClusterSuite Python application,0,1,1
618,SPARK-6708,SPARK-6835,Fixed,Using Hive UDTF may throw ClassNotFoundException,Hive UDTF with Lateral View cause ClassNotFoundException,1,1,1
619,SPARK-6718,SPARK-6720,Duplicate,Improve the test on normL1/normL2 of summary statistics,PySpark MultivariateStatisticalSummary unit test for normL1 and normL2,1,1,1
620,SPARK-6727,SPARK-11769,Duplicate,Model export/import for spark.ml: HashingTF,Model export/import for spark.ml: all basic Transformers,1,1,1
621,SPARK-6732,SPARK-6733,Duplicate,Scala existentials warning during compilation,Suppression of usage of Scala existential code should be done,1,0,1
622,SPARK-6755,SPARK-7361,Duplicate,Throw exception if the user tries to concurrently start multiple StreamingContexts in same JVM.,Throw unambiguous exception when attempting to start multiple StreamingContexts in the same JVM,1,0,1
623,SPARK-6758,SPARK-13451,Fixed,Block jetty's log as we have already shaded it,Spark shell prints error when :4040 port already in use,0,1,1
624,SPARK-6759,SPARK-7564,Won't Fix,Do not borrow/release a kryo instance for every value in a complex type value when doing serialization/deserialization in in-memory columnar store,performance bottleneck in SparkSQL using columnar storage,1,0,1
625,SPARK-6760,SPARK-7486,Unresolved,Sketch algorithms for SQL/DataFrames,Add the streaming implementation for estimating quantiles and median,0,1,1
626,SPARK-6761,SPARK-10862,Fixed,Approximate quantile,Univariate Statistics: Adding median & quantile support as UDAF,0,1,1
627,SPARK-6763,SPARK-12818,Duplicate,CountMinSketch,Implement Bloom filter and count-min sketch in DataFrames,1,1,1
628,SPARK-6774,SPARK-8811,Fixed,Implement Parquet complex types backwards-compatiblity rules,Read array struct data from parquet error,1,0,1
629,SPARK-6778,SPARK-6781,Duplicate,SQL contexts in spark-shell and pyspark should both be called sqlContext,sqlCtx -> sqlContext in pyspark shell,0,0,1
630,SPARK-6784,SPARK-7790,Duplicate,Make sure values of partitioning columns are correctly converted based on their data types,when use dynamic partitions; the partition string can be wrong without looking at the type,1,0,1
631,SPARK-6802,SPARK-10915,Fixed,User Defined Aggregate Function Refactoring,Add support for UDAFs in Python,0,1,1
632,SPARK-6884,SPARK-9016 ,Duplicate,Random forest: predict class probabilities,,0,0,1
633,SPARK-6891,SPARK-6954,Duplicate,ExecutorAllocationManager will request negative number executors,ExecutorAllocationManager can end up requesting a negative number of executors,0,0,1
634,SPARK-6896,SPARK-6930,Fixed,building error because of guava import,Build with Hive Thrift Server error; because of missing guava,0,0,1
635,SPARK-6904,SPARK-6910,Duplicate,SparkSql - HiveContext - optimize reading partition data from metastore,Support for pushing predicates down to metastore for partition pruning,1,0,1
636,SPARK-6910,SPARK-6984,Fixed,Support for pushing predicates down to metastore for partition pruning,Operations on tables with many partitions _very_slow,1,0,1
637,SPARK-6914,SPARK-9929,Duplicate,DataFrame.withColumn should take metadata,support adding metadata in withColumn,1,0,1
638,SPARK-6923,SPARK-7550,Duplicate,Spark SQL CLI does not read Data Source schema correctly,Support setting the right schema & serde when writing to Hive metastore,1,0,1
639,SPARK-6924,SPARK-7094,Won't Fix,driver hangs when net is broken,driver process will be suspend when driver network has down,0,1,1
640,SPARK-6925,SPARK-6926,Duplicate,Word2Vec's transform method throw IllegalStateException if a word not in vocabulary; but  findSynonyms(word: String; num: Int) method neither try catch exception nor throw exception. ,Word2Vec's transform method throw IllegalStateException if a word not in vocabulary; but  findSynonyms(word: String; num: Int) method neither try catch exception nor throw exception. ,1,0,1
641,SPARK-6929,SPARK-8104,Duplicate,Alias for more complex expression causes attribute not been able to resolve,move the auto alias logic into Analyzer,1,0,1
642,SPARK-6940,SPARK-6947,Fixed,PySpark CrossValidator,Make ml.tuning accessible from Python API,1,0,1
643,SPARK-6945,SPARK-8862,Fixed,Provide SQL tab in the Spark UI,Add a web UI page that visualizes physical plans (SparkPlan),0,1,1
644,SPARK-6946,SPARK-8862,Fixed,Add visualization of logical and physical plans for SQL/DataFrames,Add a web UI page that visualizes physical plans (SparkPlan),0,1,1
645,SPARK-6951,SPARK-9123,Unresolved,History server slow startup if the event log directory is large,Spark HistoryServer load logs too slow and can load the latest logs,0,1,1
646,SPARK-6951,SPARK-11123,Unresolved,History server slow startup if the event log directory is large,Inprove HistoryServer with multithread to relay logs,0,1,1
647,SPARK-6954,SPARK-7901,Fixed,ExecutorAllocationManager can end up requesting a negative number of executors,Attempt to request negative number of executors with dynamic allocation,1,1,1
648,SPARK-6961,SPARK-17305,Duplicate,Cannot save data to parquet files when executing from Windows from a Maven Project,Cannot save ML PipelineModel in pyspark;  PipelineModel.params still return null values,0,0,1
649,SPARK-7004,SPARK-7005,Duplicate,resetProb error in pagerank,resetProb error in pagerank,0,1,1
650,SPARK-7006,SPARK-10001,Duplicate,Inconsistent behavior for ctrl-c in Spark shells,Allow Ctrl-C in spark-shell to kill running job,0,1,1
651,SPARK-7009,SPARK-11157,Duplicate,Build assembly JAR via ant to avoid zip64 problems,Allow Spark to be built without assemblies,0,1,1
652,SPARK-7015,SPARK-7372,Fixed,Multiclass to Binary Reduction,Multiclass SVM - One vs All wrapper,0,0,1
653,SPARK-7019,SPARK-18692,Duplicate,Build docs on doc changes,Test Java 8 unidoc build on Jenkins master builder,0,1,1
654,SPARK-7041,SPARK-11225,Duplicate,Avoid writing empty files in BypassMergeSortShuffleWriter,Prevent generate empty file,0,0,1
655,SPARK-7041,SPARK-12400,Duplicate,Avoid writing empty files in BypassMergeSortShuffleWriter,Avoid writing a shuffle file if a partition has no output (empty),1,1,1
656,SPARK-7051,SPARK-13543,Duplicate,Support Compression write for Parquet,Support for specifying compression codec for Parquet/ORC via option(),1,0,1
657,SPARK-7051,SPARK-7062,Duplicate,Support Compression write for Parquet,Parquet compression does not work for Spark SQL loading,1,0,1
658,SPARK-7082,SPARK-9363,Duplicate,Binary processing external sort-merge join,SortMergeJoin operator should support UnsafeRow,1,1,1
659,SPARK-7089,SPARK-7090,Duplicate,Introduce LDAOptimizer to LDA to improve extensibility,Introduce LDAOptimizer to LDA to further improve extensibility,1,0,1
660,SPARK-7097,SPARK-8312,Won't Fix,Partitioned tables should only consider referred partitions in query during size estimation for checking against autoBroadcastJoinThreshold,Populate statistics info of hive tables if it's needed to be,1,0,1
661,SPARK-7104,SPARK-10729,Fixed,Support model save/load in Python's Word2Vec,word2vec model save for python,0,0,1
662,SPARK-7146,SPARK-12751,Fixed,Should ML sharedParams be a public API?,Traits generated by SharedParamsCodeGen should not be private,0,0,1
663,SPARK-7151,SPARK-7239,Duplicate,Correlation methods for DataFrame,Statistic functions for DataFrames,0,0,1
664,SPARK-7180,SPARK-8012,Fixed,SerializationDebugger fails with ArrayOutOfBoundsException,ArrayIndexOutOfBoundsException in SerializationDebugger,1,1,1
665,SPARK-7190,SPARK-7815,Fixed,UTF8String backed by binary data,Enable UTF8String to work against memory address directly,0,1,1
666,SPARK-7246,SPARK-7486,Fixed,Rank for DataFrames,Add the streaming implementation for estimating quantiles and median,0,1,1
667,SPARK-7252,SPARK-12523,Duplicate,Add support for creating new Hive and HBase delegation tokens,Support long-running of the Spark On HBase and hive meta store.,1,1,1
668,SPARK-7301,SPARK-13493,Duplicate,Issue with duplicated fields in interpreted json schemas,json to DataFrame to parquet does not respect case sensitiveness,1,0,1
669,SPARK-7325,SPARK-9381,Duplicate,Dataframe should support partitioned JSON Relation,Migrate JSON data source to the new partitioning data source,1,0,1
670,SPARK-7328,SPARK-7370,Fixed,Add missing items to pyspark.mllib.linalg.Vectors,Add missing items to pyspark.mllib.linalg.Vectors,1,1,1
671,SPARK-7330,SPARK-7364,Fixed,JDBC RDD could lead to NPE when the date field is null,NPE when reading null DATE columns from JDBC,1,1,1
672,SPARK-7354,SPARK-7414,Unresolved,Flaky test: o.a.s.deploy.SparkSubmitSuite --jars,Flaky test: o.a.s.deploy.SparkSubmitSuite --jars,0,1,1
673,SPARK-7355,SPARK-7415,Later,FlakyTest - o.a.s.DriverSuite,Flaky test: o.a.s.DriverSuite,0,1,1
674,SPARK-7366,SPARK-18352,Duplicate,Support multi-line JSON objects,Parse normal; multi-line JSON files (not just JSON Lines),0,0,1
675,SPARK-7397,SPARK-7405,Duplicate,Add missing input information report back to ReceiverInputDStream due to SPARK-7139,Fix the bug that ReceiverInputDStream doesn't report InputInfo,1,1,1
676,SPARK-7399,SPARK-7614,Fixed,Master fails on 2.11 with compilation error,CLONE - Master fails on 2.11 with compilation error,1,0,1
677,SPARK-7424,SPARK-13291,Unresolved,spark.ml classification; regression abstractions should add metadata to output column,Numerical models should preserve label attributes,1,0,1
678,SPARK-7425,SPARK-12015,Fixed,spark.ml Predictor should support other numeric types for label,Auto convert int to Double when required in pyspark.ml,0,0,1
679,SPARK-7439,SPARK-7503,Duplicate,Should delete temporary local directories,Resources in .sparkStaging directory can't be cleaned up on error,0,0,1
680,SPARK-7449,SPARK-7858,Duplicate,createPhysicalRDD should use RDD output as schema instead of relation.schema,DataSourceStrategy.createPhysicalRDD should use output schema when performing row conversions; not relation schema,1,0,1
681,SPARK-7460,SPARK-15383,Won't Fix,Provide DataFrame.zip (analog of RDD.zip) to merge two data frames,Support appending new columns from other DataFrames,1,1,1
682,SPARK-7471,SPARK-11112,Duplicate,DAG visualization: show call site information,DAG visualization: display RDD callsite,1,0,1
683,SPARK-7481,SPARK-15965,Fixed,Add spark-hadoop-cloud module to pull in object store support,No FileSystem for scheme: s3n or s3a  spark-2.0.0 and spark-1.6.1,1,1,1
684,SPARK-7497,SPARK-7908,Fixed,test_count_by_value_and_window is flaky,PySpark Streaming tests are flaky.,1,1,1
685,SPARK-7527,SPARK-10773,Fixed,Wrong detection of REPL mode in ClosureCleaner,"Repartition operation failing on RDD with ""argument type mismatch"" error",1,0,1
686,SPARK-7544,SPARK-10056,Fixed,pyspark.sql.types.Row should implement __getitem__,[Spark SQL] All result records will be popluated into ONE line during the script transform due to missing the correct line/filed delimiter,0,1,1
687,SPARK-7596,SPARK-8059,Duplicate,Let AM's Reporter thread to wake up from sleep if new executors required,Reduce latency between executor requests and RM heartbeat,1,0,1
688,SPARK-7632,SPARK-7633,Duplicate,Streaming Logistic Regression- Python bindings,Streaming Logistic Regression- Python bindings,1,1,1
689,SPARK-7657,SPARK-7928,Fixed,[MLLIB] feature.Word2Vec throws empty iterator error when the vocabulary size is zero,Yarn App Master Logs are not displayed in the spark historyserver UI,1,0,1
690,SPARK-7670,SPARK-7726,Duplicate,Failure when building with scala 2.11 (after 1.3.1,[SQL] Use PartialFunction literals instead of objects in Catalyst,1,0,1
691,SPARK-7683,SPARK-12595,Fixed,Confusing behavior of fold function of RDD in pyspark,fold should pass arguments to op in the correct order,1,0,1
692,SPARK-7703,SPARK-9591,Duplicate,Task failure caused by block fetch failure in BlockManager.doGetRemote() when using TorrentBroadcast,Job failed for exception during getting Broadcast variable,1,1,1
693,SPARK-7716,SPARK-8691,Duplicate,SparkUI stage page hangs with many tasks,Enable GZip for Web UI,1,0,1
694,SPARK-7727,SPARK-7823,Fixed,Avoid inner classes in RuleExecutor,[Mesos] Allow provisioning of executor logging configuration ,1,0,1
695,SPARK-7729,SPARK-8172,Fixed,Executor which has been killed should also be displayed on Executors Tab.,Driver UI should enable viewing of dead executors' logs,1,0,1
696,SPARK-7729,SPARK-12713,Fixed,Executor which has been killed should also be displayed on Executors Tab.,UI Executor page should keep links around to executors that died,1,0,1
697,SPARK-7729,SPARK-8100,Fixed,Executor which has been killed should also be displayed on Executors Tab.,Make able to refer lost executor log,1,1,1
698,SPARK-7730,SPARK-7731,Fixed,Complex Teradata queries throwing Analysis Exception when running on spark,Complex Teradata queries throwing Analysis Exception when running on spark,0,1,1
699,SPARK-7736,SPARK-9416,Fixed,Exception not failing Python applications (in yarn cluster mode),Yarn logs say that Spark Python job has succeeded even though job has failed in Yarn cluster mode,0,1,1
700,SPARK-7736,SPARK-8612,Fixed,Exception not failing Python applications (in yarn cluster mode),Yarn application status is misreported for failed PySpark apps.,1,0,1
701,SPARK-7756,SPARK-8438,Fixed,Ensure Spark runs clean on IBM Java implementation,Http SSLfailure with IBM java,1,1,1
702,SPARK-7758,SPARK-7759,Fixed,Failed to start thrift server when metastore is postgre sql,Failed to start thrift server when metastore is postgre sql,1,0,1
703,SPARK-7768,SPARK-20740,Unresolved,Make user-defined type (UDT) API public,Expose UserDefinedType make sure could extends it,1,0,1
704,SPARK-7797,SPARK-7997,Duplicate,"Remove ""actorSystem"" from SparkEnv",Remove the developer api SparkEnv.actorSystem and AkkaUtils,1,1,1
705,SPARK-7798,SPARK-7995,Duplicate,"Move ""AkkaRpcEnv"" to a separate project",Remove AkkaRpcEnv and remove Akka from the dependencies of Core,1,1,1
706,SPARK-7812,SPARK-7956,Duplicate,Speed up SQL code generation,Use Janino to compile SQL expression,1,0,1
707,SPARK-7813,SPARK-8117,Duplicate,Push code generation into expression definition,Push codegen into Expression,1,0,1
708,SPARK-7814,SPARK-8461,Duplicate,Turn code generation on by default,ClassNotFoundException when code generation is enabled,1,0,1
709,SPARK-7818,SPARK-7820,Duplicate,Java 8 test suite compile error under SBT,Java8-tests suite compile error under SBT,0,0,1
710,SPARK-7819,SPARK-9275,Fixed,Isolated Hive Client Loader appears to cause Native Library libMapRClient.4.0.2-mapr.so already loaded in another classloader error,IsolatedClientLoader could not load shared JNI libraries,1,0,1
711,SPARK-7821,SPARK-9763,Duplicate,Hide private SQL JDBC classes from Javadoc,Minimize exposure of internal SQL classes,0,1,1
712,SPARK-7851,SPARK-8020,Duplicate,SparkSQL cli built against Hive 0.13 throws exception when using with Hive 0.12 HCat,Spark SQL conf in spark-defaults.conf make metadataHive get constructed too early,1,0,1
713,SPARK-7879,SPARK-7881,Fixed,KMeans API for spark.ml Pipelines,KMeans API for spark.ml Pipelines,1,0,1
714,SPARK-7885,SPARK-7936,Unresolved,add config to control map aggregation in spark sql,Add configuration for initial size and limit of hash for aggregation,1,1,1
715,SPARK-7889,SPARK-8275,Fixed,Jobs progress of apps on complete page of HistoryServer shows uncompleted,HistoryServer caches incomplete App UIs,0,0,1
716,SPARK-7891,SPARK-13697,Duplicate,Python class in __main__ may trigger AssertionError,TransformFunctionSerializer.loads doesn't restore the function's module name if it's '__main__',1,0,1
717,SPARK-7902,SPARK-7903,Fixed,SQL UDF doesn't support UDT in PySpark,PythonUDT shouldn't get serialized on the Scala side,1,0,1
718,SPARK-7904,SPARK-7905,Not A Problem,Exclude parquet 1.3.2 from Hive,Exclude parquet 1.3.2 from Hive,1,1,1
719,SPARK-7904,SPARK-7906,Not A Problem,Exclude parquet 1.3.2 from Hive,Exclude parquet 1.3.2 from Hive,1,1,1
720,SPARK-7922,SPARK-7923,Fixed,ALSModel in the pipeline API should return DataFrames for factors,ALSModel in the pipeline API should return DataFrames for factors,1,1,1
721,SPARK-7947,SPARK-7948,Unresolved,Serdes Command not working ,Serdes Command not working in Spark 1.3.1,1,1,1
722,SPARK-7955,SPARK-9197,Fixed,Dynamic allocation: longer timeout for executors with cached blocks,Cached RDD partitions are lost when executors are dynamically deallocated,0,0,1
723,SPARK-7981,SPARK-8738,Duplicate,Improve DataFrame Python exception,Generate better error message in Python for AnalysisException ,0,1,1
724,SPARK-8009,SPARK-8798,Unresolved,[SparkR] Create worker R processes with a command other then Rscript,Allow additional uris to be fetched with mesos,1,1,1
725,SPARK-8033,SPARK-8034,Duplicate,spark-sql thriftserver security authorization bugs!,spark-sql security authorization bug,1,1,1
726,SPARK-8036,SPARK-8037,Duplicate,"Ignores files whose name starts with ""."" while enumerating files in HadoopFsRelation","Ignores files whose name starts with ""."" while enumerating files in HadoopFsRelation",1,1,1
727,SPARK-8048,SPARK-9236,Duplicate,Explicit partitionning of an RDD with 0 partition will yield empty outer join,Left Outer Join with empty JavaPairRDD returns empty RDD,0,0,1
728,SPARK-8052,SPARK-8892,Fixed,Hive on Spark: CAST string AS BIGINT produces wrong value,Column.cast(LongType) does not work for large values,0,1,1
729,SPARK-8057,SPARK-8311,Fixed,Call TaskAttemptContext.getTaskAttemptID using Reflection,saveAsTextFile with Hadoop1 could lead to errors,1,1,1
730,SPARK-8105,SPARK-8107,Fixed,"sqlContext.table(""databaseName.tableName"") broke with SPARK-6908",sqlContext.table() should be able to take a database name as an additional argument.,1,0,1
731,SPARK-8105,SPARK-8550,Fixed,"sqlContext.table(""databaseName.tableName"") broke with SPARK-6908",[SparkR] SparkSQL tests fail in R 3.2,1,0,1
732,SPARK-8118,SPARK-9631,Unresolved,Turn off noisy log output produced by Parquet 1.7.0,Giant pile of parquet log when trying to read local data,1,0,1
733,SPARK-8118,SPARK-13735,Unresolved,Turn off noisy log output produced by Parquet 1.7.0,Log for parquet relation reading files is too verbose,1,0,1
734,SPARK-8119,SPARK-9375,Fixed,HeartbeatReceiver should not adjust application executor resources,The total number of  executor(s) requested by  the driver may be negative,1,1,1
735,SPARK-8119,SPARK-11181,Fixed,HeartbeatReceiver should not adjust application executor resources,Spark Yarn : Spark reducing total executors count even when Dynamic Allocation is disabled.,0,0,1
736,SPARK-8119,SPARK-8374,Fixed,HeartbeatReceiver should not adjust application executor resources,Job frequently hangs after YARN preemption,0,1,1
737,SPARK-8125,SPARK-9347,Fixed,Accelerate ParquetRelation2 metadata discovery,spark load of existing parquet files extremely slow if large number of files,1,0,1
738,SPARK-8128,SPARK-11103,Duplicate,Schema Merging Broken: Dataframe Fails to Recognize Column in Schema,Parquet filters push-down may cause exception when schema merging is turned on,0,0,1
739,SPARK-8159,SPARK-9845,Fixed,Improve expression function coverage (Spark 1.5),Add built-in UDF,1,1,1
740,SPARK-8170,SPARK-10553,Fixed,Ctrl-C in pyspark shell doesn't kill running job,Allow Ctrl-C in pyspark shell to kill running job,1,1,1
741,SPARK-8174,SPARK-9374,Fixed,date/time function: unix_timestamp,unix_timestamp throws AnalysisException,1,1,1
742,SPARK-8186,SPARK-8421,Fixed,date/time function: date_add,Spark SQL DATE_ADD function - Spark 1.3.1 & 1.4.0,1,0,1
743,SPARK-8233,SPARK-12480,Duplicate,misc function: hash,add Hash expression that can calculate hash value for a group of expressions,1,1,1
744,SPARK-8276,SPARK-8754,Duplicate,NPE in YarnClientSchedulerBackend.stop,YarnClientSchedulerBackend doesn't stop gracefully in failure conditions,1,1,1
745,SPARK-8287,SPARK-11973,Duplicate,Filters not pushed with substitution through aggregation,Filter pushdown does not work with aggregation with alias,1,0,1
746,SPARK-8321,SPARK-19625,Won't Fix,Authorization Support(on all operations not only DDL) in Spark Sql,Authorization Support(on all operations not only DDL) in Spark Sql version 2.1.0,0,1,1
747,SPARK-8322,SPARK-9382,Fixed,EC2 script not fully updated for 1.4.0 release,Tachyon version mismatch,1,1,1
748,SPARK-8328,SPARK-9293,Duplicate,Add a CheckAnalysis rule to ensure that Union branches have the same schema,Analysis should detect when set operations are performed on tables with different numbers of columns,1,1,1
749,SPARK-8365,SPARK-8368,Duplicate,pyspark does not retain --packages or --jars passed on the command line as of 1.4.0,ClassNotFoundException in closure for map ,0,1,1
750,SPARK-8368,SPARK-8470,Fixed,ClassNotFoundException in closure for map ,MissingRequirementError for ScalaReflection on user classes,1,1,1
751,SPARK-8390,SPARK-8412,Fixed,Update DirectKafkaWordCount examples to show how offset ranges can be used,java#KafkaUtils.createDirectStream Java(Pair)RDDs do not implement HasOffsetRanges,1,0,1
752,SPARK-8395,SPARK-9007,Fixed,spark-submit documentation is incorrect,start-slave.sh changed API in 1.4 and the documentation got updated to mention the old API,1,0,1
753,SPARK-8405,SPARK-21013,Fixed,Show executor logs on Web UI when Yarn log aggregation is enabled,Spark History Server does not show the logs of completed Yarn Jobs,1,0,1
754,SPARK-8405,SPARK-9311,Fixed,Show executor logs on Web UI when Yarn log aggregation is enabled,Enable the ability to view centrally aggregated YARN logs for Spark Executors in the History Server UI,0,0,1
755,SPARK-8425,SPARK-8426,Fixed,Add blacklist mechanism for task scheduling,Add blacklist mechanism for YARN container allocation,1,1,1
756,SPARK-8428,SPARK-13850,Fixed,TimSort Comparison method violates its general contract with CLUSTER BY,TimSort Comparison method violates its general contract,0,1,1
757,SPARK-8443,SPARK-9058,Fixed,GenerateMutableProjection Exceeds JVM Code Size Limits,if set `spark.sql.codegen` is true;More than 100 aggregation operation; it exceeds JVM code size limits,1,1,1
758,SPARK-8463,SPARK-9985,Fixed,No suitable driver found for write.jdbc,DataFrameWriter jdbc method ignore options that have been set,0,1,1
759,SPARK-8465,SPARK-8710,Duplicate,ScalaReflectionException with DataFrames in 1.4,ScalaReflection.mirror should be a def,1,1,1
760,SPARK-8473,SPARK-9889,Fixed,Documentation for DCT,DCT User Guide,1,0,1
761,SPARK-8480,SPARK-20539,Unresolved,Add setName for Dataframe,support optional dataframe name,1,0,1
762,SPARK-8480,SPARK-21265,Unresolved,Add setName for Dataframe,Cache method could specified name,1,0,1
763,SPARK-8499,SPARK-8600,Duplicate,NaiveBayes implementation for MLPipeline,Naive Bayes API for spark.ml Pipelines,1,1,1
764,SPARK-8500,SPARK-14536,Unresolved,Support for array types in JDBCRDD,NPE in JDBCRDD when array column contains nulls (postgresql),1,1,1
765,SPARK-8516,SPARK-10025,Unresolved,ML attribute API in PySpark,Add Python API for ml.attribute,1,1,1
766,SPARK-8552,SPARK-10416,Fixed,Using incorrect database in multiple sessions,Thrift Server cannot do isolation for different users,1,1,1
767,SPARK-8568,SPARK-8573,Fixed,"Prevent accidental use of ""and"" and ""or"" to build invalid expressions in Python",For PySpark's DataFrame API; we need to throw exceptions when users try to use and/or/not,0,1,1
768,SPARK-8570,SPARK-8717,Fixed,Improve MLlib Local Matrix Documentation.,"Update mllib-data-types docs to include missing ""matrix"" Python examples",0,1,1
769,SPARK-8582,SPARK-8666,Unresolved,Optimize checkpointing to avoid computing an RDD twice,checkpointing does not take advantage of persisted/cached RDDs,0,1,1
770,SPARK-8585,SPARK-12362,Duplicate,Support LATERAL VIEW in Spark SQL parser,Create a full-fledged built-in SQL parser,1,0,1
771,SPARK-8586,SPARK-11421,Duplicate,SQL add jar command does not work well with Scala REPL,Add the ability to add a jar to the current class loader,0,0,1
772,SPARK-8593,SPARK-8594,Fixed,History Server doesn't show complete application when one attempt inprogress,History Server doesn't show complete application when one attempt inprogress,1,1,1
773,SPARK-8597,SPARK-8890,Duplicate,DataFrame partitionBy memory pressure scales extremely poorly,Reduce memory consumption for dynamic partition insert,1,0,1
774,SPARK-8616,SPARK-12437,Duplicate,SQLContext doesn't handle tricky column names when loading from JDBC,Reserved words (like table) throws error when writing a data frame to JDBC,1,1,1
775,SPARK-8616,SPARK-9505,Duplicate,SQLContext doesn't handle tricky column names when loading from JDBC,DataFrames : Mysql JDBC not support column names with special characters,0,1,1
776,SPARK-8617,SPARK-18733,Fixed,Handle history files better,Spark history server file cleaner excludes in-progress files,0,1,1
777,SPARK-8617,SPARK-17119,Fixed,Handle history files better,Add configuration property to allow the history server to delete .inprogress files,1,0,1
778,SPARK-8626,SPARK-8627,Duplicate,ALS model predict error,ALS model predict error,1,0,1
779,SPARK-8632,SPARK-10685,Fixed,Poor Python UDF performance because of RDD caching,Misaligned data with RDD.zip and DataFrame.withColumn after repartition,1,1,1
780,SPARK-8632,SPARK-10494,Fixed,Poor Python UDF performance because of RDD caching,Multiple Python UDFs together with aggregation or sort merge join may cause OOM (failed to acquire memory),1,0,1
781,SPARK-8719,SPARK-8996,Duplicate,Adding Python support for 1-sample; 2-sided Kolmogorov Smirnov Test,Add Python API for Kolmogorov-Smirnov Test,0,0,1
782,SPARK-8728,SPARK-15176,Duplicate,Add configuration for limiting the maximum number of active stages in a fair scheduling queue,Job Scheduling Within Application Suffers from Priority Inversion,0,0,1
783,SPARK-8734,SPARK-8737,Unresolved,Expose all Mesos DockerInfo options to Spark,Allow configuration of Docker networking for Mesos,1,1,1
784,SPARK-8743,SPARK-8895,Fixed,Deregister Codahale metrics for streaming when StreamingContext is closed ,MetricsSystem.removeSource not called in StreamingContext.stop,1,0,1
785,SPARK-8755,SPARK-8851,Duplicate,Streaming application from checkpoint will fail to load in security mode.,in Yarn client mode; Client.scala does not login even when credentials are specified,0,1,1
786,SPARK-8760,SPARK-10483,Fixed,allow moving and symlinking binaries,spark-submit can not support symbol link,0,0,1
787,SPARK-8773,SPARK-8926,Fixed,Throw type mismatch in check analysis for expressions with expected input types defined,Good errors for invalid input to ExpectsInput expressions,1,0,1
788,SPARK-8779,SPARK-10084,Duplicate,Add documentation for Python's FP-growth,Add Python example for mllib FP-growth user guide,0,1,1
789,SPARK-8797,SPARK-9146,Fixed,"Sorting float/double column containing NaNs can lead to ""Comparison method violates its general contract!"" errors",NaN should be greater than all other values,1,1,1
790,SPARK-8812,SPARK-8813,Duplicate,Support combine text/parquet format file in sql,Combine files when there're many small files in table,1,1,1
791,SPARK-8813,SPARK-13664,Duplicate,Combine files when there're many small files in table,Simplify and Speedup HadoopFSRelation,1,0,1
792,SPARK-8834,SPARK-8975,Duplicate,Throttle DStreams dynamically through back-pressure information,Implement a mechanism to send a new rate from the driver to the block generator,1,1,1
793,SPARK-8838,SPARK-9347,Fixed,Add config to enable/disable merging part-files when merging parquet schema,spark load of existing parquet files extremely slow if large number of files,1,1,1
794,SPARK-8840,SPARK-8897,Fixed,Float type coercion with hiveContext,SparkR DataFrame fail to return data of float type,1,1,1
795,SPARK-8847,SPARK-9427,Duplicate,String concatination with column in SparkR,Add expression functions in SparkR,1,1,1
796,SPARK-8869,SPARK-8898,Duplicate,DataFrameWriter save action makes DataFrameReader load failed,Jets3t hangs with more than 1 core,0,1,1
797,SPARK-8890,SPARK-8968,Fixed,Reduce memory consumption for dynamic partition insert,dynamic partitioning in spark sql performance issue due to the high GC overhead,1,0,1
798,SPARK-8900,SPARK-8901,Fixed,sparkPackages flag name is wrong in the documentation,[Windows] Application with Appname including whiteSpace fails in Yarn-client mode,1,0,1
799,SPARK-8917,SPARK-8920,Duplicate,Add @since tags to mllib.linalg,Add @since tags to mllib.linalg,1,1,1
800,SPARK-8934,SPARK-8942,Fixed,cast from double/float to timestamp should not go through decimal,use double not decimal when cast double and float to timestamp,1,0,1
801,SPARK-8941,SPARK-9007,Duplicate,Standalone cluster worker does not accept multiple masters on launch,start-slave.sh changed API in 1.4 and the documentation got updated to mention the old API,0,0,1
802,SPARK-8956,SPARK-8972,Duplicate,Rollup produces incorrect result when group by contains expressions,Incorrect result for rollup,1,0,1
803,SPARK-8962,SPARK-9339,Fixed,Disallow Class.forName,Use of Class.forName(String) should be replaced with version taking classloader,0,1,1
804,SPARK-8969,SPARK-8993,Fixed,move type-check from BinaryArithmetic and BinaryComparison to BinaryOperator,More comprehensive type checking in expressions,1,0,1
805,SPARK-9066,SPARK-10484,Fixed,Improve cartesian performance ,Minimum ratio of registered resources [ spark.scheduler.minRegisteredResourcesRatio] is not enabled for Mesos Coarse Grained mode,1,0,1
806,SPARK-9078,SPARK-10664,Fixed,Use of non-standard LIMIT keyword in JDBC tableExists code,JDBC DataFrameWriter does not save data to Oracle 11 Database,1,0,1
807,SPARK-9078,SPARK-10756,Fixed,Use of non-standard LIMIT keyword in JDBC tableExists code,DataFrame write to teradata using jdbc not working; tries to create table each time irrespective of table existence,1,0,1
808,SPARK-9078,SPARK-11173,Fixed,Use of non-standard LIMIT keyword in JDBC tableExists code,Cannot save data via MSSQL JDBC,0,0,1
809,SPARK-9078,SPARK-11623,Fixed,Use of non-standard LIMIT keyword in JDBC tableExists code,Sparksql-1.4.1 DataFrameWrite.jdbc() bug,0,0,1
810,SPARK-9098,SPARK-9793,Duplicate,Inconsistent Dense Vectors hashing between PySpark and Scala,PySpark DenseVector; SparseVector should override __eq__ and __hash__,0,0,1
811,SPARK-9116,SPARK-10467,Fixed,python UDT in __main__ cannot be serialized by PySpark,Vector is converted to tuple when extracted from Row using __getitem__,0,0,1
812,SPARK-9123,SPARK-9124,Duplicate,Spark HistoryServer load logs too slow and can load the latest logs,Spark HistoryServer load logs too slow and can load the latest logs,1,1,1
813,SPARK-9123,SPARK-9125,Duplicate,Spark HistoryServer load logs too slow and can load the latest logs,Spark HistoryServer load logs too slow and can load the latest logs,1,1,1
814,SPARK-9132,SPARK-9163,Fixed,Implement code gen for Conv,Implement code generation for Conv,1,1,1
815,SPARK-9196,SPARK-9406,Fixed,DatetimeExpressionsSuite: function current_timestamp is flaky,Flaky test: o.a.s.sql.DatetimeExpressionsSuite.function current_timestamp,0,0,1
816,SPARK-9211,SPARK-9274,Fixed,HiveComparisonTest generates incorrect file name for golden answer files on Windows,Tests using golden files can fail depending on new line characters in queries,0,0,1
817,SPARK-9219,SPARK-18015,Not A Problem,ClassCastException in instance of org.apache.spark.rdd.MapPartitionsRDD,CLONE - ClassCastException in instance of org.apache.spark.rdd.MapPartitionsRDD,1,1,1
818,SPARK-9219,SPARK-19938,Not A Problem,ClassCastException in instance of org.apache.spark.rdd.MapPartitionsRDD,java.lang.ClassCastException: cannot assign instance of scala.collection.immutable.List$SerializationProxy to field,0,1,1
819,SPARK-9239,SPARK-10765,Duplicate,HiveUDAF support for AggregateFunction2,use new aggregate interface for hive UDAF,1,0,1
820,SPARK-9254,SPARK-9341,Fixed,sbt-launch-lib.bash should use `curl --location` to support HTTP/HTTPS redirection,The curl command in sbt-launch-lib.bash doesn't download sbt-launch jar,1,0,1
821,SPARK-9332,SPARK-9368,Fixed,CatalystTypeConverters.toScala does not work on UnsafeRows,Support get(ordinal; dataType) generic getter in UnsafeRow,1,0,1
822,SPARK-9338,SPARK-14471,Unresolved,Aliases from SELECT not available in GROUP BY,The alias created in SELECT could be used in GROUP BY and followed expressions,1,1,1
823,SPARK-9341,SPARK-9684,Duplicate,The curl command in sbt-launch-lib.bash doesn't download sbt-launch jar,sbt/sbt assembly Error: Invalid or corrupt jarfile sbt/sbt-launch-0.13.6.jar,0,0,1
824,SPARK-9359,SPARK-10367,Duplicate,Support IntervalType for Parquet,Support Parquet logical type INTERVAL,1,1,1
825,SPARK-9370,SPARK-9425,Fixed,Support DecimalType in UnsafeRow,Support DecimalType in UnsafeRow,1,0,1
826,SPARK-9439,SPARK-14527,Fixed,ExternalShuffleService should be robust to NodeManager restarts in yarn,Job can't finish when restart all nodemanages with using external shuffle services,0,0,1
827,SPARK-9443,SPARK-10996,Duplicate,Expose sampleByKey in SparkR,Implement sampleBy() in DataFrameStatFunctions,1,1,1
828,SPARK-9444,SPARK-9512,Duplicate,RemoveEvaluationFromSort reorders sort order,RemoveEvaluationFromSort reorders sort order,1,1,1
829,SPARK-9447,SPARK-10578,Fixed,Python RandomForestClassifier probabilityCol; rawPredictionCol,pyspark.ml.classification.RandomForestClassifer does not return `rawPrediction` column,0,1,1
830,SPARK-9455,SPARK-9598,Duplicate,Remove InternalRow's generic getter (the one without data type),do not expose generic getter in internal row,1,1,1
831,SPARK-9456,SPARK-9632,Duplicate,Remove InternalRow.toSeq,update InternalRow.toSeq to make it accept data type info,1,1,1
832,SPARK-9494,SPARK-11837,Duplicate,'spark-ec2 launch' fails with anaconda python 3.4,spark_ec2.py breaks with python3 and m3 instances,1,1,1
833,SPARK-9499,SPARK-9827,Duplicate,Possible file handle leak in spilling/sort code,Too many open files in TungstenExchange,1,1,1
834,SPARK-9505,SPARK-12437,Duplicate,DataFrames : Mysql JDBC not support column names with special characters,Reserved words (like table) throws error when writing a data frame to JDBC,0,1,1
835,SPARK-9552,SPARK-10726,Fixed,Dynamic allocation kills busy executors on race condition,Using dynamic-executor-allocation;When jobs are submitted parallelly; executors will be removed before tasks finish,0,1,1
836,SPARK-9552,SPARK-10918,Fixed,Dynamic allocation kills busy executors on race condition,Task failed because executor kill by driver,0,1,1
837,SPARK-9654,SPARK-10021,Fixed,Add IndexToString in Pyspark,Add Python API for ml.feature.IndexToString,1,1,1
838,SPARK-9675,SPARK-9683,Duplicate,GenerateUnsafeProjection seems to corrupt MapType data,copy UTF8String when convert unsafe array/map to safe,1,0,1
839,SPARK-9685,SPARK-11628,Duplicate,Unsupported dataType: char(X) in Hive,spark-sql do not support for column datatype of CHAR,1,1,1
840,SPARK-9685,SPARK-11628,Duplicate,Unsupported dataType: char(X) in Hive,spark-sql do not support for column datatype of CHAR,1,1,1
841,SPARK-9687,SPARK-15685,Duplicate,System.exit() still disrupt applications embedding Spark,StackOverflowError (VirtualMachineError) or NoClassDefFoundError (LinkageError) should not System.exit() in local mode,0,0,1
842,SPARK-9701,SPARK-11562,Duplicate,allow not automatically using HiveContext with spark-shell when hive support built in,Provide user an option to init SQLContext or HiveContext in spark shell,1,0,1
843,SPARK-9705,SPARK-9822,Fixed,outdated Python 3 and IPython information,Update doc about supported Python versions,0,0,1
844,SPARK-9708,SPARK-10975,Fixed,Spark should create local temporary directories in Mesos sandbox when launched with Mesos,Shuffle files left behind on Mesos without dynamic allocation,1,1,1
845,SPARK-9742,SPARK-9760,Duplicate,NullPointerException when using --packages,SparkSubmit doesn't work with --packages when --repositories is not specified ,1,1,1
846,SPARK-9745,SPARK-9795,Fixed,Applications hangs when the last executor fails with dynamic allocation,Dynamic allocation: avoid double counting when killing same executor twice,0,0,1
847,SPARK-9769,SPARK-10482,Fixed,Add Python API for ml.feature.CountVectorizer,Add Python interface for CountVectorizer,0,1,1
848,SPARK-9804,SPARK-9887,Fixed,isSrcLocal parameter in loadTable / loadPartition is incorrect for HDFS source data,After recent hive patches PySpark fails with IllegalArgumentException: Wrong FS: hdfs:,0,1,1
849,SPARK-9813,SPARK-9874,Fixed,Incorrect UNION ALL behavior,UnionAll operation on DataFrame doesn't check for column names,0,1,1
850,SPARK-9827,SPARK-9921,Fixed,Too many open files in TungstenExchange,Too many open files in Spark SQL,1,0,1
851,SPARK-9838,SPARK-12566,Duplicate,Support Poisson family in SparkR:::glm,GLM model family; link function support in SparkR:::glm,0,0,1
852,SPARK-9839,SPARK-12566,Duplicate,Support Gamma family in SparkR:::glm,GLM model family; link function support in SparkR:::glm,0,0,1
853,SPARK-9840,SPARK-12566,Duplicate,Support popular link functions in SparkR:::glm,GLM model family; link function support in SparkR:::glm,0,0,1
854,SPARK-9844,SPARK-12876,Fixed,File appender race condition during SparkWorker shutdown,Race condition when driver rapidly shutdown after started.,1,0,1
855,SPARK-9846,SPARK-9897,Fixed,User guide for Multilayer Perceptron Classifier,User Guide for Multilayer Perceptron Classifier,0,1,1
856,SPARK-9862,SPARK-16753,Unresolved,Join: Handling data skew,Spark SQL doesn't handle skewed dataset joins properly,1,1,1
857,SPARK-9862,SPARK-17788,Unresolved,Join: Handling data skew,RangePartitioner results in few very large tasks and many small to empty tasks ,0,1,1
858,SPARK-9919,SPARK-10414,Unresolved,Matrices should respect Java's equals and hashCode contract,DenseMatrix gives different hashcode even though equals returns true,1,0,1
859,SPARK-9926,SPARK-10340,Fixed,Parallelize file listing for partitioned Hive table,Use S3 bulk listing for S3-backed Hive tables,1,1,1
860,SPARK-9976,SPARK-11609,Duplicate,create function do not work,Resolve permanent Hive UDFs,1,1,1
861,SPARK-10001,SPARK-10396,Fixed,Allow Ctrl-C in spark-shell to kill running job,spark-sql ctrl+c does not exit,0,0,1
862,SPARK-10001,SPARK-13412,Fixed,Allow Ctrl-C in spark-shell to kill running job,Spark Shell Ctrl-C behaviour suggestion,1,1,1
863,SPARK-10006,SPARK-10149,Duplicate,Locality broken in spark 1.4.x for NewHadoopRDD,"Locality Level is ANY on ""Details for Stage"" WebUI page",0,0,1
864,SPARK-10027,SPARK-10111,Fixed,Add Python API missing methods for ml.feature,"StringIndexerModel lacks of method ""labels""",1,1,1
865,SPARK-10027,SPARK-10110,Fixed,Add Python API missing methods for ml.feature,"StringIndexer lacks of parameter ""handleInvalid"".",1,1,1
866,SPARK-10030,SPARK-10422,Duplicate,Managed memory leak detected when cache table,String column in InMemoryColumnarCache needs to override clone method,1,0,1
867,SPARK-10045,SPARK-10844,Fixed,Add support for DataFrameStatFunctions in SparkR,SparkR: Add correlation function to dataframe,1,1,1
868,SPARK-10066,SPARK-10528,Duplicate,Can't create HiveContext with spark-shell or spark-sql on snapshot,spark-shell throws java.lang.RuntimeException: The root scratch dir: /tmp/hive on HDFS should be writable.,0,1,1
869,SPARK-10091,SPARK-10142,Duplicate,PySpark Streaming doesn't support Context recovery from checkpoint in HDFS,Python Streaming checkpoint recovery does not work with non-local file path,1,0,1
870,SPARK-10101,SPARK-10849,Duplicate,Spark JDBC writer mapping String to TEXT or VARCHAR,Allow user to specify database column type for data frame fields when writing data to jdbc data sources. ,1,0,1
871,SPARK-10109,SPARK-20038,Duplicate,NPE when saving Parquet To HDFS,FileFormatWriter.ExecuteWriteTask.releaseResources() implementations to be re-entrant,0,0,1
872,SPARK-10114,SPARK-11962,Duplicate,Add optional getters to the spark.sql.Row,[Spark SQL] the value of 'hiveconf' parameter in CLI can't be got after enter spark-sql session,1,0,1
873,SPARK-10186,SPARK-12266,Fixed,Add support for more postgres column types,cannot handle postgis raster type,0,1,1
874,SPARK-10196,SPARK-10298,Fixed,Failed to save json data with a decimal type in the schema,PySpark can't JSON serialize a DataFrame with DecimalType columns.,1,0,1
875,SPARK-10197,SPARK-10302,Fixed,Add null check in wrapperFor (inside HiveInspectors).,NPE while save a DataFrame as ORC,1,0,1
876,SPARK-10216,SPARK-15393,Fixed,Avoid creating empty files during overwrite into Hive table with group by query,Writing empty Dataframes doesn't save any _metadata files,1,0,1
877,SPARK-10216,SPARK-21105,Fixed,Avoid creating empty files during overwrite into Hive table with group by query,Useless empty files in hive table,1,1,1
878,SPARK-10301,SPARK-10428,Fixed,For struct type; if parquet's global schema has less fields than a file's schema; data reading will fail,Struct fields read from parquet are mis-aligned,1,1,1
879,SPARK-10312,SPARK-13119,Unresolved,Enhance SerDe to handle atomic vector,"SparkR Ser/De fail to handle ""columns(df)""",1,1,1
880,SPARK-10318,SPARK-17614,Duplicate,Getting issue in spark connectivity with cassandra,"sparkSession.read() .jdbc(***) use the sql syntax ""where 1=0"" that Cassandra does not support",1,1,1
881,SPARK-10335,SPARK-15042,Unresolved,GraphX Connected Components fail with large number of iterations,ConnectedComponents fails to compute graph with 200 vertices (but long paths),1,1,1
882,SPARK-10342,SPARK-11348,Fixed,Cooperative memory management,Replace addOnCompleteCallback with addTaskCompletionListener() in UnsafeExternalSorter,0,0,1
883,SPARK-10346,SPARK-12235,Fixed,SparkR mutate and transform should replace column with same name to match R data.frame behavior,Enhance mutate() to support replace existing columns,1,1,1
884,SPARK-10346,SPARK-12235,Fixed,SparkR mutate and transform should replace column with same name to match R data.frame behavior,Enhance mutate() to support replace existing columns,1,1,1
885,SPARK-10371,SPARK-11990,Fixed,Optimize sequential projections,DataFrame recompute UDF in some situation.,0,0,1
886,SPARK-10433,SPARK-10616,Duplicate,Gradient boosted trees: increasing input size in 1.4,GradientBoostedTrees stuck with 2958359 features train data,1,1,1
887,SPARK-10433,SPARK-10629,Duplicate,Gradient boosted trees: increasing input size in 1.4,Gradient boosted trees: mapPartitions input size increasing ,1,1,1
888,SPARK-10436,SPARK-14845,Duplicate,spark-submit overwrites spark.files defaults with the job script filename,spark.files in properties file is not distributed to driver in yarn-cluster mode,0,1,1
889,SPARK-10458,SPARK-10701,Fixed,Would like to know if a given Spark Context is stopped or currently stopping,Expose SparkContext#stopped flag with @DeveloperApi,0,1,1
890,SPARK-10461,SPARK-14983,Fixed,make sure `input.primitive` is always variable name not code at GenerateUnsafeProjection,Getting CompileException when feed an UDF with an array and another paramter,0,0,1
891,SPARK-10494,SPARK-10685,Fixed,Multiple Python UDFs together with aggregation or sort merge join may cause OOM (failed to acquire memory),Misaligned data with RDD.zip and DataFrame.withColumn after repartition,1,0,1
892,SPARK-10494,SPARK-10714,Fixed,Multiple Python UDFs together with aggregation or sort merge join may cause OOM (failed to acquire memory),Refactor PythonRDD to decouple iterator computation from PythonRDD,0,0,1
893,SPARK-10506,SPARK-11124,Duplicate,There exits some potential resource leak  in jsonExpressions.scala,JsonParser/Generator should be closed for resource recycle,0,0,1
894,SPARK-10523,SPARK-11349,Duplicate,SparkR formula syntax to turn strings/factors into numerics,Support transform string label for RFormula,0,1,1
895,SPARK-10525,SPARK-14514,Fixed,Add Python example for VectorSlicer to user guide,Add python example for VectorSlicer,1,1,1
896,SPARK-10528,SPARK-12435,Not A Problem,spark-shell throws java.lang.RuntimeException: The root scratch dir: /tmp/hive on HDFS should be writable.,Installing Spark,0,0,1
897,SPARK-10528,SPARK-12190,Not A Problem,spark-shell throws java.lang.RuntimeException: The root scratch dir: /tmp/hive on HDFS should be writable.,spark does not start cleanly windows 7 64 bit,0,0,1
898,SPARK-10530,SPARK-13965,Fixed,Kill other task attempts when one taskattempt belonging the same task is succeeded in speculation,TaskSetManager should kill the other running task attempts if any one task attempt succeeds for the same task,0,0,1
899,SPARK-10531,SPARK-10571,Fixed,AppId is set as AppName in status rest api,Spark REST / JSON API mixes up application names and application ids,0,0,1
900,SPARK-10531,SPARK-10927,Fixed,AppId is set as AppName in status rest api,Spark history uses the application name instead of the ID,0,0,1
901,SPARK-10539,SPARK-10727,Fixed,Intersection Optimization is Wrong,Dataframe count is zero after 'except' operation,1,0,1
902,SPARK-10539,SPARK-11430,Fixed,Intersection Optimization is Wrong,DataFrame's except method does not work; returns 0,1,0,1
903,SPARK-10541,SPARK-11375,Fixed,Allow ApplicationHistoryProviders to provide their own text when there aren't any complete apps,"History Server ""no histories"" message to be dynamically generated by ApplicationHistoryProviders",0,1,1
904,SPARK-10542,SPARK-10544,Fixed,The  PySpark 1.5 closure serializer can't serialize a namedtuple instance.,Serialization of Python namedtuple subclasses in functions / closures is broken,1,0,1
905,SPARK-10574,SPARK-13968,Fixed,HashingTF should use MurmurHash3,Use MurmurHash3 for hashing String features,0,0,1
906,SPARK-10580,SPARK-11808,Fixed,Remove Bagel,Remove Bagel,1,1,1
907,SPARK-10602,SPARK-10641,Duplicate,Univariate statistics as UDAFs: single-pass continuous stats,skewness and kurtosis support,1,1,1
908,SPARK-10605,SPARK-13335,Fixed,collect_list() and collect_set() should accept struct types as argument,Optimize Data Frames collect_list and collect_set with declarative aggregates,1,0,1
909,SPARK-10622,SPARK-11298,Fixed,Race condition between scheduler and YARN executor status update,"When driver sends message ""GetExecutorLossReason"" to AM; the AM stops.",0,0,1
910,SPARK-10637,SPARK-12878,Duplicate,DataFrames: saving with nested User Data Types,Dataframe fails with nested User Defined Types,1,1,1
911,SPARK-10643,SPARK-20860,Fixed,Support remote application download in client mode spark submit,Make spark-submit download remote files to local in client mode,0,0,1
912,SPARK-10648,SPARK-10909,Fixed,Spark-SQL JDBC fails to set a default precision and scale when they are not defined in an oracle schema.,Spark sql jdbc fails for Oracle NUMBER type columns,1,0,1
913,SPARK-10678,SPARK-20179,Unresolved,Specialize PrefixSpan for single-item patterns,Major improvements to Spark's Prefix span,1,1,1
914,SPARK-10709,SPARK-11102,Duplicate,When loading a json dataset as a data frame; if the input path is wrong; the error message is very confusing,Uninformative exception when specifing non-exist input for JSON data source,1,1,1
915,SPARK-10709,SPARK-11220,Duplicate,When loading a json dataset as a data frame; if the input path is wrong; the error message is very confusing,SQL data source gives confusing error message when file not found,1,0,1
916,SPARK-10709,SPARK-11102,Duplicate,When loading a json dataset as a data frame; if the input path is wrong; the error message is very confusing,Uninformative exception when specifing non-exist input for JSON data source,1,1,1
917,SPARK-10722,SPARK-15403,Fixed,Uncaught exception: RDDBlockId not found in driver-heartbeater,LinearRegressionWithSGD fails on files more than 12Mb data ,0,0,1
918,SPARK-10724,SPARK-10866,Duplicate,SQL's floor() returns DOUBLE,[streaming] [flume] Gracefully shutdown Flume receiver threads,1,0,1
919,SPARK-10729,SPARK-18311,Duplicate,word2vec model save for python,CLONE - Support model save/load in Python's Word2Vec,0,0,1
920,SPARK-10750,SPARK-10751,Fixed,ML Param validate should print better error information,ML Param validate should print better error information,1,1,1
921,SPARK-10753,SPARK-10905,Duplicate,Implement freqItems() and sampleBy() in DataFrameStatFunctions,Export freqItems() for DataFrameStatFunctions in SparkR,1,0,1
922,SPARK-10775,SPARK-10873,Duplicate,add search keywords in history page ui,Change history to use datatables to support sorting columns and searching,1,0,1
923,SPARK-10775,SPARK-10874,Duplicate,add search keywords in history page ui,add Search box to History Page,1,0,1
924,SPARK-10777,SPARK-12705,Fixed,order by fails when column is aliased and projection includes windowed aggregate,Sorting column can't be resolved if it's not in projection,1,1,1
925,SPARK-10800,SPARK-10825,Duplicate,Flaky test: org.apache.spark.deploy.StandaloneDynamicAllocationSuite,Flaky test: StandaloneDynamicAllocationSuite,1,0,1
926,SPARK-10802,SPARK-15504,Won't Fix,Let ALS recommend for subset of data,Could MatrixFactorizationModel support recommend for some users only ?,1,0,1
927,SPARK-10812,SPARK-11201,Fixed,Spark Hadoop Util does not support stopping a non-yarn Spark Context & starting a Yarn spark context.,StreamContext.getOrCreate is broken is yarn-client mode,0,0,1
928,SPARK-10840,SPARK-18352,Duplicate,SparkSQL doesn't work well with JSON,Parse normal; multi-line JSON files (not just JSON Lines),1,0,1
929,SPARK-10842,SPARK-13902,Duplicate,Eliminate create duplicate stage while generate job dag,Make DAGScheduler not to create duplicate stage.,1,0,1
930,SPARK-10849,SPARK-11300,Fixed,Allow user to specify database column type for data frame fields when writing data to jdbc data sources. ,Support for string length when writing to JDBC,1,0,1
931,SPARK-10859,SPARK-11330,Fixed,Predicates pushed to InmemoryColumnarTableScan are not evaluated correctly,Filter operation on StringType after groupBy PERSISTED brings no results,0,1,1
932,SPARK-10872,SPARK-11924,Not A Problem,Derby error (XSDB6) when creating new HiveContext after restarting SparkContext,SparkContext stop method does not close HiveContexts,0,1,1
933,SPARK-10878,SPARK-21507,Unresolved,Race condition when resolving Maven coordinates via Ivy,Exception when using spark.jars.packages ,1,1,1
934,SPARK-10879,SPARK-12973,Later,spark on yarn support priority option,Support to set priority when submit spark application to YARN,0,1,1
935,SPARK-10884,SPARK-16198,Unresolved,Support prediction on single instance for regression and classification related models,Change the access level of the predict method in spark.ml.Predictor to public,1,0,1
936,SPARK-10893,SPARK-11009,Duplicate,Lag Analytic function broken,RowNumber in HiveContext returns negative values in cluster mode,0,0,1
937,SPARK-10894,SPARK-13436,Fixed,Add 'drop' support for DataFrame's subset function,py4j.Py4JException: Method createDirectStream([class org.apache.spark.streaming.api.java.JavaStreamingContext; class java.util.HashMap; class java.util.HashSet; class java.util.HashMap]) does not exist,1,1,1
938,SPARK-10899,SPARK-12126,Duplicate,Support JDBC pushdown for additional commands,JDBC datasource processes filters only commonly pushed down.,1,0,1
939,SPARK-10914,SPARK-15156,Fixed,UnsafeRow serialization breaks when two machines have different Oops size,String fields in Dataframe behaves weirdly when executor-memory >= 32GB,1,0,1
940,SPARK-10914,SPARK-11556,Fixed,UnsafeRow serialization breaks when two machines have different Oops size,High spark.executor.memory causes wrong result,1,1,1
941,SPARK-10914,SPARK-17706,Fixed,UnsafeRow serialization breaks when two machines have different Oops size,DataFrame losing string data in yarn mode,0,1,1
942,SPARK-10914,SPARK-11282,Fixed,UnsafeRow serialization breaks when two machines have different Oops size,Very strange broadcast join behaviour,0,0,1
943,SPARK-10925,SPARK-14948,Unresolved,Exception when joining DataFrames,Exception when joining DataFrames derived form the same DataFrame,1,1,1
944,SPARK-10925,SPARK-14948,Unresolved,Exception when joining DataFrames,Exception when joining DataFrames derived form the same DataFrame,1,1,1
945,SPARK-10925,SPARK-20093,Unresolved,Exception when joining DataFrames,Exception when Joining dataframe with another dataframe generated by applying groupBy transformation on original one,1,1,1
946,SPARK-10931,SPARK-13368,Fixed,PySpark ML Models should contain Param values,PySpark JavaModel fails to extract params from Spark side automatically,0,0,1
947,SPARK-10931,SPARK-12468,Fixed,PySpark ML Models should contain Param values,getParamMap in Pyspark ML API returns empty dictionary in example for Documentation,0,0,1
948,SPARK-10969,SPARK-19911,Duplicate,Spark Streaming Kinesis: Allow specifying separate credentials for Kinesis and DynamoDB,Add builder interface for Kinesis DStreams,1,0,1
949,SPARK-10979,SPARK-11231,Fixed,SparkR: Add merge to DataFrame,join returns schema with duplicated and ambiguous join columns,1,1,1
950,SPARK-11009,SPARK-11481,Fixed,RowNumber in HiveContext returns negative values in cluster mode,orderBy with multiple columns in WindowSpec does not work properly,0,0,1
951,SPARK-11009,SPARK-11452,Fixed,RowNumber in HiveContext returns negative values in cluster mode,Window functions give invalid values,0,0,1
952,SPARK-11012,SPARK-11148,Fixed,Canonicalize view definitions,Unable to create views,1,0,1
953,SPARK-11034,SPARK-20742,Fixed,Launcher: add support for monitoring Mesos apps,SparkAppHandle.getState() doesnt return the right state when the launch is done on a mesos master in cluster mode,0,0,1
954,SPARK-11034,SPARK-17504,Fixed,Launcher: add support for monitoring Mesos apps,Spark App Handle from SparkLauncher always returns UNKNOWN app state when used with Mesos in Client Mode ,0,0,1
955,SPARK-11036,SPARK-11080,Duplicate,AttributeReference should not be created outside driver,Incorporate per-JVM id into ExprId to prevent unsafe cross-JVM comparisions,1,1,1
956,SPARK-11039,SPARK-14079,Fixed,"Document all UI ""retained*"" configurations",Limit the number of queries on SQL UI,0,0,1
957,SPARK-11043,SPARK-11062,Fixed,"Hive Thrift Server will log warn ""Couldn't find log associated with operation handle""",Thrift server does not support operationLog,1,0,1
958,SPARK-11055,SPARK-11425,Duplicate,Use mixing hash-based and sort-based aggregation in TungstenAggregationIterator,Improve hybrid aggregation (sort-based after hash-based),0,1,1
959,SPARK-11055,SPARK-11486,Duplicate,Use mixing hash-based and sort-based aggregation in TungstenAggregationIterator,TungstenAggregate may fail when switching to sort-based aggregation when there are string in grouping columns and no aggregation buffer columns,1,0,1
960,SPARK-11061,SPARK-11064,Invalid,baidu,spark streaming checkpoint question,1,1,1
961,SPARK-11071,SPARK-11133,Fixed,Flaky test: o.a.s.launcher.LauncherServerSuite,Flaky test: o.a.s.launcher.LauncherServerSuite,1,0,1
962,SPARK-11083,SPARK-19511,Unresolved,insert overwrite table failed when beeline reconnect,insert into table does not work on second session of beeline,1,1,1
963,SPARK-11097,SPARK-12328,Fixed,Add connection established callback to lower level RPC layer so we don't need to check for new connections in NettyRpcHandler.receive,Add connectionEstablished callback to RpcHandler to monitor the new connections,1,1,1
964,SPARK-11098,SPARK-11230,Fixed,RPC message ordering is not guaranteed,Add Outbox to cache the sending messages to resolve the message disorder issue,1,1,1
965,SPARK-11103,SPARK-11428,Fixed,Parquet filters push-down may cause exception when schema merging is turned on,Schema Merging Broken for Some Queries,0,0,1
966,SPARK-11126,SPARK-12906,Fixed,A memory leak in SQLListener._stageIdToStageMetrics,LongSQLMetricValue cause memory leak on Spark 1.5.1,1,0,1
967,SPARK-11126,SPARK-11192,Fixed,A memory leak in SQLListener._stageIdToStageMetrics,Spark sql seems to leak org.apache.spark.sql.execution.ui.SQLTaskMetrics objects over time,1,0,1
968,SPARK-11130,SPARK-11251,Duplicate,TestHive fails on machines with few cores,Page size calculation is wrong in local mode,0,0,1
969,SPARK-11136,SPARK-13026,Unresolved,Warm-start support for ML estimator,Umbrella: Allow user to specify initial model when training,1,0,1
970,SPARK-11137,SPARK-11139,Fixed,Make StreamingContext.stop() exception-safe,Make SparkContext.stop() exception-safe,0,1,1
971,SPARK-11137,SPARK-11139,Fixed,Make StreamingContext.stop() exception-safe,Make SparkContext.stop() exception-safe,0,1,1
972,SPARK-11170,SPARK-21447,Duplicate,    EOFException on History server reading in progress lz4,Spark history server fails to render compressed inprogress history file in some cases.,1,0,1
973,SPARK-11204,SPARK-11205,Duplicate,Delegate to scala DataFrame API rather than print in python,Match the output of DataFrame#explain() in both scala api and python,1,1,1
974,SPARK-11223,SPARK-12810,Fixed,PySpark CrossValidatorModel does not output metrics for every param in paramGrid,PySpark CrossValidatorModel should support avgMetrics,1,0,1
975,SPARK-11246,SPARK-12167,Fixed,[Launcher] Launcher library fails is app resource is not added,Invoke the right sameResult function when plan is warpped with SubQueries,1,1,1
976,SPARK-11271,SPARK-11583,Duplicate,MapStatus too large for driver,Make MapStatus use less memory uage,0,1,1
977,SPARK-11290,SPARK-11291,Fixed,Implement trackStateByKey for improved state management,Implement trackStateByKey for improvement state management,0,1,1
978,SPARK-11317,SPARK-12241,Duplicate,YARN HBase token code shouldn't swallow invocation target exceptions,Improve failure reporting in Yarn client obtainTokenForHBase(),1,0,1
979,SPARK-11319,SPARK-13740,Duplicate,PySpark silently accepts null values in non-nullable DataFrame fields.,add null check for _verify_type in types.py,0,1,1
980,SPARK-11327,SPARK-13258,Fixed,spark-dispatcher doesn't pass along some spark properties,#NAME?,1,1,1
981,SPARK-11329,SPARK-11637,Fixed,Expand Star when creating a struct,Alias do not work with udf with * parameter,1,1,1
982,SPARK-11331,SPARK-11657,Duplicate,Kryo serializer broken with StringTypes,Bad Dataframe data read from parquet,0,0,1
983,SPARK-11334,SPARK-16708,Fixed,numRunningTasks can't be less than 0; or it will affect executor allocation,ExecutorAllocationManager.numRunningTasks can be negative when stage retry,0,1,1
984,SPARK-11334,SPARK-22312,Fixed,numRunningTasks can't be less than 0; or it will affect executor allocation,Spark job stuck with no executor due to bug in Executor Allocation Manager,0,1,1
985,SPARK-11336,SPARK-11418,Fixed,Include path to the source file in generated example code,Add link to the source file at the end of included example code,0,1,1
986,SPARK-11352,SPARK-12451,Fixed,codegen.GeneratePredicate fails due to unquoted comment,Regexp functions don't support patterns containing '*/',1,1,1
987,SPARK-11353,SPARK-13044,Duplicate,Writing to S3 buckets; which only support AWS4-HMAC-SHA256 fails with s3n URLs,saveAsTextFile(s3n://) doesn't support s3 Signature Version 4,1,1,1
988,SPARK-11374,SPARK-21379,Won't Fix,skip.header.line.count is ignored in HiveContext,skip.header.line.count is ignored in HiveContext,1,1,1
989,SPARK-11412,SPARK-21019,Unresolved,Support merge schema for ORC, read orc when some of the columns are missing in some files,0,1,1
990,SPARK-11421,SPARK-20019,Unresolved,Add the ability to add a jar to the current class loader,spark can not load alluxio fileSystem after adding jar,0,0,1
991,SPARK-11460,SPARK-18886,Duplicate,Locality waits should be based on task set creation time; not last launch time,Delay scheduling should not delay some executors indefinitely if one task is scheduled before delay timeout,1,1,1
992,SPARK-11494,SPARK-11668,Fixed,Expose R-like summary statistics in SparkR::glm for linear regression,R style summary stats in GLM package SparkR,0,0,1
993,SPARK-11512,SPARK-12394,Duplicate,Bucket Join,Support writing out pre-hash-partitioned data and exploit that in join optimizations to avoid shuffle (i.e. bucketing in Hive),1,1,1
994,SPARK-11548,SPARK-13014,Fixed,Replace example code in mllib-collaborative-filtering.md using include_example,Replace example code in mllib-collaborative-filtering.md using include_example,1,0,1
995,SPARK-11569,SPARK-12779,Fixed,StringIndexer transform fails when column contains nulls,StringIndexer should handle null,0,1,1
996,SPARK-11580,SPARK-12978,Duplicate,Just do final aggregation when there is no Exchange,Skip unnecessary final group-by when input data already clustered with group-by keys,1,1,1
997,SPARK-11609,SPARK-12051,Unresolved,Resolve permanent Hive UDFs,Can't register UDF from Hive thrift server,1,1,1
998,SPARK-11609,SPARK-11948,Unresolved,Resolve permanent Hive UDFs,Permanent UDF not work,1,0,1
999,SPARK-11611,SPARK-11944,Fixed,Python API for bisecting k-means,Python API for mllib.clustering.BisectingKMeans,0,0,1
1000,SPARK-11611,SPARK-11944,Fixed,Python API for bisecting k-means,Python API for mllib.clustering.BisectingKMeans,0,0,1
1001,SPARK-11617,SPARK-11648,Fixed,MEMORY LEAK: ByteBuf.release() was not called before it's garbage-collected,IllegalReferenceCountException in Spark workloads,0,1,1
1002,SPARK-11621,SPARK-11661,Duplicate,ORC filter pushdown not working properly after new unhandled filter interface.,We should still pushdown filters returned by a data source's unhandledFilters,1,0,1
1003,SPARK-11624,SPARK-11950,Fixed,Spark SQL CLI will set sessionstate twice,Exception throws when executing    exit;    in spark-sql,1,0,1
1004,SPARK-11634,SPARK-11769,Duplicate,Make simple transformers and estimators implement default read/write,Model export/import for spark.ml: all basic Transformers,1,0,1
1005,SPARK-11652,SPARK-11682,Fixed,Remote code execution with InvokerTransformer,Commons-collections object deserialization may expose remote command execution vulnerability,0,0,1
1006,SPARK-11652,SPARK-19943,Fixed,Remote code execution with InvokerTransformer,commons-collections has vulnerability: CVE-2015-6420,1,0,1
1007,SPARK-11653,SPARK-17771,Fixed,Would be very useful if spark-daemon.sh supported foreground operations,Allow start-master/slave scripts to start in the foreground,0,1,1
1008,SPARK-11657,SPARK-11737,Fixed,Bad Dataframe data read from parquet,String may not be serialized correctly with Kyro,0,1,1
1009,SPARK-11691,SPARK-13503,Duplicate,Allow to specify compression codec in HadoopFsRelation when saving ,Support to specify the (writing) option for compression codec for TEXT,1,0,1
1010,SPARK-11701,SPARK-13054,Duplicate,YARN - dynamic allocation and speculation active task accounting wrong,Always post TaskEnd event for tasks in cancelled stages,0,0,1
1011,SPARK-11704,SPARK-11982,Unresolved,Optimize the Cartesian Join,Improve performance of CartesianProduct,1,0,1
1012,SPARK-11711,SPARK-12511,Duplicate,Finalizer memory leak is pyspark,streaming driver with checkpointing unable to finalize leading to OOM,0,0,1
1013,SPARK-11724,SPARK-13341,Fixed,Casting integer types to timestamp has unexpected semantics,Casting Unix timestamp to SQL timestamp fails,1,0,1
1014,SPARK-11737,SPARK-14524,Fixed,String may not be serialized correctly with Kyro,In SparkSQL; it can't be select column of String type because of UTF8String when setting more than 32G for executors.,1,1,1
1015,SPARK-11753,SPARK-14989,Unresolved,Understand why allowNonNumericNumbers JSON option doesn't work,Upgrade to Jackson 2.7.3,0,1,1
1016,SPARK-11782,SPARK-19061,Unresolved,Master Web UI should link to correct Application UI in cluster mode,Master Web UI does not link to correct Application UI in standalone cluster mode,1,0,1
1017,SPARK-11823,SPARK-11931,Unresolved,HiveThriftBinaryServerSuite tests timing out; leaves hanging processes,org.apache.spark.sql.hive.thriftserver.HiveThriftBinaryServerSuite.test jdbc cancel is sometimes very slow,0,1,1
1018,SPARK-11832,SPARK-12202,Fixed,Spark shell does not work from sbt with scala 2.11,Pass additional Scala REPL options to the underlying REPL (2.11),1,0,1
1019,SPARK-11851,SPARK-14694,Unresolved,Unable to start spark thrift server against secured hive metastore(GSS initiate failed),Thrift Server + Hive Metastore + Kerberos doesn't work,1,0,1
1020,SPARK-11861,SPARK-12405,Fixed,Expose feature importances API for decision trees,Expose featureImportances on org.apache.spark.mllib.tree.RandomForest,0,0,1
1021,SPARK-11879,SPARK-17972,Duplicate,Checkpoint support for DataFrame/Dataset,Query planning slows down dramatically for large query plans even when sub-trees are cached,1,1,1
1022,SPARK-11882,SPARK-13904,Duplicate,Allow for running Spark applications against a custom coarse grained scheduler,Add support for pluggable cluster manager,0,0,1
1023,SPARK-11885,SPARK-12491,Fixed,UDAF may nondeterministically generate wrong results,UDAF result differs in SQL if alias is used,1,0,1
1024,SPARK-11896,SPARK-11970,Duplicate,[SQL] Support Persist/Cache and Unpersist in Dataset APIs,Add missing APIs in Dataset,1,1,1
1025,SPARK-11918,SPARK-17588,Fixed,Better error from WLS for cases like singular input,java.lang.AssertionError: assertion failed: lapack.dppsv returned 105. when running glm using gaussian link function.,0,1,1
1026,SPARK-11922,SPARK-11987,Fixed,   Python API for ml.feature.QuantileDiscretizer,Python API update for ChiSqSelector and QuantileDiscretizer,0,1,1
1027,SPARK-11923,SPARK-11987,Fixed,Python API for ml.feature.ChiSqSelector,Python API update for ChiSqSelector and QuantileDiscretizer,0,1,1
1028,SPARK-11927,SPARK-16784,Unresolved,configure log4j properties with spark-submit ,Configurable log4j settings,0,0,1
1029,SPARK-11934,SPARK-11970,Duplicate,Add getAsOpt[T] functions to org.apache.spark.sql.Row,Add missing APIs in Dataset,1,1,1
1030,SPARK-11938,SPARK-15113,Duplicate,Expose numFeatures in all ML PredictionModel for PySpark,Add missing numFeatures & numClasses to wrapped JavaClassificationModel,1,1,1
1031,SPARK-11940,SPARK-14420,Fixed,Python API for ml.clustering.LDA,keepLastCheckpoint Param for Python LDA with EM,1,0,1
1032,SPARK-11968,SPARK-20446,Fixed,ALS recommend all methods spend most of time in GC,Optimize the process of MLLIB ALS recommendForAll,1,1,1
1033,SPARK-11995,SPARK-17388,Duplicate,Partitioning Parquet by DateType,Support for inferring type date/timestamp/decimal for partition column,1,0,1
1034,SPARK-12014,SPARK-12497,Unresolved,Spark SQL query containing semicolon is broken in Beeline (related to HIVE-11100),thriftServer does not support semicolon in sql ,1,0,1
1035,SPARK-12016,SPARK-12680,Fixed,word2vec load model can't use findSynonyms to get words ,"Loading Word2Vec model in pyspark gives ""ValueError: too many values to unpack"" in  findSynonyms",0,1,1
1036,SPARK-12030,SPARK-12055,Fixed,Incorrect results when aggregate joined data,TimSort failing with error when writing a partitioned data set,1,1,1
1037,SPARK-12063,SPARK-13957,Duplicate,Group by Column Number identifier is not successfully parsed,Support group by ordinal in SQL,1,0,1
1038,SPARK-12100,SPARK-13330,Duplicate,bug in spark/python/pyspark/rdd.py portable_hash(),PYTHONHASHSEED is not propgated to python worker,1,0,1
1039,SPARK-12105,SPARK-12359,Unresolved,Add a DataFrame.show() with argument for output PrintStream,Add showString() to DataSet API.,1,1,1
1040,SPARK-12124,SPARK-12127,Invalid,Spark Sql MongoDB Cross Join Not Working,Spark sql Support Cross join with Mongo DB,0,1,1
1041,SPARK-12139,SPARK-13849,Unresolved,REGEX Column Specification for Hive Queries,REGEX Column Specification,1,1,1
1042,SPARK-12154,SPARK-14598,Fixed,Upgrade to Jersey 2,Can spark-mllib upgrade to Jersey 2.x,1,0,1
1043,SPARK-12157,SPARK-19087,Unresolved,Support numpy types as return values of Python UDFs,Numpy types fail to be casted to any other types,0,0,1
1044,SPARK-12162,SPARK-12175,Not A Problem,Embedded Spark on JBoss server cause crashing due system.exit when SparkUncaughtExceptionHandler called,Add new flag to Spark that identify if the driver run on application servers.,1,0,1
1045,SPARK-12163,SPARK-12999,Unresolved,FPGrowth unusable on some datasets without extensive tweaking of the support threshold,Guidance on adding a stopping criterion (maximul literal length or itemset count) for FPGrowth,0,0,1
1046,SPARK-12177,SPARK-15089,Fixed,Update KafkaDStreams to new Kafka 0.10 Consumer API,kafka-spark consumer with SSL problem,1,1,1
1047,SPARK-12206,SPARK-15480,Unresolved,Streaming WebUI shows incorrect batch statistics when using Window operations,Some InputInfo missed with window operation applied,0,1,1
1048,SPARK-12215,SPARK-12246,Fixed,User guide section for KMeans in spark.ml,Add documentation for spark.ml.clustering.kmeans,0,1,1
1049,SPARK-12216,SPARK-18979,Invalid,Spark failed to delete temp directory ,ShutdownHookManager   Exception while deleting Spark temp dir  ,0,0,1
1050,SPARK-12269,SPARK-12453,Fixed,Update aws-java-sdk version,Spark Streaming Kinesis Example broken due to wrong AWS Java SDK version,1,0,1
1051,SPARK-12307,SPARK-14913,Duplicate,ParquetFormat options should be exposed through the DataFrameReader/Writer options API,Simplify configuration API,1,0,1
1052,SPARK-12323,SPARK-13730,Fixed,Don't assign default value for non-nullable columns of a Dataset,Nulls in dataframes getting converted to 0 with spark 2.0 SNAPSHOT,0,0,1
1053,SPARK-12350,SPARK-12366,Fixed,VectorAssembler#transform() initially throws an exception,IllegalArgumentException: requirement failed: File not found: ...sql/catalyst/expressions/GeneratedClass.class when df.show,0,1,1
1054,SPARK-12352,SPARK-17728,Duplicate,Reuse the result of split in SQL,UDFs are run too many times,0,0,1
1055,SPARK-12357,SPARK-12476,Duplicate,Implement unhandledFilter interface for JDBC,Implement JdbcRelation#unhandledFilters for removing unnecessary Spark Filter,1,0,1
1056,SPARK-12363,SPARK-13226,Fixed,PowerIterationClustering test case failed if we deprecated KMeans.setRuns,MLLib PowerIteration Clustering depends on deprecated KMeans setRuns API,1,0,1
1057,SPARK-12366,SPARK-12406,Duplicate,IllegalArgumentException: requirement failed: File not found: ...sql/catalyst/expressions/GeneratedClass.class when df.show,Codegen'd classes can't be found under REPL,1,0,1
1058,SPARK-12367,SPARK-12375,Duplicate,NoSuchElementException during prediction with Random Forest Regressor,VectorIndexer: allow unknown categories,1,1,1
1059,SPARK-12381,SPARK-16728,Duplicate,Copy public decision tree helper classes from spark.mllib to spark.ml and make private,migrate internal API for MLlib trees from spark.mllib to spark.ml,0,1,1
1060,SPARK-12383,SPARK-16728,Duplicate,Move unit tests for GBT from spark.mllib to spark.ml,migrate internal API for MLlib trees from spark.mllib to spark.ml,0,1,1
1061,SPARK-12394,SPARK-12538,Fixed,Support writing out pre-hash-partitioned data and exploit that in join optimizations to avoid shuffle (i.e. bucketing in Hive),bucketed table support,1,1,1
1062,SPARK-12408,SPARK-12500,Duplicate,Spark 1.6 with tachyon 0.8.2 uses deprecated client,Fix Tachyon deprecations; pull Tachyon dependency into one class,1,1,1
1063,SPARK-12423,SPARK-12979,Duplicate,Mesos executor home should not be resolved on the driver's file system,Paths are resolved relative to the local file system,1,1,1
1064,SPARK-12423,SPARK-12979,Duplicate,Mesos executor home should not be resolved on the driver's file system,Paths are resolved relative to the local file system,1,1,1
1065,SPARK-12437,SPARK-16387,Duplicate,Reserved words (like table) throws error when writing a data frame to JDBC,Reserved SQL words are not escaped by JDBC writer,1,1,1
1066,SPARK-12449,SPARK-19655,Unresolved,Pushing down arbitrary logical plans to data sources,select count(*) ; requests 1 for each row,1,0,1
1067,SPARK-12449,SPARK-20259,Unresolved,Pushing down arbitrary logical plans to data sources,Support push down join optimizations in DataFrameReader when loading from JDBC,1,0,1
1068,SPARK-12458,SPARK-14415,Duplicate,Add ExpressionDescription to datetime functions,All functions should show usages by command `DESC FUNCTION`,1,1,1
1069,SPARK-12459,SPARK-14415,Duplicate,Add ExpressionDescription to string functions,All functions should show usages by command `DESC FUNCTION`,1,1,1
1070,SPARK-12460,SPARK-14415,Duplicate,Add ExpressionDescription to aggregate functions,All functions should show usages by command `DESC FUNCTION`,1,1,1
1071,SPARK-12461,SPARK-14415,Duplicate,Add ExpressionDescription to math functions,All functions should show usages by command `DESC FUNCTION`,1,1,1
1072,SPARK-12462,SPARK-14415,Duplicate,Add ExpressionDescription to misc non-aggregate functions,All functions should show usages by command `DESC FUNCTION`,1,1,1
1073,SPARK-12467,SPARK-13802,Won't Fix,Get rid of sorting in Row's constructor in pyspark,Fields order in Row(**kwargs) is not consistent with Schema.toInternal method,0,0,1
1074,SPARK-12467,SPARK-20527,Won't Fix,Get rid of sorting in Row's constructor in pyspark,Schema issues when fields are queries in different order,0,0,1
1075,SPARK-12492,SPARK-12946,Fixed,SQL page of Spark-sql is always blank ,The SQL page is empty,0,1,1
1076,SPARK-12525,SPARK-12527,Fixed,Fix compiler warnings in Kinesis ASL module due to @transient annotations,Add private val after @transient for kinesis-asl module,0,1,1
1077,SPARK-12530,SPARK-12535,Fixed,Build break at Spark-Master-Maven-Snapshots from #1293,Generating scaladoc using sbt fails for network-common and catalyst modules,0,0,1
1078,SPARK-12532,SPARK-13219,Later,Join-key Pushdown via Predicate Transitivity,Pushdown predicate propagation in SparkSQL with join,0,1,1
1079,SPARK-12552,SPARK-21169,Fixed,Recovered driver's resource is not counted in the Master,Spark HA: Jobs state is in WAITING status after reconnecting to standby master,0,1,1
1080,SPARK-12552,SPARK-18554,Fixed,Recovered driver's resource is not counted in the Master,leader master lost the leadership; when the slave become master; the perivious app's state display as waitting,0,0,1
1081,SPARK-12552,SPARK-20058,Fixed,Recovered driver's resource is not counted in the Master,the running application status changed  from running to waiting when a master is down and it change to another standy by master,0,0,1
1082,SPARK-12555,SPARK-15070,Fixed,Datasets: data is corrupted when input data is reordered,Accept Dataset[_] in joins,0,1,1
1083,SPARK-12563,SPARK-12579,Duplicate,No suitable driver when calling JdbcUtils.saveTable in isolation,User-specified JDBC driver should always take precedence,1,0,1
1084,SPARK-12583,SPARK-13159,Fixed,spark shuffle fails with mesos after 2mins,External shuffle service broken w/ Mesos,0,1,1
1085,SPARK-12593,SPARK-13496,Fixed,Convert basic resolved logical plans back to SQL query strings,Optimizing count distinct changes the resulting column name,1,1,1
1086,SPARK-12594,SPARK-13354,Fixed,Outer Join Elimination by Filter Condition,Push filter throughout outer join when the condition can filter out empty row ,0,0,1
1087,SPARK-12597,SPARK-12599,Duplicate,Use udf to replace callUDF for ML,Remove the use of the deprecated callUDF in MLlib,0,1,1
1088,SPARK-12604,SPARK-14873,Fixed,Java count(AprroxDistinct)ByKey methods return Scala Long not Java,Java sampleByKey methods take ju.Map but with Scala Double values; results in type Object,1,1,1
1089,SPARK-12609,SPARK-17919,Unresolved,Make R to JVM timeout configurable ,Make timeout to RBackend configurable in SparkR,1,1,1
1090,SPARK-12616,SPARK-12691,Fixed,Union logical plan should support arbitrary number of children (rather than binary),Multiple unionAll on Dataframe goes growingly slow.,1,1,1
1091,SPARK-12618,SPARK-12651,Fixed,Clean up build warnings: 2.0.0 edition,mllib deprecation messages mention non-existent version 1.7.0,0,0,1
1092,SPARK-12619,SPARK-14259,Duplicate,Combine small files in a hadoop directory into single split ,Add config to control maximum number of files when coalescing partitions,0,0,1
1093,SPARK-12648,SPARK-20212,Unresolved,java.lang.ClassCastException: [B cannot be cast to java.lang.String,'/applications/[app-id]/stages' in REST API;add description.,1,0,1
1094,SPARK-12672,SPARK-12673,Duplicate,Streaming batch ui can't be opened in jobs page in yarn mode.,Prepending base URI of job description is missing,0,1,1
1095,SPARK-12673,SPARK-13483,Fixed,Prepending base URI of job description is missing,URL address error in Spark web ui in YARN mode,1,0,1
1096,SPARK-12694,SPARK-13267,Duplicate,The detailed rest API documentation for each field is missing,Document ?params for the v1 REST API,1,0,1
1097,SPARK-12695,SPARK-13082,Duplicate,No encoder implicits for Seq[Primitive],sqlCtx.real.json() doesn't work with PythonRDD,1,1,1
1098,SPARK-12702,SPARK-12996,Duplicate,Populate statistics for DataFrame when reading CSV,CSVRelation should be based on HadoopFsRelation,1,1,1
1099,SPARK-12746,SPARK-13359,Fixed,ArrayType(_; true) should also accept ArrayType(_; false),ArrayType(_; true) should also accept ArrayType(_; false) fix for branch-1.6,0,0,1
1100,SPARK-12776,SPARK-13233,Duplicate,Implement Python API for Datasets,Python Dataset,0,0,1
1101,SPARK-12789,SPARK-13862,Fixed,Support order by ordinal in SQL,TPCDS query 49 returns wrong results compared to TPC official result set ,1,0,1
1102,SPARK-12789,SPARK-13864,Fixed,Support order by ordinal in SQL,TPCDS query 74 returns wrong results compared to TPC official result set ,1,0,1
1103,SPARK-12799,SPARK-13311,Fixed,Simplify various string output for expressions,prettyString of IN is not good,1,0,1
1104,SPARK-12804,SPARK-14095,Fixed,ml.classification.LogisticRegression fails when FitIntercept with same-label dataset,LogisticRegression fails when a DataFrame has only a one-class label,0,0,1
1105,SPARK-12809,SPARK-12823,Duplicate,Spark SQL UDF does not work with struct input parameters,Cannot create UDF with StructType input,1,1,1
1106,SPARK-12827,SPARK-13117,Duplicate,Configurable bind address for WebUI,WebUI should use the local ip not 0.0.0.0,1,1,1
1107,SPARK-12832,SPARK-19606,Unresolved,Mesos cluster mode should handle constraints,Support constraints in spark-dispatcher,1,1,1
1108,SPARK-12837,SPARK-14226,Fixed,Spark driver requires large memory space for serialized results even there are no data collected to the driver,Caching a table with 1;100 columns and a few million rows fails,1,1,1
1109,SPARK-12844,SPARK-13339,Duplicate,Spark documentation should be more precise about the algebraic properties of functions in various transformations,Clarify commutative / associative operator requirements for reduce; fold,1,1,1
1110,SPARK-12868,SPARK-18910,Fixed,ADD JAR via sparkSQL JDBC will fail when using a HDFS URL,Can't use UDF that jar file in hdfs,1,1,1
1111,SPARK-12925,SPARK-13542,Fixed,Improve HiveInspectors.unwrap for StringObjectInspector.getPrimitiveWritableObject,Fix HiveInspectors.unwrap,0,0,1
1112,SPARK-12956,SPARK-13063,Duplicate,add spark.yarn.hdfs.home.directory property,Make the SPARK YARN STAGING DIR as configurable,1,0,1
1113,SPARK-12965,SPARK-20987,Unresolved,Indexer setInputCol() doesn't resolve column names like DataFrame.col(),columns with name having dots caused issues with VectorAssemblor,0,1,1
1114,SPARK-12972,SPARK-13199,Fixed,Update org.apache.httpcomponents.httpclient; commons-io,Upgrade apache httpclient version to the latest 4.5 for security,0,1,1
1115,SPARK-12987,SPARK-12988,Duplicate,Drop fails when columns contain dots,Can't drop columns that contain dots,1,0,1
1116,SPARK-12988,SPARK-13455,Fixed,Can't drop columns that contain dots,Periods in dataframe column names breaks df.drop(<string>),0,0,1
1117,SPARK-12998,SPARK-14070,Duplicate,Enable OrcRelation when connecting via spark thrift server,Use ORC data source for SQL queries on ORC tables,1,0,1
1118,SPARK-13013,SPARK-13500,Fixed,Replace example code in mllib-clustering.md using include_example,Add an example for LDA in PySpark,0,1,1
1119,SPARK-13022,SPARK-14919,Won't Fix,Shade jackson core,Spark Cannot be used with software that requires jackson-databind 2.6+: RDDOperationScope,0,0,1
1120,SPARK-13054,SPARK-14660,Fixed,Always post TaskEnd event for tasks in cancelled stages,Executors show up active tasks indefinitely after stage is killed,0,0,1
1121,SPARK-13060,SPARK-13112,Invalid,CoarsedExecutorBackend register to driver should wait Executor was ready?,CoarsedExecutorBackend register to driver should wait Executor was ready,0,0,1
1122,SPARK-13085,SPARK-21903,Duplicate,Add scalastyle command used in build testing,Upgrade scalastyle to 1.0.0,0,0,1
1123,SPARK-13088,SPARK-13645,Fixed,DAG viz does not work with latest version of chrome,DAG Diagram not shown properly in Chrome,1,0,1
1124,SPARK-13089,SPARK-13502,Fixed,spark.ml Naive Bayes user guide,Missing ml.NaiveBayes in MLlib guide,1,0,1
1125,SPARK-13112,SPARK-18820,Fixed,CoarsedExecutorBackend register to driver should wait Executor was ready,"Driver may send ""LaunchTask"" before executor receive ""RegisteredExecutor""",0,1,1
1126,SPARK-13112,SPARK-16230,Fixed,CoarsedExecutorBackend register to driver should wait Executor was ready,Executors self-killing after being assigned tasks while still in init,1,0,1
1127,SPARK-13127,SPARK-18860,Unresolved,Upgrade Parquet to 1.9 (Fixes parquet sorting),Update Parquet to 1.9.0,1,1,1
1128,SPARK-13127,SPARK-18140,Unresolved,Upgrade Parquet to 1.9 (Fixes parquet sorting),Parquet NPE / Update to 1.9,0,1,1
1129,SPARK-13127,SPARK-20406,Unresolved,Upgrade Parquet to 1.9 (Fixes parquet sorting),Upgrade parquet to 1.9,0,1,1
1130,SPARK-13174,SPARK-13381,Unresolved,Add API and options for csv data sources,Support for loading CSV with a single function call,0,1,1
1131,SPARK-13186,SPARK-13204,Fixed,Migrate away from SynchronizedMap which is deprecated,Replace use of mutable.SynchronizedMap with ConcurrentHashMap,0,1,1
1132,SPARK-13189,SPARK-13190,Fixed,Cleanup build references to Scala 2.10,Update pom.xml to reference Scala 2.11,1,0,1
1133,SPARK-13189,SPARK-13191,Fixed,Cleanup build references to Scala 2.10,Update LICENSE with Scala 2.11 dependencies,1,0,1
1134,SPARK-13189,SPARK-13193,Fixed,Cleanup build references to Scala 2.10,Update Docker tests to use Scala 2.11,1,0,1
1135,SPARK-13189,SPARK-13194,Fixed,Cleanup build references to Scala 2.10,Update release audit tools to use Scala 2.11,1,0,1
1136,SPARK-13244,SPARK-13458,Fixed,Unify DataFrame and Dataset API,Datasets cannot be sorted,1,1,1
1137,SPARK-13251,SPARK-13252,Duplicate,Bump up Kafka to 0.9.0.0,Bump up Kafka to 0.9.0.0,1,1,1
1138,SPARK-13269,SPARK-14069,Fixed,Expose more executor stats in stable status API,Improve SparkStatusTracker to also track executor information,0,1,1
1139,SPARK-13347,SPARK-13523,Duplicate,Reuse the shuffle for duplicated exchange,Reuse the exchanges in a query,1,1,1
1140,SPARK-13391,SPARK-13534,Duplicate,Use Apache Arrow as In-memory columnar store implementation,Implement Apache Arrow serializer for Spark DataFrame for use in DataFrame.toPandas,0,1,1
1141,SPARK-13406,SPARK-14752,Duplicate,NPE in LazilyGeneratedOrdering,LazilyGenerateOrdering throws NullPointerException,1,1,1
1142,SPARK-13418,SPARK-13603,Duplicate,SQL generation for uncorrelated scalar subqueries,SQL generation for subquery,1,1,1
1143,SPARK-13430,SPARK-13517,Fixed,Expose ml summary function in PySpark for classification and regression models,Expose regression summary classes in Pyspark,0,0,1
1144,SPARK-13446,SPARK-18112,Fixed,Spark need to support reading data from Hive 2.0.0 metastore,Spark2.x does not support read data from Hive 2.x metastore,1,0,1
1145,SPARK-13446,SPARK-19076,Fixed,Spark need to support reading data from Hive 2.0.0 metastore,Upgrade Hive dependence to Hive 2.x,0,1,1
1146,SPARK-13446,SPARK-19321,Fixed,Spark need to support reading data from Hive 2.0.0 metastore,Support Hive 2.x's metastore,1,1,1
1147,SPARK-13448,SPARK-14847,Fixed,Document MLlib behavior changes in Spark 2.0,ML/MLlib breaking changes between 1.6 & 2.0,1,0,1
1148,SPARK-13531,SPARK-14578,Duplicate,Some DataFrame joins stopped working with UnsupportedOperationException: No size estimation available for objects,Can't load a json dataset with nested wide schema,1,1,1
1149,SPARK-13566,SPARK-15558,Fixed,Deadlock between MemoryStore and BlockManager,Deadlock when retreiving shuffled cached data,0,1,1
1150,SPARK-13566,SPARK-15943,Fixed,Deadlock between MemoryStore and BlockManager,Spark driver hangs up periodically (cannot receive any reply in 120 seconds),0,1,1
1151,SPARK-13566,SPARK-16513,Fixed,Deadlock between MemoryStore and BlockManager,Spark executor deadlocks itself in memory management,0,1,1
1152,SPARK-13566,SPARK-16564,Fixed,Deadlock between MemoryStore and BlockManager,DeadLock happens when    StaticMemoryManager    release in-memory block,0,1,1
1153,SPARK-13587,SPARK-19095,Unresolved,Support virtualenv in PySpark,virtualenv example does not work in yarn cluster mode,0,0,1
1154,SPARK-13656,SPARK-21921,Fixed,Delete spark.sql.parquet.cacheMetadata,Remove `spark.sql.parquet.cacheMetadata`,0,0,1
1155,SPARK-13669,SPARK-22426,Fixed,Job will always fail in the external shuffle service unavailable situation,Spark AM launching containers on node where External spark shuffle service failed to initialize,0,1,1
1156,SPARK-13682,SPARK-15016,Unresolved,Finalize the public API for FileFormat,Simplify and Speedup HadoopFSRelation (follow-up),1,1,1
1157,SPARK-13684,SPARK-13823,Duplicate,Possible unsafe bytesRead increment in StreamInterceptor,SQLContext.range should return Dataset[Long],0,0,1
1158,SPARK-13699,SPARK-16410,Duplicate,"Spark SQL drops the table in ""overwrite"" mode while writing into table",DataFrameWriter's jdbc method drops table in overwrite mode,1,1,1
1159,SPARK-13725,SPARK-13726,Duplicate,Spark 1.6.0 stopping working for HiveThriftServer2 and registerTempTable,Spark 1.6.0 stopping working for HiveThriftServer2 and registerTempTable,1,1,1
1160,SPARK-13768,SPARK-13983,Fixed,Set hive conf failed use --hiveconf when beeline connect to thriftserver,"HiveThriftServer2 can not get ""--hiveconf"" or ''--hivevar"" variables since 1.6 version (both multi-session and single session)",1,0,1
1161,SPARK-13786,SPARK-21221,Duplicate,Pyspark ml.tuning support export/import,CrossValidator and TrainValidationSplit Persist Nested Estimators such as OneVsRest,0,1,1
1162,SPARK-13796,SPARK-17469,Fixed,Lock release errors occur frequently in executor logs,mapWithState causes block lock warning,0,1,1
1163,SPARK-13796,SPARK-14168,Fixed,Lock release errors occur frequently in executor logs,Managed Memory Leak Msg Should Only Be a Warning,1,1,1
1164,SPARK-13819,SPARK-18368,Duplicate,using a regexp_replace in a group by clause raises a nullpointerexception,Regular expression replace throws NullPointerException when serialized,1,1,1
1165,SPARK-13824,SPARK-13825,Duplicate,Upgrade to Scala 2.11.8,Upgrade to Scala 2.11.8,0,1,1
1166,SPARK-13832,SPARK-14096,Duplicate,TPC-DS Query 36 fails with Parser error,SPARK-SQL CLI returns NPE,1,1,1
1167,SPARK-13857,SPARK-14379,Duplicate,Feature parity for ALS ML with MLLIB,Review spark.ml parity for recommendation,1,1,1
1168,SPARK-13862,SPARK-13864,Duplicate,TPCDS query 49 returns wrong results compared to TPC official result set ,TPCDS query 74 returns wrong results compared to TPC official result set ,1,1,1
1169,SPARK-13867,SPARK-13878,Fixed,Failed to bind reference when cume_dist is used,Window functions failed in cluster,1,1,1
1170,SPARK-13867,SPARK-14244,Fixed,Failed to bind reference when cume_dist is used,Physical Window operator uses global SizeBasedWindowFunction.n attribute generated on both driver and executor side,1,1,1
1171,SPARK-13891,SPARK-14009,Duplicate,Issue an exception when hitting max iteration limit in testing,Fail the tests if the any catalyst rule reach max number of iteration.,1,1,1
1172,SPARK-13904,SPARK-14690,Fixed,Add support for pluggable cluster manager,[PYSPARK] Make Lambda Serializer Configurable,0,1,1
1173,SPARK-13912,SPARK-14912,Duplicate,spark.hadoop.* configurations are not applied for Parquet Data Frame Readers,Propagate data source options to Hadoop configurations,1,1,1
1174,SPARK-13919,SPARK-14010,Fixed,Resolving the Conflicts of ColumnPruning and PushPredicateThroughProject ,ColumnPruning is conflict with PushPredicateThroughProject,0,1,1
1175,SPARK-13935,SPARK-14003,Duplicate,Other clients' connection hang up when someone do huge load,"Multi-session can not work when one session is moving files for ""INSERT ... SELECT"" clause",1,0,1
1176,SPARK-13976,SPARK-14002,Fixed,do not remove sub-queries added by user when generate SQL,SQLBuilder should add subquery to Aggregate child when necessary,1,1,1
1177,SPARK-13983,SPARK-19927,Unresolved,"HiveThriftServer2 can not get ""--hiveconf"" or ''--hivevar"" variables since 1.6 version (both multi-session and single session)","SparkThriftServer2 can not get ''--hivevar"" variables in spark 2.1",1,1,1
1178,SPARK-14003,SPARK-16795,Unresolved,"Multi-session can not work when one session is moving files for ""INSERT ... SELECT"" clause",Spark's HiveThriftServer should be able to use multiple sqlContexts,0,1,1
1179,SPARK-14027,SPARK-14030,Duplicate,Add parameter check to GradientDescent,Add parameter check to several MLlib implementations,1,1,1
1180,SPARK-14057,SPARK-18936,Duplicate,sql time stamps do not respect time zones,Infrastructure for session local timezone support,1,0,1
1181,SPARK-14084,SPARK-19071,Duplicate,Parallel training jobs in model selection,Optimizations for ML Pipeline Tuning,1,1,1
1182,SPARK-14090,SPARK-14200,Invalid,The optimization method of convex function,The optimization method of convex function ,1,1,1
1183,SPARK-14096,SPARK-14521,Duplicate,SPARK-SQL CLI returns NPE,StackOverflowError in Kryo when executing TPC-DS,1,0,1
1184,SPARK-14126,SPARK-15335,Duplicate,[Table related commands] Describe table,Implement TRUNCATE TABLE Command,1,0,1
1185,SPARK-14138,SPARK-16191,Fixed,Generated SpecificColumnarIterator code can exceed JVM size limit for cached DataFrames,Code-Generated SpecificColumnarIterator fails for wide pivot with caching,1,1,1
1186,SPARK-14146,SPARK-15675,Unresolved,Imported implicits can't be found in Spark REPL in some cases,Implicit resolution doesn't work in multiple Statements in Spark Repl ,0,1,1
1187,SPARK-14146,SPARK-17103,Unresolved,Imported implicits can't be found in Spark REPL in some cases,Can not define class variable in repl,0,1,1
1188,SPARK-14146,SPARK-18880,Unresolved,Imported implicits can't be found in Spark REPL in some cases,Cannot use imported class as parameter of case class in spark-shell,0,1,1
1189,SPARK-14153,SPARK-14489,Duplicate,My dataset does not provide proper predictions in ALS,RegressionEvaluator returns NaN for ALS in Spark ml,0,1,1
1190,SPARK-14162,SPARK-14204,Duplicate,java.lang.IllegalStateException: Did not find registered driver with class oracle.jdbc.OracleDriver,Association with remote system [akka.tcp://sparkDriver@192.168.1.81:34047] has failed; address is now gated for [5000] ms. Reason is: [Association failed$,0,1,1
1191,SPARK-14171,SPARK-18137,Duplicate,UDAF aggregates argument object inspector not parsed correctly,RewriteDistinctAggregates UnresolvedException when a UDAF has a foldable TypeCheck,1,0,1
1192,SPARK-14172,SPARK-21520,Unresolved,Hive table partition predicate not passed down correctly,Improvement a special case for non-deterministic projects in optimizer,1,0,1
1193,SPARK-14194,SPARK-19610,Duplicate,spark csv reader not working properly if CSV content contains CRLF character (newline) in the intermediate cell,multi line support for CSV,1,1,1
1194,SPARK-14223,SPARK-15001,Fixed,Cannot project all columns from a parquet files with ~1;100 columns,Cherry-pick Wide Table Support for Parquet Codegen from Spark 2.0,1,0,1
1195,SPARK-14241,SPARK-17833,Fixed,Output of monotonically_increasing_id lacks stable relation with rows of DataFrame,'monotonicallyIncreasingId()' should be deterministic,0,0,1
1196,SPARK-14272,SPARK-17825,Fixed,Evaluate GaussianMixtureModel with LogLikelihood,Expose log likelihood of EM algorithm in mllib,1,0,1
1197,SPARK-14273,SPARK-15654,Duplicate,Add FileFormat.isSplittable to indicate whether a format is splittable,Reading gzipped files results in duplicate rows,1,0,1
1198,SPARK-14286,SPARK-15347,Cannot Reproduce,Empty ORC table join throws exception,Problem select empty ORC table,0,0,1
1199,SPARK-14309,SPARK-17154,Duplicate,Dataframe returns wrong results due to parsing incorrectly,Wrong result can be returned or AnalysisException can be thrown after self-join or similar operations,1,1,1
1200,SPARK-14352,SPARK-14432,Unresolved,approxQuantile should support multi columns,Add API to calculate the approximate quantiles for multiple columns,1,0,1
1201,SPARK-14365,SPARK-15110,Duplicate,Repartition by column,SparkR - Implement repartitionByColumn on DataFrame,1,1,1
1202,SPARK-14385,SPARK-14888,Fixed,Use FunctionIdentifier in FunctionRegistry/SessionCatalog,UnresolvedFunction should use FunctionIdentifier rather than just a string for function name,1,1,1
1203,SPARK-14387,SPARK-15757,Fixed,Enable Hive-1.x ORC compatibility with spark.sql.hive.convertMetastoreOrc,"Error occurs when using Spark sql ""select"" statement on orc file after hive sql ""insert overwrite tb1 select * from sourcTb"" has been executed on this orc file",0,1,1
1204,SPARK-14387,SPARK-16605,Fixed,Enable Hive-1.x ORC compatibility with spark.sql.hive.convertMetastoreOrc,"Spark2.0 cannot ""select"" data from a table stored as an orc file which has been created by hive while hive or spark1.6 supports",1,1,1
1205,SPARK-14434,SPARK-15200,Fixed,User guide doc and examples for GaussianMixture in spark.ml,Add documentaion and examples for GaussianMixture,1,0,1
1206,SPARK-14450,SPARK-21027,Duplicate,Python OneVsRest should train multiple models at once,Parallel One vs. Rest Classifier,0,1,1
1207,SPARK-14460,SPARK-18141,Duplicate,DataFrameWriter JDBC doesn't Quote/Escape column names,jdbc datasource read fails when  quoted  columns (eg:mixed case; reserved words) in source table are used  in the filter.,1,1,1
1208,SPARK-14469,SPARK-14818,Duplicate,Remove mllib-local from mima project exclusion,Move sketch and mllibLocal out from mima exclusion,0,0,1
1209,SPARK-14471,SPARK-19778,Fixed,The alias created in SELECT could be used in GROUP BY and followed expressions,alais cannot use in group by,1,1,1
1210,SPARK-14479,SPARK-14517,Fixed,GLM supports output link prediction,GLM should support predict link,1,1,1
1211,SPARK-14526,SPARK-14876,Fixed,The catalog of SQLContext should not be case-sensitive ,SparkSession should be case insensitive by default,1,0,1
1212,SPARK-14533,SPARK-16156,Unresolved,RowMatrix.computeCovariance inaccurate when values are very large,RowMatr  x Covariance,1,0,1
1213,SPARK-14543,SPARK-19286,Unresolved,SQL/Hive insertInto has unexpected results,Spark/Hive insert Into has unexpected results,0,1,1
1214,SPARK-14560,SPARK-18443,Duplicate,Cooperative Memory Management for Spillables,spark leak memeory and led to OOM,1,1,1
1215,SPARK-14587,SPARK-14630,Duplicate,abstract class Receiver should be explicit about the return type of its methods,Code style: public abstract methods should have explicit return types,0,0,1
1216,SPARK-14658,SPARK-19263,Duplicate,when executor lost DagScheduer may submit one stage twice even if the first running taskset for this stage is not finished,DAGScheduler should avoid sending conflicting task set.,1,1,1
1217,SPARK-14702,SPARK-16511,Fixed,Expose SparkLauncher's ProcessBuilder for user flexibility,SparkLauncher should allow setting working directory for spark-submit process,0,1,1
1218,SPARK-14707,SPARK-16566,Unresolved,Linear algebra: clarify light vs heavy constructors and accessors,Bug in SparseMatrix multiplication with SparseVector,0,1,1
1219,SPARK-14731,SPARK-16048,Fixed,Revert SPARK-12130 to make 2.0 shuffle service compatible with 1.x,"spark-shell unresponsive after ""FetchFailedException: java.lang.UnsupportedOperationException: Unsupported shuffle manager"" with YARN and spark.shuffle.service.enabled",0,0,1
1220,SPARK-14743,SPARK-16342,Fixed,Improve delegation token handling in secure clusters,Add a new Configurable Token Manager  for Spark Running on YARN,0,1,1
1221,SPARK-14743,SPARK-16612,Fixed,Improve delegation token handling in secure clusters,Introduce a way for users to easily add support for new services that need delegation tokens,0,1,1
1222,SPARK-14752,SPARK-15604,Fixed,LazilyGenerateOrdering throws NullPointerException,Spark-SQL: Get com.esotericsoftware.kryo.KryoException: java.lang.NullPointerException when runing query_1.sql of TPC-DS,1,1,1
1223,SPARK-14752,SPARK-15755,Fixed,LazilyGenerateOrdering throws NullPointerException,java.lang.NullPointerException when run spark 2.0 setting spark.serializer=org.apache.spark.serializer.KryoSerializer,0,1,1
1224,SPARK-14762,SPARK-14840,Fixed,Fail to parse TPCDS Q90,Cannot drop a table which has the name starting with 'or',1,0,1
1225,SPARK-14762,SPARK-17597,Fixed,Fail to parse TPCDS Q90,HiveContext cannot create a table named sort,0,0,1
1226,SPARK-14764,SPARK-21937,Unresolved,Spark SQL documentation should be more precise about which SQL features it supports,Spark SQL DDL/DML docs non-existent,0,0,1
1227,SPARK-14767,SPARK-18717,Duplicate,"Codegen ""no constructor found"" errors with Maps inside case classes in Datasets",Datasets - crash (compile exception) when mapping to immutable scala map,0,0,1
1228,SPARK-14785,SPARK-14968,Fixed,Support correlated scalar subquery,TPC-DS query 1 resolved attribute(s) missing,0,0,1
1229,SPARK-14802,SPARK-14991,Duplicate,Disable Passing to Hive the queries that can't be parsed,Remove HiveNativeCommand,1,1,1
1230,SPARK-14804,SPARK-15717,Fixed,Graph vertexRDD/EdgeRDD checkpoint results ClassCastException: ,Cannot perform RDD operations on a checkpointed VertexRDD.,1,0,1
1231,SPARK-14819,SPARK-19218,Duplicate,"Improve the ""SET"" and ""SET -v"" command",Fix SET command to show a result correctly and in a sorted order,1,0,1
1232,SPARK-14887,SPARK-16624,Unresolved,Generated SpecificUnsafeProjection Exceeds JVM Code Size Limits,Generated SpecificColumnarIterator code can exceed JVM size limit for cached DataFrames,1,1,1
1233,SPARK-14887,SPARK-17936,Unresolved,Generated SpecificUnsafeProjection Exceeds JVM Code Size Limits,CodeGenerator - failed to compile: org.codehaus.janino.JaninoRuntimeException: Code of method Error,0,1,1
1234,SPARK-14894,SPARK-18282,Duplicate,Python GaussianMixture summary,Add model summaries for Python GMM and BisectingKMeans,1,1,1
1235,SPARK-14895,SPARK-14945,Duplicate,SparkSession Python API,Python SparkSession API,0,1,1
1236,SPARK-14915,SPARK-16709,Fixed,Tasks that fail due to CommitDeniedException (a side-effect of speculation) can cause job to never complete,Task with commit failed will retry infinite when speculation set to true,1,0,1
1237,SPARK-14922,SPARK-17732,Unresolved,Alter Table Drop Partition Using Predicate-based Partition Spec,ALTER TABLE DROP PARTITION should support comparators,1,1,1
1238,SPARK-14955,SPARK-16057,Duplicate,JDBCRelation should report an IllegalArgumentException if stride equals 0,JDBC source: Wrong Partition Generation when numPartitions is More than the number of rows between upper and lower bounds,1,0,1
1239,SPARK-14959,SPARK-16091,Fixed,   Problem Reading partitioned ORC or Parquet files,Dataset.partitionBy.csv raise a java.io.FileNotFoundException when launched on an hadoop cluster,0,0,1
1240,SPARK-14963,SPARK-15519,Fixed,YarnShuffleService should use YARN getRecoveryPath() for leveldb location,Shuffle Service fails to start if first yarn.nodemanager.local-dirs is bad,1,1,1
1241,SPARK-14963,SPARK-15371,Fixed,YarnShuffleService should use YARN getRecoveryPath() for leveldb location,YARNShuffleService doesn't get current local-dirs from NodeManager,1,0,1
1242,SPARK-14964,SPARK-16870,Duplicate,Document spark.sql.broadcastTimeout configuration,"add ""spark.sql.broadcastTimeout"" into docs/sql-programming-guide.md to help people to how to fix this timeout error when it happenned",1,0,1
1243,SPARK-15005,SPARK-15007,Unresolved,Usage of Temp Table twice in Hive query fails with bad error,Usage of Temp Table twice in Hive query ,1,0,1
1244,SPARK-15034,SPARK-15068,Fixed,Use the value of spark.sql.warehouse.dir as the warehouse location instead of using hive.metastore.warehouse.dir,Use proper metastore warehouse path,1,1,1
1245,SPARK-15037,SPARK-15266,Fixed,Use SparkSession instead of SQLContext in testsuites,Use SparkSession instead of SQLContext in Python tests,0,1,1
1246,SPARK-15083,SPARK-16083,Fixed,History Server would OOM due to unlimited TaskUIData in some stages,spark HistoryServer memory increases until gets killed by OS.,0,1,1
1247,SPARK-15125,SPARK-16895,Unresolved,CSV data source recognizes empty quoted strings in the input as null. ,Reading empty string from csv has changed behaviour,0,1,1
1248,SPARK-15142,SPARK-15359,Duplicate,Spark Mesos dispatcher becomes unusable when the Mesos master restarts,Mesos dispatcher should handle DRIVER_ABORTED status from mesosDriver.run(),1,1,1
1249,SPARK-15144,SPARK-16462,Duplicate,option nullValue for CSV data source not working for several types.,Spark 2.0 CSV does not cast null values to certain data types properly,1,1,1
1250,SPARK-15153,SPARK-15510,Fixed,SparkR spark.naiveBayes throws error when label is numeric type,SparkR NaiveBayes should not require label to have NominalAttribute,1,1,1
1251,SPARK-15156,SPARK-15157,Duplicate,String fields in Dataframe behaves weirdly when executor-memory >= 32GB,String fields in Dataframe behaves weirdly when executor-memory >= 32GB,1,1,1
1252,SPARK-15156,SPARK-15157,Duplicate,String fields in Dataframe behaves weirdly when executor-memory >= 32GB,String fields in Dataframe behaves weirdly when executor-memory >= 32GB,1,1,1
1253,SPARK-15171,SPARK-15325,Fixed,Deprecate registerTempTable and add dataset.createTempView,Replace the usage of deprecated DataSet API in tests,0,0,1
1254,SPARK-15183,SPARK-15517,Duplicate,Adding outputMode to structure Streaming Experimental Api,Add support for complete output mode ,1,0,1
1255,SPARK-15214,SPARK-16998,Fixed,Implement code generation for Generate,"select($""column1""; explode($""column2"")) is extremely slow",1,1,1
1256,SPARK-15224,SPARK-15763,Duplicate,Can not delete jar and list jar in spark Thrift server,Add DELETE FILE command support in spark,1,0,1
1257,SPARK-15226,SPARK-17222,Fixed,CSV file data-line with newline at first line load error,Support multline csv records,1,1,1
1258,SPARK-15230,SPARK-17024,Fixed,Back quoted column with dot in it fails when running distinct on dataframe,Weird behaviour of the DataFrame when a column name contains dots.,1,1,1
1259,SPARK-15282,SPARK-20586,Duplicate,UDF executed twice when filter on new column created by withColumn and the final value may be not correct,Add deterministic to ScalaUDF,1,1,1
1260,SPARK-15285,SPARK-18492,Fixed,Generated SpecificSafeProjection.apply method grows beyond 64 KB,GeneratedIterator grows beyond 64 KB,1,1,1
1261,SPARK-15317,SPARK-15419,Fixed,JobProgressListener takes a huge amount of memory with iterative DataFrame program in local; standalone,monotonicallyIncreasingId should use less memory with multiple partitions,0,1,1
1262,SPARK-15332,SPARK-15391,Duplicate,OutOfMemory in TimSort ,Spark executor OOM during TimSort,0,1,1
1263,SPARK-15360,SPARK-15410,Fixed,Should print spark-submit usage when no arguments is specified,spark-submit --help throws exception,1,0,1
1264,SPARK-15381,SPARK-15384,Fixed,physical object operator should define `reference` correctly,"Codegen CompileException ""mapelements_isNull"" is not an rvalue",1,1,1
1265,SPARK-15382,SPARK-16686,Fixed,monotonicallyIncreasingId doesn't work when data is upsampled,Dataset.sample with seed: result seems to depend on downstream usage,1,1,1
1266,SPARK-15384,SPARK-16223,Fixed,"Codegen CompileException ""mapelements_isNull"" is not an rvalue",Codegen failure with a Dataframe program using an array,1,0,1
1267,SPARK-15422,SPARK-15926,Duplicate,Remove unnecessary calculation of stage's parents,Improve readability of DAGScheduler stage creation methods,0,0,1
1268,SPARK-15444,SPARK-15448,Fixed,Default value mismatch of param linkPredictionCol for  GeneralizedLinearRegression,Flaky test:pyspark.ml.tests.DefaultValuesTests.test_java_params,1,0,1
1269,SPARK-15445,SPARK-15446,Fixed,Support for creating a dataframe from CSV in Dataset[String],catalyst using BigInteger.longValueExact that not supporting java 7 and compile error,0,0,1
1270,SPARK-15472,SPARK-18192,Fixed,Add support for writing partitioned `csv`; `json`; `text` formats in Structured Streaming,Support all file formats in structured streaming,0,1,1
1271,SPARK-15473,SPARK-20035,Unresolved,CSV fails to write and read back empty dataframe,Spark 2.0.2 writes empty file if no record is in the dataset,0,1,1
1272,SPARK-15473,SPARK-15475,Unresolved,CSV fails to write and read back empty dataframe,Add tests for writing and reading back empty data for Parquet; Json and Text data sources,1,1,1
1273,SPARK-15506,SPARK-17172,Invalid,only one notebook can define a UDF; java.sql.SQLException: Another instance of Derby may have already booted the database,pyspak hiveContext can not create UDF: Py4JJavaError: An error occurred while calling None.org.apache.spark.sql.hive.HiveContext. ,1,1,1
1274,SPARK-15512,SPARK-16797,Fixed,repartition(0) should raise IllegalArgumentException.,Repartiton call w/ 0 partitions drops data,1,0,1
1275,SPARK-15559,SPARK-16950,Duplicate,TopicAndPartition should provide __hash__ method,fromOffsets parameter in Kafka's Direct Streams does not work in python3,1,1,1
1276,SPARK-15590,SPARK-21018,Fixed,Paginate Job Table in Jobs tab,"Completed Jobs and ""Completed Stages"" support pagination",1,0,1
1277,SPARK-15616,SPARK-16669,Unresolved,CatalogRelation should fallback to HDFS size of partitions that are involved in Query if statistics are not available.,Partition pruning for metastore relation size estimates for better join selection.,1,1,1
1278,SPARK-15635,SPARK-16570,Fixed,ALTER TABLE RENAME doesn't work for datasource tables,Not able to access table's data after ALTER TABLE RENAME in Spark 1.6.2,1,1,1
1279,SPARK-15659,SPARK-15683,Fixed,Ensure FileSystem is gotten from path in InMemoryCatalog,spark sql local FS spark.sql.warehouse.dir throws on YARN,1,0,1
1280,SPARK-15667,SPARK-16036,Duplicate,Throw exception if columns number of outputs mismatch the inputs,better error message if the number of columns in SELECT clause doesn't match the table schema,1,0,1
1281,SPARK-15703,SPARK-18550,Fixed,Make ListenerBus event queue size configurable,Make the queue capacity of LiveListenerBus configurable.,0,1,1
1282,SPARK-15757,SPARK-16628,Duplicate,"Error occurs when using Spark sql ""select"" statement on orc file after hive sql ""insert overwrite tb1 select * from sourcTb"" has been executed on this orc file",OrcConversions should not convert an ORC table represented by MetastoreRelation to HadoopFsRelation if metastore schema does not match schema stored in ORC files,0,1,1
1283,SPARK-15763,SPARK-19708,Won't Fix,Add DELETE FILE command support in spark,delete jar unable,1,0,1
1284,SPARK-15765,SPARK-17924,Duplicate,Make continuous Parquet writes consistent with non-continuous Parquet writes,Consolidate streaming and batch write path,0,1,1
1285,SPARK-15774,SPARK-15775,Duplicate,Spark 2.0 thrift server not starting in cluster mode.,Spark 2.0 thrift server not starting in hadoop cluster.,1,1,1
1286,SPARK-15786,SPARK-15910,Duplicate,joinWith bytecode generation calling ByteBuffer.wrap with InternalRow,Schema is not checked when converting DataFrame to Dataset using Kryo encoder,1,1,1
1287,SPARK-15805,SPARK-15863,Duplicate,update the whole sql programming guide,Update SQL programming guide for Spark 2.0,1,0,1
1288,SPARK-15815,SPARK-21539,Unresolved,Hang while enable blacklistExecutor and DynamicExecutorAllocator ,Job should not be aborted when dynamic allocation is enabled or spark.executor.instances larger then current allocated number by yarn,0,0,1
1289,SPARK-15836,SPARK-15839,Duplicate,Spark 2.0/master maven snapshots are broken,Maven doc JAR generation fails when JAVA_7_HOME is set,0,1,1
1290,SPARK-15848,SPARK-15921,Cannot Reproduce,Spark unable to read partitioned table in avro format and column name in upper case,Spark unable to read partitioned table in avro format and column name in upper case,0,1,1
1291,SPARK-15893,SPARK-15899,Duplicate,spark.createDataFrame raises an exception in Spark 2.0 tests on Windows,file scheme should be used correctly,0,1,1
1292,SPARK-15899,SPARK-18439,Fixed,file scheme should be used correctly,spark 2.0.1 fails in windows when using file:/// scratchdir in hive-site.xml,0,1,1
1293,SPARK-15902,SPARK-18138,Duplicate,Add a deprecation warning for Python 2.6,More officially deprecate support for Python 2.6; Java 7; and Scala 2.10,0,0,1
1294,SPARK-15911,SPARK-16037,Duplicate,Remove additional Project to be consistent with SQL when insert into table,use by-position resolution when insert into hive table,1,1,1
1295,SPARK-15918,SPARK-20761,Not A Problem,unionAll returns wrong result when two dataframes has schema in different order,Union uses column order rather than schema,1,0,1
1296,SPARK-15923,SPARK-16595,Fixed,"Spark Application rest api returns ""no such app: <appId>""",Spark History server Rest Api gives Application not found error for yarn-cluster mode,1,0,1
1297,SPARK-15950,SPARK-18585,Duplicate,Eliminate unreachable code at projection for complex types,"Use `ev.isNull = ""false""` if possible for Janino to have a chance to optimize.",1,1,1
1298,SPARK-15971,SPARK-15973,Duplicate,GroupedData's member incorrectly named,Fix GroupedData Documentation,1,1,1
1299,SPARK-15972,SPARK-15973,Duplicate,GroupedData varargs arguments misnamed,Fix GroupedData Documentation,1,1,1
1300,SPARK-16041,SPARK-16879,Duplicate,Disallow Duplicate Columns in `partitionBy`; `bucketBy` and `sortBy`,unify logical plans for CREATE TABLE and CTAS,1,1,1
1301,SPARK-16042,SPARK-16213,Duplicate,Eliminate nullcheck code at projection for an array type,Reduce runtime overhead of a program that creates an primitive array in DataFrame,1,1,1
1302,SPARK-16095,SPARK-16293,Fixed,Yarn cluster mode should return consistent result for command line and SparkLauncher,SparkAppHandle.getState() returns wrong state in standalone mode if Spark application terminates unexpectedly,0,1,1
1303,SPARK-16101,SPARK-16103,Fixed,Refactoring CSV data source to be consistent with JSON data source,Share a single Row for CSV data source rather than creating every time,1,1,1
1304,SPARK-16173,SPARK-16449,Fixed,Can't join describe() of DataFrame in Scala 2.10,"unionAll raises ""Task not serializable""",0,0,1
1305,SPARK-16181,SPARK-16252,Fixed,Incorrect behavior for isNull filter,Full Outer join with literal column results in incorrect result,1,1,1
1306,SPARK-16201,SPARK-16452,Duplicate,Expose information schema,basic INFORMATION_SCHEMA support,1,1,1
1307,SPARK-16203,SPARK-16876,Unresolved,regexp_extract to return an ArrayType(StringType()),Add match Column expression for regular expression matching in Scala API ,0,1,1
1308,SPARK-16215,SPARK-17490,Duplicate,Reduce runtime overhead of a program that writes an primitive array in Dataframe/Dataset,Optimize SerializeFromObject for primitive array,1,1,1
1309,SPARK-16216,SPARK-16597,Fixed,CSV data source does not write date and timestamp correctly,DataFrame DateType is written as an int(Days since epoch) by csv writer,1,0,1
1310,SPARK-16216,SPARK-17066,Fixed,CSV data source does not write date and timestamp correctly,dateFormat should be used when writing dataframes as csv files,0,0,1
1311,SPARK-16216,SPARK-17923,Fixed,CSV data source does not write date and timestamp correctly,dateFormat unexpected kwarg to df.write.csv,0,0,1
1312,SPARK-16234,SPARK-17664,Not A Problem,Speculative Task may not be able to overwrite file,Failed to saveAsHadoop when speculate is enabled,0,1,1
1313,SPARK-16243,SPARK-16245,Duplicate,model loading backward compatibility for ml.feature.PCA,model loading backward compatibility for ml.feature.PCA,0,1,1
1314,SPARK-16250,SPARK-16259,Duplicate,Can't use escapeQuotes option in DataFrameWriter.csv(),Cleanup options for DataFrame reader API in Python,1,0,1
1315,SPARK-16252,SPARK-17594,Duplicate,Full Outer join with literal column results in incorrect result,Bug in left-outer join,1,1,1
1316,SPARK-16299,SPARK-16300,Fixed,Capture errors from R workers in daemon.R to avoid deletion of R session temporary directory,Capture errors from R workers in daemon.R to avoid deletion of R session temporary directory,1,1,1
1317,SPARK-16304,SPARK-16305,Fixed,LinkageError should not crash Spark executor,LinkageError should not crash Spark executor,1,1,1
1318,SPARK-16306,SPARK-16307,Duplicate,Improve testing for DecisionTree variances,Improve testing for DecisionTree variances,1,1,1
1319,SPARK-16308,SPARK-16310,Duplicate,SparkR csv source should have the same default na.string as R,SparkR csv source should have the same default na.string as R,1,1,1
1320,SPARK-16312,SPARK-16917,Fixed,Docs for Kafka 0.10 consumer integration,Spark streaming kafka version compatibility. ,0,0,1
1321,SPARK-16312,SPARK-16705,Fixed,Docs for Kafka 0.10 consumer integration,Kafka Direct Stream is not experimental anymore,0,0,1
1322,SPARK-16332,SPARK-16333,Duplicate,the history server of spark2.0-preview (may-24 build) consumes more than 1000% cpu,Excessive Spark history event/json data size (5GB each),1,1,1
1323,SPARK-16333,SPARK-20084,Duplicate,Excessive Spark history event/json data size (5GB each),Remove internal.metrics.updatedBlockStatuses accumulator from history files,0,1,1
1324,SPARK-16333,SPARK-19316,Duplicate,Excessive Spark history event/json data size (5GB each),Spark event logs are huge compared to 1.5.2,0,1,1
1325,SPARK-16347,SPARK-21191,Not A Problem,DataFrame allows duplicate column-names,DataFrame Row StructType check duplicate name,1,1,1
1326,SPARK-16384,SPARK-16806,Not A Problem,FROM_UNIXTIME reports incorrect days,from_unixtime function gives wrong answer,0,1,1
1327,SPARK-16410,SPARK-16463,Duplicate,DataFrameWriter's jdbc method drops table in overwrite mode, Support `truncate` option in Overwrite mode for JDBC DataFrameWriter,1,0,1
1328,SPARK-16419,SPARK-17271,Duplicate,EnsureRequirements adds extra Sort to already sorted cached table,Planner adds un-necessary Sort even if child ordering is semantically same as required ordering,1,0,1
1329,SPARK-16450,SPARK-16637,Duplicate,Build failes for Mesos 0.28.x,Support Mesos Unified Containerizer,1,1,1
1330,SPARK-16456,SPARK-16958,Duplicate,Reuse the uncorrelated scalar subqueries with the same logical plan in a query,Reuse subqueries within single query,1,1,1
1331,SPARK-16462,SPARK-16903,Fixed,Spark 2.0 CSV does not cast null values to certain data types properly,nullValue in first field is not respected by CSV source when read,1,1,1
1332,SPARK-16462,SPARK-17039,Fixed,Spark 2.0 CSV does not cast null values to certain data types properly,cannot read null dates from csv file,0,1,1
1333,SPARK-16462,SPARK-17290,Fixed,Spark 2.0 CSV does not cast null values to certain data types properly,Spark CSVInferSchema does not always respect nullValue settings,1,1,1
1334,SPARK-16472,SPARK-18270,Unresolved,Inconsistent nullability in schema after being read,Users schema with non-nullable properties is overidden with true,1,0,1
1335,SPARK-16512,SPARK-18699,Duplicate,No way to load CSV data without dropping whole rows when some of data is not matched with given schema,Spark CSV parsing types other than String throws exception when malformed,1,0,1
1336,SPARK-16533,SPARK-16702,Fixed,Spark application not handling preemption messages,Driver hangs after executors are lost,0,1,1
1337,SPARK-16544,SPARK-17477,Unresolved,Support for conversion from compatible schema for Parquet data source when data types are not matched,SparkSQL cannot handle schema evolution from Int -> Long when parquet files have Int as its type while hive metastore has Long as its type,1,1,1
1338,SPARK-16548,SPARK-20314,Fixed,java.io.CharConversionException: Invalid UTF-32 character  prevents me from querying my data,Inconsistent error handling in JSON parsing SQL functions,1,0,1
1339,SPARK-16580,SPARK-16861,Duplicate,"spark-class crash with ""[: too many arguments"" instead of displaying the correct error message",Refactor PySpark accumulator API to be on top of AccumulatorV2 API,0,1,1
1340,SPARK-16581,SPARK-16608,Fixed,Making JVM backend calling functions public,Expose JVM SparkR API functions ,1,1,1
1341,SPARK-16595,SPARK-17111,Unresolved,Spark History server Rest Api gives Application not found error for yarn-cluster mode,"Spark2 History server got ""Failed to load application attempt""",1,1,1
1342,SPARK-16609,SPARK-18424,Fixed,Single function for parsing timestamps/dates,Single Function for Parsing Dates and Times with Formats,0,0,1
1343,SPARK-16617,SPARK-19697,Unresolved,Upgrade to Avro 1.8.x,NoSuchMethodError: org.apache.avro.Schema.getLogicalType(),1,1,1
1344,SPARK-16648,SPARK-18358,Fixed,LAST_VALUE(FALSE) OVER () throws IndexOutOfBoundsException,Multiple Aggregation Using 'countDistinct' and 'first' result in error ,0,1,1
1345,SPARK-16664,SPARK-17061,Fixed,Spark 1.6.2 - Persist call on Data frames with more than 200 columns is wiping out the data.,Incorrect results returned following a join of two datasets and a map step where total number of columns >100,1,0,1
1346,SPARK-16664,SPARK-17043,Fixed,Spark 1.6.2 - Persist call on Data frames with more than 200 columns is wiping out the data.,Cannot call zipWithIndex on RDD with more than 200 columns (get wrong result),1,0,1
1347,SPARK-16664,SPARK-17218,Fixed,Spark 1.6.2 - Persist call on Data frames with more than 200 columns is wiping out the data.,Caching a DataFrame with >200 columns ~nulls the contents,0,0,1
1348,SPARK-16664,SPARK-17294,Fixed,Spark 1.6.2 - Persist call on Data frames with more than 200 columns is wiping out the data.,Caching invalidates data on mildly wide dataframes,0,0,1
1349,SPARK-16664,SPARK-21851,Fixed,Spark 1.6.2 - Persist call on Data frames with more than 200 columns is wiping out the data.,Spark 2.0 data corruption with cache and 200 columns,0,0,1
1350,SPARK-16664,SPARK-16716,Fixed,Spark 1.6.2 - Persist call on Data frames with more than 200 columns is wiping out the data.,calling cache on joined dataframe can lead to data being blanked,0,0,1
1351,SPARK-16665,SPARK-17737,Cannot Reproduce,python import pyspark fails in context.py ,cannot import name accumulators error,1,0,1
1352,SPARK-16685,SPARK-16712,Fixed,Remove defunct audit-release dir,converter and access code out of sync: createDataFrame on RDD[Option[C]] fails with MatchError,0,1,1
1353,SPARK-16697,SPARK-18548,Fixed,redundant RDD computation in LDAOptimizer,OnlineLDAOptimizer reads the same broadcast data after deletion,0,0,1
1354,SPARK-16698,SPARK-17232,Fixed,"json parsing regression - ""."" in keys",Expecting same behavior after loading a dataframe with dots in column name,0,1,1
1355,SPARK-16698,SPARK-17341,Fixed,"json parsing regression - ""."" in keys","Can't read Parquet data with fields containing periods "".""",1,1,1
1356,SPARK-16761,SPARK-17202,Fixed,Fix doc link in docs/ml-guide.md,Pipeline guide link is broken in MLlib Guide main page,0,1,1
1357,SPARK-16781,SPARK-17220,Fixed,java launched by PySpark as gateway may not be the same java used in the spark environment,Upgrade Py4J to 0.10.3,1,0,1
1358,SPARK-16789,SPARK-16803,Duplicate,Can't run saveAsTable with database name,SaveAsTable does not work when source DataFrame is built on a Hive Table,1,1,1
1359,SPARK-16792,SPARK-22296,Fixed,Dataset containing a Case Class with a List type causes a CompileException (converting sequence to list),CodeGenerator - failed to compile when constructor has scala.collection.mutable.Seq vs. scala.collection.Seq,0,0,1
1360,SPARK-16843,SPARK-17017,Duplicate,Select features according to a percentile of the highest scores of ChiSqSelector,Add a chiSquare Selector based on False Positive Rate (FPR) test,0,1,1
1361,SPARK-16845,SPARK-18492,Fixed,"org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificOrdering"" grows beyond 64 KB",GeneratedIterator grows beyond 64 KB,1,1,1
1362,SPARK-16845,SPARK-17092,Fixed,"org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificOrdering"" grows beyond 64 KB",DataFrame with large number of columns causing code generation error,1,1,1
1363,SPARK-16845,SPARK-17131,Fixed,"org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificOrdering"" grows beyond 64 KB",Code generation fails when running SQL expressions against a wide dataset (thousands of columns),1,1,1
1364,SPARK-16845,SPARK-17223,Fixed,"org.apache.spark.sql.catalyst.expressions.GeneratedClass$SpecificOrdering"" grows beyond 64 KB",grows beyond 64 KB with data frame with many columns,0,1,1
1365,SPARK-16851,SPARK-16863,Fixed,Incorrect threshould length in 'setThresholds()' evoke Exception ,ProbabilisticClassifier.fit check threshoulds' length,1,0,1
1366,SPARK-16873,SPARK-18289,Fixed,force spill NPE,spark.util.collection.ExternalSorter leak memory when task force spilling in-memory map to disk ,0,1,1
1367,SPARK-16901,SPARK-17000,Fixed,Hive settings in hive-site.xml may be overridden by Hive's default values,Spark cannot connect to secure metastore when using custom metastore jars,1,1,1
1368,SPARK-16938,SPARK-17037,Unresolved,Cannot resolve column name after a join,distinct() operator fails on Dataframe with column names containing periods,0,0,1
1369,SPARK-16950,SPARK-17411,Fixed,fromOffsets parameter in Kafka's Direct Streams does not work in python3,Cannot set fromOffsets in createDirectStream function,0,1,1
1370,SPARK-16965,SPARK-17130,Fixed,Fix bound checking for SparseVector,SparseVectors.apply and SparseVectors.toArray have different returns when creating with a illegal indices,0,1,1
1371,SPARK-16966,SPARK-17105,Fixed,"App Name is a randomUUID even when ""spark.app.name"" exists",Create spark context with random uuid app name if app name is not set in configuration,1,0,1
1372,SPARK-16980,SPARK-17179,Fixed,Load only catalog table partition metadata required to answer a query,Consider improving partition pruning in HiveMetastoreCatalog,1,1,1
1373,SPARK-16986,SPARK-18298,Fixed,"Started time; ""Completed"" time and ""Last Updated"" time in history server UI are not user local time",HistoryServer use GMT time all time,1,0,1
1374,SPARK-16986,SPARK-19099,Fixed,"Started time; ""Completed"" time and ""Last Updated"" time in history server UI are not user local time",Wrong time display on Spark History Server web UI,0,0,1
1375,SPARK-16987,SPARK-17874,Duplicate,Add spark-default.conf property to define https port for spark history server,Additional SSL port on HistoryServer should be configurable,0,0,1
1376,SPARK-16991,SPARK-17099,Fixed,Full outer join followed by inner join produces wrong results,Incorrect result when HAVING clause is added to group by query,1,0,1
1377,SPARK-16991,SPARK-17120,Fixed,Full outer join followed by inner join produces wrong results,Analyzer incorrectly optimizes plan to empty LocalRelation,1,0,1
1378,SPARK-16991,SPARK-17060,Fixed,Full outer join followed by inner join produces wrong results,Call inner join after outer join will miss rows with null values,1,0,1
1379,SPARK-17039,SPARK-17040,Duplicate,cannot read null dates from csv file,cannot read null dates from csv file,1,1,1
1380,SPARK-17071,SPARK-17537,Won't Fix,Fetch Parquet schema within driver-side when there is single file to touch without another Spark job,Improve performance for reading parquet schema,1,0,1
1381,SPARK-17091,SPARK-21218,Unresolved,Convert IN predicate to equivalent Parquet filter,Convert IN predicate to equivalent Parquet filter,0,1,1
1382,SPARK-17101,SPARK-18760,Duplicate,Provide consistent format identifiers for TextFileFormat and ParquetFileFormat,Provide consistent format output for all file formats,1,0,1
1383,SPARK-17112,SPARK-17818,Fixed,select if(true; null; null) via JDBC triggers IllegalArgumentException in Thriftserver,Cannot SELECT NULL,1,0,1
1384,SPARK-17147,SPARK-19361,Unresolved,Spark Streaming Kafka 0.10 Consumer Can't Handle Non-consecutive Offsets (i.e. Log Compaction),kafka.maxRatePerPartition for compacted topic cause exception,1,1,1
1385,SPARK-17174,SPARK-22478,Unresolved,Provide support for Timestamp type Column in add_months function to return HH:mm:ss,Spark  - Truncate date by Day / Hour,0,0,1
1386,SPARK-17222,SPARK-19610,Duplicate,Support multline csv records,multi line support for CSV,1,1,1
1387,SPARK-17224,SPARK-19610,Duplicate,Support skipping multiple header rows in csv,multi line support for CSV,1,0,1
1388,SPARK-17225,SPARK-17878,Duplicate,Support multiple null values in csv files,Support for multiple null values when reading CSV data,1,0,1
1389,SPARK-17227,SPARK-21289,Duplicate,Allow configuring record delimiter in csv,Text and CSV formats do not support custom end-of-line delimiters,1,1,1
1390,SPARK-17248,SPARK-21670,Unresolved,Add native Scala enum support to Dataset Encoders,Encoders.bean() throws UnsupportedOperationException if Java Bean Class contains an enum,1,1,1
1391,SPARK-17253,SPARK-17296,Duplicate,Left join where ON clause does not reference the right table produces analysis error,Spark SQL: cross join + two joins = BUG,1,0,1
1392,SPARK-17259,SPARK-17558,Duplicate,Hadoop 2.7 profile to depend on Hadoop 2.7.3,Bump Hadoop 2.7 version from 2.7.2 to 2.7.3,1,0,1
1393,SPARK-17278,SPARK-17297,Duplicate,better error message for NPE during ScalaUDF execution,Clarify window/slide duration as absolute time; not relative to a calendar,0,0,1
1394,SPARK-17287,SPARK-17585,Duplicate,PySpark sc.AddFile method does not support the recursive keyword argument,PySpark SparkContext.addFile supports adding files recursively,0,1,1
1395,SPARK-17296,SPARK-17384,Fixed,Spark SQL: cross join + two joins = BUG,SQL - Running query with outer join from 1.6 fails,1,1,1
1396,SPARK-17296,SPARK-17384,Fixed,Spark SQL: cross join + two joins = BUG,SQL - Running query with outer join from 1.6 fails,1,1,1
1397,SPARK-17312,SPARK-17313,Duplicate,Support spark-shell on cluster mode,Support spark-shell on cluster mode,1,1,1
1398,SPARK-17312,SPARK-17313,Duplicate,Support spark-shell on cluster mode,Support spark-shell on cluster mode,1,1,1
1399,SPARK-17321,SPARK-21660,Fixed,YARN shuffle service should use good disk from yarn.nodemanager.local-dirs,Yarn ShuffleService failed to start when the chosen directory become read-only,0,1,1
1400,SPARK-17362,SPARK-17363,Duplicate,fix MultivariantOnlineSummerizer.numNonZeros,fix MultivariateOnlineSummerizer.numNonZeros,1,0,1
1401,SPARK-17367,SPARK-17368,Duplicate,Cannot define value classes in REPL,Scala value classes create encoder problems and break at runtime,0,1,1
1402,SPARK-17375,SPARK-17626,Duplicate,Star Join Optimization,TPC-DS performance improvements using star-schema heuristics,1,0,1
1403,SPARK-17396,SPARK-17842,Fixed,Threads number keep increasing when query on external CSV partitioned table,Thread and memory leak in WindowDstream (UnionRDD ) when parallelPartition computation gets enabled. ,0,0,1
1404,SPARK-17406,SPARK-19328,Fixed,Event Timeline will be very slow when there are too many executor events,using spark thrift server gets memory leak problem in `ExecutorsListener`,0,0,1
1405,SPARK-17414,SPARK-21204,Fixed,Set type is not supported for creating data frames,RuntimeException with Set and Case Class in Spark 2.1.1,0,0,1
1406,SPARK-17452,SPARK-17612,Duplicate,"Spark 2.0.0 is not supporting the ""partition"" keyword on a ""describe"" statement when using Hive Support",Support `DESCRIBE table PARTITION` SQL syntax,1,1,1
1407,SPARK-17458,SPARK-18393,Fixed,Alias specified for aggregates in a pivot are not honored,DataFrame pivot output column names should respect aliases,1,0,1
1408,SPARK-17512,SPARK-17566,Fixed,Specifying remote files for Python based Spark jobs in Yarn cluster mode not working,"--master yarn --deploy-mode cluster gives ""Launching Python applications through spark-submit is currently only supported for local files""",0,1,1
1409,SPARK-17542,SPARK-17586,Duplicate,Compiler warning in UnsafeInMemorySorter class,Use Static member not via instance reference,0,1,1
1410,SPARK-17565,SPARK-17948,Unresolved,Janino exception when calculating metrics for large generated class, WARN CodeGenerator: Error calculating stats of compiled class,0,0,1
1411,SPARK-17568,SPARK-19630,Fixed,Add spark-submit option for user to override ivy settings used to resolve packages/artifacts,spark.jars.ivy explanation is incorrect and missleading.,0,1,1
1412,SPARK-17578,SPARK-17580,Duplicate,Modify default value of spark.app.name in configuration for spark session,Assign random App name while creating spark context,0,0,1
1413,SPARK-17599,SPARK-19187,Fixed,Folder deletion after globbing may fail StructuredStreaming jobs,querying from parquet partitioned table throws FileNotFoundException when some partitions' hdfs locations do not exist,0,1,1
1414,SPARK-17615,SPARK-17616,Duplicate,"Getting ""java.lang.RuntimeException: Distinct columns cannot exist in Aggregate ""","Getting ""java.lang.RuntimeException: Distinct columns cannot exist in Aggregate """,1,1,1
1415,SPARK-17636,SPARK-19638,Unresolved,Parquet filter push down doesn't handle struct fields,Filter pushdown not working for struct fields,0,0,1
1416,SPARK-17707,SPARK-18343,Fixed,Web UI prevents spark-submit application to be finished,FileSystem$Statistics$StatisticsDataReferenceCleaner hangs on s3 write,0,1,1
1417,SPARK-17728,SPARK-18748,Not A Problem,UDFs are run too many times,UDF multiple evaluations causes very poor performance,0,0,1
1418,SPARK-17728,SPARK-18747,Not A Problem,UDFs are run too many times,UDF multiple evaluations causes very poor performance,0,0,1
1419,SPARK-17732,SPARK-18515,Duplicate,ALTER TABLE DROP PARTITION should support comparators,AlterTableDropPartitions fails for non-string columns,1,1,1
1420,SPARK-17747,SPARK-17797,Fixed,WeightCol support non-double datatypes,getNumClasses support non-double datatypes,1,0,1
1421,SPARK-17766,SPARK-18617,Duplicate,Write ahead log exception on a toy project,"Close ""kryo auto pick"" feature for Spark Streaming",0,0,1
1422,SPARK-17767,SPARK-19632,Later,Spark SQL ExternalCatalog API custom implementation support,Allow configuring non-hive and non-local SessionState and ExternalCatalog,1,1,1
1423,SPARK-17806,SPARK-17962,Fixed,Incorrect result when work with data from parquet,DataFrame/Dataset join not producing correct results in Spark 2.0/Yarn,0,0,1
1424,SPARK-17806,SPARK-17891,Fixed,Incorrect result when work with data from parquet,SQL-based three column join loses first column,0,0,1
1425,SPARK-17810,SPARK-17918,Fixed,Default spark.sql.warehouse.dir is relative to local FS but can resolve as HDFS path,Default Warehouse location apparently in HDFS ,0,1,1
1426,SPARK-17816,SPARK-17901,Fixed,Json serialzation of accumulators are failing with ConcurrentModificationException,NettyRpcEndpointRef: Error sending message and Caused by: java.util.ConcurrentModificationException,0,1,1
1427,SPARK-17819,SPARK-19000,Fixed,Specified database in JDBC URL is ignored when connecting to thriftserver,Spark beeline: table was created  at default database  even though specifing a database name,1,1,1
1428,SPARK-17865,SPARK-20684,Not A Problem,R API for global temp view,expose createOrReplaceGlobalTempView/createGlobalTempView and dropGlobalTempView in SparkR,0,1,1
1429,SPARK-17880,SPARK-18435,Fixed,The url linking to `AccumulatorV2` in the document is incorrect.,The requested URL /docs/latest/api/scala/org/apache/spark/AccumulatorV2.html was not found on this server.,1,1,1
1430,SPARK-17881,SPARK-18000,Duplicate,Aggregation function for generating string histograms,Aggregation function for computing bins (distinct value; count) pairs for equi-width histograms,1,1,1
1431,SPARK-17890,SPARK-18055,Cannot Reproduce,scala.ScalaReflectionException,Dataset.flatMap can't work with types from customized jar,0,0,1
1432,SPARK-17913,SPARK-19415,Fixed,Filter/join expressions can return incorrect results when comparing strings to longs,Improve the implicit type conversion between numeric type and string to avoid precesion loss,1,1,1
1433,SPARK-17913,SPARK-19971,Fixed,Filter/join expressions can return incorrect results when comparing strings to longs,Wired SELECT equal behaviour. ,1,0,1
1434,SPARK-17913,SPARK-18489,Fixed,Filter/join expressions can return incorrect results when comparing strings to longs,Implicit type conversion during comparision between Integer type column and String type column,1,1,1
1435,SPARK-17916,SPARK-21768,Unresolved,CSV data source treats empty string as null no matter what nullValue option is,spark.csv.read Empty String Parsed as NULL when nullValue is Set,0,1,1
1436,SPARK-17940,SPARK-17963,Duplicate,Typo in LAST function error message,Add examples (extend) in each function and improve documentation,1,0,1
1437,SPARK-17969,SPARK-18352,Duplicate,I think it's user unfriendly to process standard json file with DataFrame ,Parse normal; multi-line JSON files (not just JSON Lines),1,0,1
1438,SPARK-18027,SPARK-18968,Fixed,.sparkStaging not clean on RM ApplicationNotFoundException,.sparkStaging quickly fill up HDFS,0,0,1
1439,SPARK-18055,SPARK-18139,Fixed,Dataset.flatMap can't work with types from customized jar,INSERT [INTO|OVERWRITE] TABLE ... PARTITION for Datasource tables cannot handle partitions with custom locations,0,1,1
1440,SPARK-18061,SPARK-21407,Fixed,Spark Thriftserver needs to create SPNego principal,Support spnego for ThriftServer thrift/http auth,1,0,1
1441,SPARK-18075,SPARK-20525,Not A Problem,UDF doesn't work on non-local spark,ClassCast exception when interpreting UDFs from a String in spark-shell,0,1,1
1442,SPARK-18075,SPARK-18802,Not A Problem,UDF doesn't work on non-local spark,java.lang.ClassCastException in a simple spark application,0,1,1
1443,SPARK-18081,SPARK-18286,Fixed,Locality Sensitive Hashing (LSH) User Guide,Add Scala/Java/Python examples for MinHash and RandomProjection,0,0,1
1444,SPARK-18085,SPARK-21348,Unresolved,SPIP: Better History Server scalability for many / large applications,Spark history Server load too slow when eventlog is large,0,0,1
1445,SPARK-18085,SPARK-20582,Unresolved,SPIP: Better History Server scalability for many / large applications,Speed up the restart of HistoryServer using ApplicationAttemptInfo checkpointing,0,0,1
1446,SPARK-18111,SPARK-18221,Fixed,Wrong ApproximatePercentile answer when multiple records have the minimum value,Wrong ApproximatePercentile answer when multiple records have the minimum value(for branch 2.0),1,1,1
1447,SPARK-18123,SPARK-19308,Resolved,org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils.saveTable  the case senstivity issue,Unable to write to Hive table where column names contains period (.),1,1,1
1448,SPARK-18127,SPARK-18799,Fixed,Add hooks and extension points to Spark,Spark SQL expose interface for plug-gable parser extension ,1,1,1
1449,SPARK-18167,SPARK-18168,Unresolved,Flaky test when hive partition pruning is enabled,Revert the change of SPARK-18167,1,0,1
1450,SPARK-18215,SPARK-18216,Duplicate,Make Column.expr public,Make Column.expr public,1,1,1
1451,SPARK-18223,SPARK-18224,Duplicate,Optimise PartitionedAppendOnlyMap implementation,Optimise PartitionedPairBuffer implementation,1,1,1
1452,SPARK-18240,SPARK-18282,Duplicate,Add Summary of BiKMeans and GMM in pyspark,Add model summaries for Python GMM and BisectingKMeans,1,0,1
1453,SPARK-18266,SPARK-18332,Duplicate,Update R vignettes and programming guide for 2.1.0 release,SparkR 2.1 QA: Programming guide; migration guide; vignettes updates,0,0,1
1454,SPARK-18284,SPARK-20866,Fixed,Scheme of DataFrame generated from RDD is different between master and 2.0,Dataset map does not respect nullable field ,1,1,1
1455,SPARK-18285,SPARK-19619,Fixed,approxQuantile in R support multi-column,SparkR approxQuantile supports input multiple columns,1,0,1
1456,SPARK-18291,SPARK-18618,Duplicate,"SparkR glm predict should output original label when family = ""binomial""",SparkR GLM model predict should support type as a argument,1,1,1
1457,SPARK-18300,SPARK-19954,Fixed,ClassCastException during count distinct,Joining to a unioned DataFrame does not produce expected result.,1,0,1
1458,SPARK-18330,SPARK-18332,Duplicate,SparkR 2.1 QA: Update user guide for new features & APIs,SparkR 2.1 QA: Programming guide; migration guide; vignettes updates,1,1,1
1459,SPARK-18355,SPARK-21686,Fixed,Spark SQL fails to read data from a ORC hive table that has a new column added to it,spark.sql.hive.convertMetastoreOrc is causing NullPointerException while reading ORC tables,0,1,1
1460,SPARK-18359,SPARK-20743,Unresolved,Let user specify locale in CSV parsing,Spark ignores JVM Locale parsing CSV data,0,0,1
1461,SPARK-18375,SPARK-18756,Fixed,Upgrade netty to 4.0.42.Final ,Memory leak in Spark streaming,0,0,1
1462,SPARK-18386,SPARK-18682,Duplicate,Batch mode SQL source for Kafka,Batch Source for Kafka,0,1,1
1463,SPARK-18470,SPARK-18537,Duplicate,Provide Spark Streaming Monitor Rest Api,Add a REST api to spark streaming,0,1,1
1464,SPARK-18523,SPARK-18876,Fixed,OOM killer may leave SparkContext in broken state causing Connection Refused errors,An error occurred while trying to connect to the Java server,1,1,1
1465,SPARK-18523,SPARK-21881,Fixed,OOM killer may leave SparkContext in broken state causing Connection Refused errors,Again: OOM killer may leave SparkContext in broken state causing Connection Refused errors,1,1,1
1466,SPARK-18528,SPARK-18851,Fixed,limit + groupBy leads to java.lang.NullPointerException,DataSet Limit into Aggregate Results in NPE in Codegen,0,0,1
1467,SPARK-18528,SPARK-19037,Fixed,limit + groupBy leads to java.lang.NullPointerException,Run count(distinct x) from sub query found some errors,0,1,1
1468,SPARK-18555,SPARK-19375,Fixed,na.fill miss up original values in long integers,na.fill() should not change the data type of column,1,0,1
1469,SPARK-18557,SPARK-18784,Fixed,Downgrade the memory leak warning message,Managed memory leak - spark-2.0.2,0,1,1
1470,SPARK-18560,SPARK-18617,Duplicate,Receiver data can not be dataSerialized properly.,"Close ""kryo auto pick"" feature for Spark Streaming",0,0,1
1471,SPARK-18560,SPARK-18737,Duplicate,Receiver data can not be dataSerialized properly.,"Serialization setting ""spark.serializer"" ignored in Spark 2.x",0,0,1
1472,SPARK-18574,SPARK-18575,Duplicate,Keep same style: adjust the position of ,Keep same style: adjust the position of driver log links,0,0,1
1473,SPARK-18579,SPARK-19942,Fixed,spark-csv strips whitespace (pyspark) ,"DataFrameWriter - CSV options ""ignoreLeadingWhiteSpace"" and ""ignoreTrailingWhiteSpace"" Not working",0,0,1
1474,SPARK-18579,SPARK-21442,Fixed,spark-csv strips whitespace (pyspark) ,Spark CSV writer trims trailing spaces,1,0,1
1475,SPARK-18589,SPARK-19728,Fixed,"persist() resolves ""java.lang.RuntimeException: Invalid PythonUDF <lambda>(...); requires attributes from more than one child""", PythonUDF with multiple parents shouldn't be pushed down when used as a predicate,1,0,1
1476,SPARK-18598,SPARK-20374,Unresolved,Encoding a Java Bean with extra accessors; produces inconsistent Dataset; resulting in AssertionError,Encoder generated using Java beans causes corruption in MapGroupsWithState,0,0,1
1477,SPARK-18608,SPARK-21799,Fixed,Spark ML algorithms that check RDD cache level for internal caching double-cache data,KMeans performance regression (5-6x slowdown) in Spark 2.2,0,1,1
1478,SPARK-18627,SPARK-20709,Cannot Reproduce,Cannot connect to Hive metastore in client mode with proxy user,spark-shell use proxy-user failed,0,0,1
1479,SPARK-18646,SPARK-19675,Fixed,ExecutorClassLoader for spark-shell does not honor spark.executor.userClassPathFirst,ExecutorClassLoader loads classes from SystemClassLoader,0,0,1
1480,SPARK-18648,SPARK-21339,Duplicate,spark-shell --jars option does not add jars to classpath on windows,spark-shell --packages option does not add jars to classpath on windows,1,1,1
1481,SPARK-18658,SPARK-18984,Fixed,Writing to a text DataSource buffers one or more lines in memory,Concat with ds.write.text() throw exception if column contains null data,1,0,1
1482,SPARK-18680,SPARK-18681,Duplicate,Throw Filtering is supported only on partition keys of type string exception,Throw Filtering is supported only on partition keys of type string exception,1,1,1
1483,SPARK-18687,SPARK-18956,Fixed,Backward compatibility - creating a Dataframe on a new SQLContext object fails with a Derby error,Python API should reuse existing SparkSession while creating new SQLContext instances,0,1,1
1484,SPARK-18696,SPARK-18697,Duplicate,Upgrade sbt plugins,Upgrade sbt plugins,1,0,1
1485,SPARK-18699,SPARK-20387,Fixed,Spark CSV parsing types other than String throws exception when malformed,Permissive mode is not replacing corrupt record with null,0,1,1
1486,SPARK-18699,SPARK-18906,Fixed,Spark CSV parsing types other than String throws exception when malformed,"CSV parser should return null for empty (or with """") numeric columns.",1,0,1
1487,SPARK-18703,SPARK-18931,Fixed,Insertion/CTAS against Hive Tables: Staging Directories and Data Files Not Dropped Until Normal Termination of JVM,Create empty staging directory in partitioned table on insert,1,0,1
1488,SPARK-18751,SPARK-19362,Fixed,Deadlock when SparkContext.stop is called in Utils.tryOrStopSparkContext,master UI kill link stops spark context but leave it active,1,1,1
1489,SPARK-18792,SPARK-18797,Duplicate,SparkR vignette update: logit,Update spark.logit in sparkr-vignettes,0,1,1
1490,SPARK-18827,SPARK-21794,Fixed,Cann't read broadcast if broadcast blocks are stored on-disk,exception about reading task serial data(broadcast) value when the storage memory is not enough to unroll,1,1,1
1491,SPARK-18838,SPARK-18881,Fixed,High latency of event processing for large jobs,Spark never finishes jobs and stages; JobProgressListener fails,1,1,1
1492,SPARK-18847,SPARK-18848,Fixed,PageRank gives incorrect results for graphs with sinks,PageRank gives incorrect results for graphs with sinks,1,1,1
1493,SPARK-18847,SPARK-20429,Fixed,PageRank gives incorrect results for graphs with sinks,Add support for IS [NOT] DISTINCT FROM to SPARK SQL,1,1,1
1494,SPARK-18866,SPARK-18952,Duplicate,Codegen fails with cryptic error if regexp_replace() output column is not aliased,regex strings not properly escaped in codegen for aggregations,0,0,1
1495,SPARK-18876,SPARK-21881,Duplicate,An error occurred while trying to connect to the Java server,Again: OOM killer may leave SparkContext in broken state causing Connection Refused errors,1,1,1
1496,SPARK-18879,SPARK-19457,Not A Problem,Spark SQL support for Hive hooks regressed,Support Hive Hooks in Spark thrift server again,1,1,1
1497,SPARK-18891,SPARK-19104,Fixed,Support for specific collection types, CompileException with Map and Case Class in Spark 2.1.0,0,0,1
1498,SPARK-18891,SPARK-19434,Fixed,Support for specific collection types,Dataframe/Dataset unserialization failing with Map,1,0,1
1499,SPARK-18893,SPARK-19474,Fixed,"Not support ""alter table .. add columns .."" ",SparkSQL unsupports  to change hive table's name\dataType,1,1,1
1500,SPARK-18893,SPARK-19261,Fixed,"Not support ""alter table .. add columns .."" ",Support `ALTER TABLE table_name ADD COLUMNS(..)` statement,1,1,1
1501,SPARK-18896,SPARK-18914,Unresolved,Suppress ScalaCheck warning -- Unknown ScalaCheck args provided when executing tests using sbt,"Local UDTs test (org.apache.spark.sql.UserDefinedTypeSuite) fails due to ""ClassCastException: java.lang.Integer cannot be cast to org.apache.spark.sql.UDT$MyDenseVector""",0,0,1
1502,SPARK-18907,SPARK-18908,Duplicate,Fix flaky test: o.a.s.sql.streaming.FileStreamSourceSuite max files per trigger - incorrect values,It's hard for the user to see the failure if StreamExecution fails to create the logical plan,0,0,1
1503,SPARK-18952,SPARK-20556,Fixed,regex strings not properly escaped in codegen for aggregations,codehaus fails to generate code because of unescaped strings,1,1,1
1504,SPARK-18969,SPARK-19035,Fixed,PullOutNondeterministic should work for Aggregate operator,rand() function in case when cause failed,1,1,1
1505,SPARK-18971,SPARK-19300,Fixed,Netty issue may cause the shuffle client hang,Executor is waiting for lock,1,0,1
1506,SPARK-18971,SPARK-19883,Fixed,Netty issue may cause the shuffle client hang,Executor is waiting for lock,1,0,1
1507,SPARK-18976,SPARK-18994,Duplicate,in standlone mode;executor expired by HeartbeanReceiver that still take up cores but no tasks assigned to ,worker clean up app directory block the heartbeat sending ,1,1,1
1508,SPARK-18982,SPARK-18983,Duplicate,Couldn't find leader offsets exception when the one of kafka cluster brokers is down,Couldn't find leader offsets exception when the one of kafka cluster brokers is down,1,1,1
1509,SPARK-18983,SPARK-21836,Invalid,Couldn't find leader offsets exception when the one of kafka cluster brokers is down,[spark UI]In the SQL table page; modify jobs trace information,0,0,1
1510,SPARK-19049,SPARK-19050,Duplicate,Failed in `delay in months and years handled correctly`,Fix EventTimeWatermarkSuite 'delay in months and years handled correctly',0,0,1
1511,SPARK-19055,SPARK-19138,Fixed,SparkSession initialization will be associated with invalid SparkContext when new SparkContext is created to replace stopped SparkContext,Python: new HiveContext will use a stopped SparkContext,0,1,1
1512,SPARK-19064,SPARK-19608,Fixed,Fix pip install issue with ml sub components,setup.py missing reference to pyspark.ml.param,1,0,1
1513,SPARK-19068,SPARK-19146,Duplicate,Large number of executors causing a ton of ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(41;WrappedArray()),Drop more elements when stageData.taskData.size > retainedTasks to reduce the number of times on call drop,0,0,1
1514,SPARK-19095,SPARK-19096,Duplicate,virtualenv example does not work in yarn cluster mode,Kmeans.py application fails with virtualenv and due to  parse error ,0,0,1
1515,SPARK-19095,SPARK-19097,Duplicate,virtualenv example does not work in yarn cluster mode,virtualenv example failed with conda due to ImportError: No module named ruamel.yaml.comments,0,0,1
1516,SPARK-19104,SPARK-21391,Fixed, CompileException with Map and Case Class in Spark 2.1.0,Cannot convert a Seq of Map whose value type is again a seq; into a dataset ,0,1,1
1517,SPARK-19106,SPARK-21889,Fixed,Styling for the configuration docs is broken,Web site headers not rendered correctly in some pages,1,0,1
1518,SPARK-19106,SPARK-22627,Fixed,Styling for the configuration docs is broken,Fix formatting of headers in configuration.html page,1,0,1
1519,SPARK-19112,SPARK-19958,Fixed,add codec for ZStandard,Support ZStandard Compression,1,0,1
1520,SPARK-19169,SPARK-19170,Invalid,columns changed orc table encouter 'IndexOutOfBoundsException' when read the old schema files,columns changed orc table encouter 'IndexOutOfBoundsException' when read the old schema files,1,1,1
1521,SPARK-19169,SPARK-19172,Invalid,columns changed orc table encouter 'IndexOutOfBoundsException' when read the old schema files,columns changed orc table encouter 'IndexOutOfBoundsException' when read the old schema files,1,1,1
1522,SPARK-19169,SPARK-19174,Invalid,columns changed orc table encouter 'IndexOutOfBoundsException' when read the old schema files,columns changed orc table encouter 'IndexOutOfBoundsException' when read the old schema files,1,1,1
1523,SPARK-19169,SPARK-19175,Invalid,columns changed orc table encouter 'IndexOutOfBoundsException' when read the old schema files,columns changed orc table encouter 'IndexOutOfBoundsException' when read the old schema files,1,1,1
1524,SPARK-19169,SPARK-19171,Invalid,columns changed orc table encouter 'IndexOutOfBoundsException' when read the old schema files,columns changed orc table encouter 'IndexOutOfBoundsException' when read the old schema files,1,1,1
1525,SPARK-19169,SPARK-19173,Invalid,columns changed orc table encouter 'IndexOutOfBoundsException' when read the old schema files,columns changed orc table encouter 'IndexOutOfBoundsException' when read the old schema files,1,1,1
1526,SPARK-19174,SPARK-19175,Duplicate,columns changed orc table encouter 'IndexOutOfBoundsException' when read the old schema files,columns changed orc table encouter 'IndexOutOfBoundsException' when read the old schema files,1,1,1
1527,SPARK-19185,SPARK-20911,Unresolved,ConcurrentModificationExceptions with CachedKafkaConsumers when Windowing,Unable to do windowing operation on Spark 2.1.1 and kafka 0.10.2.0,1,1,1
1528,SPARK-19256,SPARK-21649,Unresolved,Hive bucketing support,Support writing data into hive bucket table.,1,0,1
1529,SPARK-19257,SPARK-19332,Fixed,The type of CatalogStorageFormat.locationUri should be java.net.URI instead of String,table's location should check if a URI is legal,1,1,1
1530,SPARK-19262,SPARK-19623,Duplicate,DAGScheduler should handle stage's pendingPartitions properly in handleTaskCompletion.,Take rows from DataFrame with empty first partition,0,0,1
1531,SPARK-19276,SPARK-20480,Fixed,FetchFailures can be hidden by user (or sql) exception handling,FileFormatWriter hides FetchFailedException from scheduler,0,1,1
1532,SPARK-19278,SPARK-19280,Duplicate,Failed Recovery from checkpoint caused by the multi-threads issue in Spark Streaming scheduler,Failed Recovery from checkpoint caused by the multi-threads issue in Spark Streaming scheduler,1,0,1
1533,SPARK-19293,SPARK-20358,Duplicate,Spark 2.1.x unstable with spark.speculation=true,Executors failing stage on interrupted exception thrown by cancelled tasks,1,0,1
1534,SPARK-19294,SPARK-20797,Duplicate,improve LocalLDAModel save/load scaling for large models,mllib lda's LocalLDAModel's save: out of memory. ,0,1,1
1535,SPARK-19300,SPARK-19883,Duplicate,Executor is waiting for lock,Executor is waiting for lock,1,0,1
1536,SPARK-19307,SPARK-19369,Fixed,SPARK-17387 caused ignorance of conf object passed to SparkContext:,SparkConf not getting properly initialized in PySpark 2.1.0,1,1,1
1537,SPARK-19307,SPARK-20362,Fixed,SPARK-17387 caused ignorance of conf object passed to SparkContext:,spark submit not considering user defined Configs (Pyspark),1,1,1
1538,SPARK-19317,SPARK-22249,Duplicate,UnsupportedOperationException: empty.reduceLeft in LinearSeqOptimized,UnsupportedOperationException: empty.reduceLeft when caching a dataframe,0,0,1
1539,SPARK-19323,SPARK-20449,Duplicate,Upgrade breeze to 0.13,Upgrade breeze version to 0.13.1,0,1,1
1540,SPARK-19339,SPARK-19573,Duplicate,StatFunctions.multipleApproxQuantiles can give NoSuchElementException: next on empty iterator,Make NaN/null handling consistent in approxQuantile,0,0,1
1541,SPARK-19354,SPARK-20217,Duplicate,Killed tasks are getting marked as FAILED,Executor should not fail stage if killed task throws non-interrupted exception,0,1,1
1542,SPARK-19360,SPARK-21002,Unresolved,Spark 2.X does not support stored by clause,Syntax error regression when creating Hive storage handlers on Spark shell,1,0,1
1543,SPARK-19430,SPARK-19459,Duplicate,Cannot read external tables with VARCHAR columns if they're backed by ORC files written by Hive 1.2.1,ORC tables cannot be read when they contain char/varchar columns,1,1,1
1544,SPARK-19455,SPARK-19611,Duplicate,Add option for case-insensitive Parquet field resolution,Spark 2.1.0 breaks some Hive tables backed by case-sensitive data files,1,1,1
1545,SPARK-19458,SPARK-19836,Won't Fix,loading hive jars from the local repo which has already downloaded,Customizable remote repository url for hive versions unit test,0,0,1
1546,SPARK-19459,SPARK-20515,Fixed,ORC tables cannot be read when they contain char/varchar columns,Issue with reading Hive ORC tables having char/varchar columns in Spark SQL,1,1,1
1547,SPARK-19473,SPARK-20182,Not A Problem,Several DataFrame Methods still fail with dot in column names ,Dot in DataFrame Column title causes errors,0,1,1
1548,SPARK-19490,SPARK-19811,Cannot Reproduce,Hive partition columns are case-sensitive,sparksql 2.1 can not prune hive partition ,1,1,1
1549,SPARK-19491,SPARK-19625,Duplicate,add a config for tableRelation cache size in SessionCatalog,Authorization Support(on all operations not only DDL) in Spark Sql version 2.1.0,1,0,1
1550,SPARK-19498,SPARK-19717,Unresolved,Discussion: Making MLlib APIs extensible for 3rd party libraries,Expanding Spark ML under Different Namespace,0,0,1
1551,SPARK-19507,SPARK-19871,Fixed,pyspark.sql.types._verify_type() exceptions too broad to debug collections or nested data,Improve error message in verify_type to indicate which field the error is for,0,0,1
1552,SPARK-19512,SPARK-20111,Fixed,codegen for compare structs fails,codegen bug surfaced by GraphFrames issue 165,1,1,1
1553,SPARK-19521,SPARK-19610,Duplicate,Error with embedded line break (multi-line record) in csv file.,multi line support for CSV,0,1,1
1554,SPARK-19573,SPARK-21550,Fixed,Make NaN/null handling consistent in approxQuantile,"approxQuantiles throws ""next on empty iterator"" on empty data",1,1,1
1555,SPARK-19622,SPARK-20293,Fixed,Fix a http error in a paged table when using a `Go` button to search.,In the page of 'jobs' or 'stages' of history server web ui;;click the 'Go' button;  query paging data; the page error,1,0,1
1556,SPARK-19645,SPARK-19677,Duplicate,structured streaming job restart bug,HDFSBackedStateStoreProvider fails to overwrite existing file,1,1,1
1557,SPARK-19661,SPARK-19935,Not A Problem,Spark-2.1.0 can not connect hbase,SparkSQL unsupports to create a hive table which is mapped for HBase table,0,1,1
1558,SPARK-19668,SPARK-20838,Unresolved,Multiple NGram sizes,Spark ML ngram feature extractor should support ngram range like scikit,1,0,1
1559,SPARK-19671,SPARK-19672,Not A Problem,change 'var' to 'val' for better Specification,change 'var' to 'val' for better Specification,1,1,1
1560,SPARK-19688,SPARK-21008,Fixed,Spark on Yarn Credentials File set to different application directory,Streaming applications read stale credentials file when recovering from checkpoint.,0,0,1
1561,SPARK-19690,SPARK-21765,Duplicate,Join a streaming DataFrame with a batch DataFrame may not work,Ensure all leaf nodes that are derived from streaming sources have isStreaming=true,0,0,1
1562,SPARK-19703,SPARK-20447,Unresolved,Add Suppress/Revive support to the Mesos Spark Driver,spark mesos scheduler suppress call,1,0,1
1563,SPARK-19712,SPARK-22573,Unresolved,EXISTS and Left Semi join do not produce the same plan,SQL Planner is including unnecessary columns in the projection,1,1,1
1564,SPARK-19752,SPARK-19809,Duplicate,OrcGetSplits fails with 0 size files,NullPointerException on zero-size ORC file,0,1,1
1565,SPARK-19804,SPARK-22742,Fixed,HiveClientImpl does not work with Hive 2.2.0 metastore,Spark2.x does not support read data from Hive 2.2 and 2.3,1,0,1
1566,SPARK-19876,SPARK-20103,Fixed,Add OneTime trigger executor,Spark structured steaming from kafka - last message processed again after resume from checkpoint,1,1,1
1567,SPARK-19881,SPARK-21574,Won't Fix,Support Dynamic Partition Inserts params with SET command,set hive.exec.max.dynamic.partitions lose effect,1,0,1
1568,SPARK-19898,SPARK-19967,Duplicate,Add from_json in FunctionRegistry,Add from_json APIs to SQL,1,0,1
1569,SPARK-19950,SPARK-20457,Unresolved,nullable ignored when df.load() is executed for file-based data source,Spark CSV is not able to Override Schema while reading data,1,1,1
1570,SPARK-19975,SPARK-21073,Fixed,Add map_keys and map_values functions  to Python ,Support map_keys and map_values functions in DataSet,0,1,1
1571,SPARK-19975,SPARK-21540,Fixed,Add map_keys and map_values functions  to Python ,add spark.sql.functions.map_keys and spark.sql.functions.map_values,0,1,1
1572,SPARK-19995,SPARK-19997,Fixed,Using real user to connect HiveMetastore in HiveClientImpl,proxy-user failed connecting to a kerberos configured metastore,1,1,1
1573,SPARK-20000,SPARK-21276,Duplicate,Spark Hive tests aborted due to lz4-java on ppc64le,Update  lz4-java to remove custom LZ4BlockInputStream,0,0,1
1574,SPARK-20036,SPARK-20037,Fixed,impossible to read a whole kafka topic using kafka 0.10 and spark 2.0.0 ,impossible to set kafka offsets using kafka 0.10 and spark 2.0.0,0,0,1
1575,SPARK-20050,SPARK-20052,Unresolved,Kafka 0.10 DirectStream doesn't commit last processed batch's offset when graceful shutdown,Some InputDStream needs closing processing after processing all batches when graceful shutdown,1,1,1
1576,SPARK-20063,SPARK-20209,Duplicate,Trigger without delay when falling behind ,Execute next trigger immediately if previous batch took longer than trigger interval,1,0,1
1577,SPARK-20073,SPARK-20804,Fixed,Unexpected Cartesian product when using eqNullSafe in join with a derived table,Join with null safe equality fails with AnalysisException,1,0,1
1578,SPARK-20082,SPARK-20767,Unresolved,Incremental update of LDA model; by adding initialModel as start point,The training continuation for saved LDA model,1,0,1
1579,SPARK-20156,SPARK-20361,Fixed,"Java String toLowerCase ""Turkish locale bug"" causes Spark problems",JVM locale affects SQL type names ,0,1,1
1580,SPARK-20188,SPARK-20198,Unresolved,Catalog recoverPartitions should allow specifying the database name,Remove the inconsistency in table/function name conventions in SparkSession.Catalog APIs,1,1,1
1581,SPARK-20213,SPARK-20635,Fixed,DataFrameWriter operations do not show up in SQL tab,No SQL tab in Spark UI,0,1,1
1582,SPARK-20312,SPARK-20359,Fixed,query optimizer calls udf with null values when it doesn't expect them,Catalyst EliminateOuterJoin optimization can cause NPE,1,1,1
1583,SPARK-20331,SPARK-22247,Fixed,Broaden support for Hive partition pruning predicate pushdown,Hive partition filter very slow,0,0,1
1584,SPARK-20342,SPARK-21009,Fixed,DAGScheduler sends SparkListenerTaskEnd before updating task's accumulators,SparkListenerTaskEnd.taskInfo.accumulables might not be accurate,1,1,1
1585,SPARK-20348,SPARK-20602,Duplicate,Support squared hinge loss (L2 loss) for LinearSVC,Adding LBFGS optimizer and Squared_hinge loss for LinearSVC,1,0,1
1586,SPARK-20432,SPARK-20441,Duplicate,Unioning two identical Streaming DataFrames fails during attribute resolution,Within the same streaming query; one StreamingRelation should only be transformed to one StreamingExecutionRelation,1,1,1
1587,SPARK-20444,SPARK-20445,Duplicate,pyspark.sql.utils.IllegalArgumentException: u'DecisionTreeClassifier was given input with invalid label column label; without the number of classes specified. See StringIndexer,pyspark.sql.utils.IllegalArgumentException: u'DecisionTreeClassifier was given input with invalid label column label; without the number of classes specified. See StringIndexer,1,1,1
1588,SPARK-20529,SPARK-20531,Fixed,Worker should not use the received Master address,Spark master shouldn't send its address back to the workers over proxied connections,1,1,1
1589,SPARK-20582,SPARK-21348,Duplicate,Speed up the restart of HistoryServer using ApplicationAttemptInfo checkpointing,Spark history Server load too slow when eventlog is large,0,1,1
1590,SPARK-20640,SPARK-20956,Fixed,Make rpc timeout and retry for shuffle registration configurable,External shuffle server timeout,1,1,1
1591,SPARK-20656,SPARK-22264,Unresolved,Incremental parsing of event logs in SHS,History server will be unavailable if there is an event log file with large size,0,1,1
1592,SPARK-20684,SPARK-21965,Unresolved,expose createOrReplaceGlobalTempView/createGlobalTempView and dropGlobalTempView in SparkR,Add createOrReplaceGlobalTempView and dropGlobalTempView for SparkR,1,1,1
1593,SPARK-20840,SPARK-21185,Unresolved,Misleading spurious errors when there are Javadoc (Unidoc) breaks,Spurious errors in unidoc causing PRs to fail,0,1,1
1594,SPARK-20845,SPARK-21548,Unresolved,Support specification of column names in INSERT INTO,Support insert into serial columns of table,1,0,1
1595,SPARK-20930,SPARK-22309,Fixed, Destroy broadcasted centers after computing cost,Remove unused param in `LDAModel.getTopicDistributionMethod`,1,0,1
1596,SPARK-21027,SPARK-21028,Fixed,Parallel One vs. Rest Classifier,Parallel One vs. Rest Classifier Scala,0,1,1
1597,SPARK-21033,SPARK-22438,Fixed,fix the potential OOM in UnsafeExternalSorter,OutOfMemoryError on very small data sets,0,0,1
1598,SPARK-21034,SPARK-21707,Duplicate,Allow filter pushdown filters through non deterministic functions for columns involved in groupby / join,Improvement a special case for non-deterministic filters in optimizer,0,1,1
1599,SPARK-21146,SPARK-21148,Fixed,Master/Worker should handle and shutdown when any thread gets UncaughtException,Set SparkUncaughtExceptionHandler to the Master,0,1,1
1600,SPARK-21205,SPARK-21630,Fixed,pmod(number; 0) should  be null,Pmod should not throw a divide by zero exception,1,1,1
1601,SPARK-21214,SPARK-21215,Invalid,"Exception in thread ""main"" org.apache.spark.sql.AnalysisException: cannot resolve '","Exception in thread ""main"" org.apache.spark.sql.AnalysisException: cannot resolve",0,1,1
1602,SPARK-21278,SPARK-22337,Fixed,Upgrade to Py4J 0.10.6,new pyspark release,1,0,1
1603,SPARK-21360,SPARK-21361,Unresolved,Spark failing to query SQL Server. Query contains a column having space  in where clause ,Spark failing to query SQL Server. Query contains a column having space  in where clause ,1,0,1
1604,SPARK-21383,SPARK-21562,Fixed,YARN can allocate too many executors,Spark may request extra containers if the rpc between YARN and spark is too fast,1,1,1
1605,SPARK-21393,SPARK-21413,Duplicate,spark (pyspark) crashes unpredictably when using show() or toPandas(),Multiple projections with CASE WHEN fails to run generated codes,0,1,1
1606,SPARK-21402,SPARK-21747,Unresolved,Java encoders - switch fields on collectAsList,Java encoders - switch fields on collectAsList,1,1,1
1607,SPARK-21413,SPARK-22520,Duplicate,Multiple projections with CASE WHEN fails to run generated codes,Support code generation also for complex CASE WHEN,1,0,1
1608,SPARK-21469,SPARK-21810,Fixed,Add doc and example for FeatureHasher,Add ML Examples for FeatureHasher,0,0,1
1609,SPARK-21477,SPARK-21884,Fixed,Mark LocalTableScanExec's input data transient,Fix StackOverflowError on MetadataOnlyQuery,1,1,1
1610,SPARK-21523,SPARK-21614,Fixed,Fix bug of strong wolfe linesearch `init` parameter lose effectiveness,Multinomial logistic regression model fitting fails with ERROR StrongWolfeLineSearch,0,0,1
1611,SPARK-21523,SPARK-21919,Fixed,Fix bug of strong wolfe linesearch `init` parameter lose effectiveness,inconsistent behavior of AFTsurvivalRegression algorithm,0,0,1
1612,SPARK-21596,SPARK-21760,Fixed,Audit the places calling HDFSMetadataLog.get,Structured streaming terminates with Exception ,1,0,1
1613,SPARK-21599,SPARK-21627,Fixed,Collecting column statistics for datasource tables may fail with java.util.NoSuchElementException,analyze hive table compute stats for columns with mixed case exception,1,1,1
1614,SPARK-21605,SPARK-21628,Fixed,Let IntelliJ IDEA correctly detect Language level and Target byte code version,Explicitly specify Java version in maven compiler plugin so IntelliJ imports project correctly,1,1,1
1615,SPARK-21610,SPARK-22580,Fixed,Corrupt records are not handled properly when creating a dataframe from a file,Count after filtering uncached CSV for isnull(columnNameOfCorruptRecord) always 0,0,1,1
1616,SPARK-21646,SPARK-22722,Unresolved,Add new type coercion rules to compatible with Hive,Test Coverage for Type Coercion Compatibility,1,1,1
1617,SPARK-21720,SPARK-22523,Fixed,Filter predicate with many conditions throw stackoverflow error,Janino throws StackOverflowError on nested structs with many fields,0,0,1
1618,SPARK-21734,SPARK-21735,Invalid,spark job blocked by updateDependencies,spark job blocked by updateDependencies,1,1,1
1619,SPARK-21762,SPARK-22258,Fixed,FileFormatWriter/BasicWriteTaskStatsTracker metrics collection fails if a new file isn't yet visible,Writing empty dataset fails with ORC format,1,0,1
1620,SPARK-21834,SPARK-22598,Fixed,Incorrect executor request in case of dynamic allocation,ExecutorAllocationManager does not requests new executors when executor fail and target has not change,0,1,1
1621,SPARK-21896,SPARK-22804,Unresolved,Stack Overflow when window function nested inside aggregate function,Using a window function inside of an aggregation causes StackOverflowError,0,1,1
1622,SPARK-21977,SPARK-22752,Fixed,SinglePartition optimizations break certain Streaming Stateful Aggregation requirements,FileNotFoundException while reading from Kafka,1,1,1
1623,SPARK-21999,SPARK-22163,Won't Fix,ConcurrentModificationException - Spark Streaming,Design Issue of Spark Streaming that Causes Random Run-time Exception,0,0,1
1624,SPARK-22066,SPARK-22269,Fixed,Update checkstyle to 8.2; enable it; fix violations,Java style checks should be run in Jenkins,1,1,1
1625,SPARK-22150,SPARK-22184,Unresolved,PeriodicCheckpointer fails with FileNotFoundException in case of dependant RDDs,GraphX fails in case of insufficient memory and checkpoints enabled,0,1,1
1626,SPARK-22179,SPARK-22208,Duplicate,percentile_approx should choose the first element if it already reaches the percentage,Improve percentile_approx by not rounding up targetError and starting from index 0,1,1,1
1627,SPARK-22223,SPARK-22276,Fixed,ObjectHashAggregate introduces unnecessary shuffle,Unnecessary repartitioning,1,1,1
1628,SPARK-22226,SPARK-22761,Fixed,splitExpression can create too many method calls (generating a Constant Pool limit error),64KB JVM bytecode limit problem with GLM,1,1,1
1629,SPARK-22242,SPARK-22243,Duplicate,streaming job failed to restart from checkpoint,streaming job failed to restart from checkpoint,1,1,1
1630,SPARK-22259,SPARK-22260,Duplicate,Postgresql UUID[] to Cassandra: Conversion Error, java.lang.RuntimeException: hdfs://HdfsHA/logrep/1/sspstatistic/_metadata is not a Parquet file (too small),0,1,1
1631,SPARK-22304,SPARK-22305,Duplicate,HDFSBackedStateStoreProvider stackoverflow due to reloading of very old state,HDFSBackedStateStoreProvider fails with StackOverflowException when attempting to recover state,1,1,1
1632,SPARK-22324,SPARK-22656,Fixed,Upgrade Arrow to version 0.8.0,Upgrade Arrow to 0.8.0,1,1,1
1633,SPARK-22398,SPARK-22413,Duplicate,Partition directories with leading 0s cause wrong results,Type coercion for IN is not coherent between Literals and subquery,1,1,1
1634,SPARK-22525,SPARK-22819,Fixed,Spark download page doesn't update package name based package type,Download page - updating package type does nothing,1,1,1
1635,SPARK-22660,SPARK-22687,Fixed,Use position() and limit() to fix ambiguity issue in scala-2.12,Run spark-sql in scala-2.12 and JDK9,1,0,1
1636,SPARK-22660,SPARK-22661,Fixed,Use position() and limit() to fix ambiguity issue in scala-2.12,Fix the putAll compile error when compiling with scala-2.12 and jdk9,1,0,1
1637,SPARK-22769,SPARK-22770,Unresolved,"When driver stopping; there is errors: ""Could not find CoarseGrainedScheduler"" and ""RpcEnv already stopped""","When driver stopping; there is errors: ""Could not find CoarseGrainedScheduler"" and ""RpcEnv already stopped""",1,1,1
1638,SPARK-22863,SPARK-22912,Duplicate,Make MicroBatchExecution also support MicroBatchRead/WriteSupport,Support v2 streaming sources and sinks in MicroBatchExecution,1,1,1
1639,SPARK-22888,SPARK-22899,Duplicate,OneVsRestModel does not work with Structured Streaming,OneVsRestModel transform on streaming data failed.,0,0,1
